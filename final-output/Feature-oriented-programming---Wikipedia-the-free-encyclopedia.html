<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Feature-oriented-programming---Wikipedia-the-free-encyclopedia.html</title></head>
<body>
<h1>Feature-oriented programming</h1>
<ul>
<li>Action</li>
<li>Agent-oriented</li>
<li>Aspect-oriented</li>
<li>Automata-based</li>
<li>Concurrent computing
<ul>
<li>Relativistic programming</li>
</ul>
</li>
<li>Data-driven</li>
<li>Declarative (contrast: Imperative)
<ul>
<li>Constraint</li>
<li>Dataflow
<ul>
<li>Flow-based</li>
<li>Cell-oriented (spreadsheets)</li>
<li>Reactive</li>
</ul>
</li>
<li>Functional
<ul>
<li>Functional logic</li>
</ul>
</li>
<li>Logic
<ul>
<li>Abductive logic</li>
<li>Answer set</li>
<li>Constraint logic</li>
<li>Functional logic</li>
<li>Inductive logic</li>
</ul>
</li>
<li>Relational</li>
</ul>
</li>
<li>End-user programming</li>
<li>Event-driven
<ul>
<li>Service-oriented</li>
<li>Time-driven</li>
</ul>
</li>
<li>Expression-oriented</li>
<li><strong class="selflink">Feature-oriented</strong></li>
<li>Function-level (contrast: Value-level)</li>
<li>Generic</li>
<li>Imperative (contrast: Declarative)
<ul>
<li>Procedural</li>
</ul>
</li>
<li>Language-oriented
<ul>
<li>Natural language programming</li>
<li>Discipline-specific</li>
<li>Domain-specific</li>
<li>Grammar-oriented
<ul>
<li>Dialecting</li>
</ul>
</li>
<li>Intentional</li>
</ul>
</li>
<li>Metaprogramming
<ul>
<li>Automatic</li>
<li>Reflective
<ul>
<li>Attribute-oriented</li>
</ul>
</li>
<li>Homoiconic</li>
<li>Template
<ul>
<li>Policy-based</li>
</ul>
</li>
</ul>
</li>
<li>Non-structured (contrast: Structured)
<ul>
<li>Array</li>
</ul>
</li>
<li>Nondeterministic</li>
<li>Parallel computing
<ul>
<li>Process-oriented</li>
</ul>
</li>
<li>Point-free style
<ul>
<li>Concatenative</li>
</ul>
</li>
<li>Semantic</li>
<li>Structured (contrast: Non-structured)
<ul>
<li>Block-structured</li>
<li>Modular (contrast: Monolithic)</li>
<li>Object-oriented (OOP)
<ul>
<li>By separation of concerns:
<ul>
<li>Aspect-oriented</li>
<li>Role-oriented</li>
<li>Subject-oriented</li>
</ul>
</li>
<li>Class-based</li>
<li>Prototype-based</li>
</ul>
</li>
<li>Recursive</li>
</ul>
</li>
<li>Value-level (contrast: Function-level)</li>
<li>Probabilistic</li>
<li>Concept</li>
</ul>
<ul>
<li>Relativistic programming</li>
</ul>
<ul>
<li>Constraint</li>
<li>Dataflow
<ul>
<li>Flow-based</li>
<li>Cell-oriented (spreadsheets)</li>
<li>Reactive</li>
</ul>
</li>
<li>Functional
<ul>
<li>Functional logic</li>
</ul>
</li>
<li>Logic
<ul>
<li>Abductive logic</li>
<li>Answer set</li>
<li>Constraint logic</li>
<li>Functional logic</li>
<li>Inductive logic</li>
</ul>
</li>
<li>Relational</li>
</ul>
<ul>
<li>Flow-based</li>
<li>Cell-oriented (spreadsheets)</li>
<li>Reactive</li>
</ul>
<ul>
<li>Functional logic</li>
</ul>
<ul>
<li>Abductive logic</li>
<li>Answer set</li>
<li>Constraint logic</li>
<li>Functional logic</li>
<li>Inductive logic</li>
</ul>
<ul>
<li>Service-oriented</li>
<li>Time-driven</li>
</ul>
<ul>
<li>Procedural</li>
</ul>
<ul>
<li>Natural language programming</li>
<li>Discipline-specific</li>
<li>Domain-specific</li>
<li>Grammar-oriented
<ul>
<li>Dialecting</li>
</ul>
</li>
<li>Intentional</li>
</ul>
<ul>
<li>Dialecting</li>
</ul>
<ul>
<li>Automatic</li>
<li>Reflective
<ul>
<li>Attribute-oriented</li>
</ul>
</li>
<li>Homoiconic</li>
<li>Template
<ul>
<li>Policy-based</li>
</ul>
</li>
</ul>
<ul>
<li>Attribute-oriented</li>
</ul>
<ul>
<li>Policy-based</li>
</ul>
<ul>
<li>Array</li>
</ul>
<ul>
<li>Process-oriented</li>
</ul>
<ul>
<li>Concatenative</li>
</ul>
<ul>
<li>Block-structured</li>
<li>Modular (contrast: Monolithic)</li>
<li>Object-oriented (OOP)
<ul>
<li>By separation of concerns:
<ul>
<li>Aspect-oriented</li>
<li>Role-oriented</li>
<li>Subject-oriented</li>
</ul>
</li>
<li>Class-based</li>
<li>Prototype-based</li>
</ul>
</li>
<li>Recursive</li>
</ul>
<ul>
<li>By separation of concerns:
<ul>
<li>Aspect-oriented</li>
<li>Role-oriented</li>
<li>Subject-oriented</li>
</ul>
</li>
<li>Class-based</li>
<li>Prototype-based</li>
</ul>
<ul>
<li>Aspect-oriented</li>
<li>Role-oriented</li>
<li>Subject-oriented</li>
</ul>
<ul>
<li>v</li>
<li>t</li>
<li>e</li>
</ul>
<p><b>Feature Oriented Programming</b> (<b>FOP</b>) or <b>Feature Oriented Software Development</b> (<b>FOSD</b>) is a general paradigm for program synthesis in software product lines.</p>
<p>FOSD arose out of layer-based designs and levels of abstraction in network protocols and extensible database systems in the late-1980s. A program was a stack of layers. Each layer added functionality to previously composed layers and different compositions of layers produced different programs. Not surprisingly, there was a need for a compact language to express such designs. Elementary algebra fit the bill: each layer was function (program transformation) that added new code to an existing program to produce a new program, and a program's design was modeled by an expression, i.e., a composition of transformations (layers). The figure below illustrates the stacking of layers h, j, and i (where h is on the bottom and i is on the top). The algebraic notations i(j(h))and i•j•h express these designs.</p>
<p>Over time, the idea of layers was generalized to features, where a <i><b>feature</b></i> is an increment in program development or functionality. The paradigm for program design and synthesis was recognized to be a generalization of relational query optimization, where query evaluation programs were defined as relational algebra expressions, and query optimization was expression evaluation. A <i><b>software product line (SPL)</b></i> is a family of programs where each program is defined by a unique composition of features, and no two programs have the same combination. FOSD has since evolved into the study of feature modularity, tools, analyses, and design techniques to support feature-based program synthesis.</p>
<p>Further advances in FOSD arose from recognizing the following facts: Every program has multiple representations (e.g., source, makefiles, documentation, etc.) and adding a feature to a program should elaborate each of its representations so that all representations are consistent. Additionally, some of these representations could be generated (or derived) from other representations. In this article, the mathematics of the three most recent generations of FOSD, namely GenVoca, AHEAD, and FOMDD are described, and links to product lines that have been developed using FOSD tools are provided. Also, four additional results that apply to all generations of FOSD are presented elsewhere: MetaModels, Program Cubes, Feature Algebras, and Feature Interactions.</p>
<p></p>
<h2>Contents</h2>
<ul>
<li>1 GenVoca</li>
<li>2 AHEAD</li>
<li>3 FOMDD</li>
<li>4 Applications</li>
<li>5 See also</li>
<li>6 References</li>
</ul>
<p></p>
<h2>GenVoca</h2>
<p><i><b>GenVoca</b></i> (a meld of the names Genesis and Avoca) is a compositional paradigm for defining programs of a product lines. Base programs are 0-ary functions or transformations called <i><b>values</b></i>:</p>
<p>WHATSON? 53995047-24c8-474f-9b70-ada9a2824680</p>
<pre>
  f      -- base program with feature f
  h      -- base program with feature h
</pre>
<p>and features are unary functions/transformations that elaborate (modify, extend, refine) a program:</p>
<p>WHATSON? 79cc394c-e579-4c71-9cbb-9c970601a21f</p>
<pre>
  i • x  -- adds feature i to program x
  j • x  -- adds feature j to program x
</pre>
<p>where • denotes function composition. The <i>design</i> of a program is a named expression, e.g.:</p>
<p>WHATSON? 2961a0ed-1d00-447f-81a8-b06056978c9b</p>
<pre>
  p<sub>1</sub> = j • f       -- program p<sub>1</sub> has features j and f
  p<sub>2</sub> = j • h       -- program p<sub>2</sub> has features j and h
  p<sub>3</sub> = i • j • h   -- program p<sub>3</sub> has features i, j, and h
</pre>
<p>A <i><b>GenVoca model</b></i> of a domain or software product line is a collection of base programs and features (see MetaModels and Program Cubes). The programs (expressions) that can be created defines a product line. Expression optimization is <i>program design optimization</i>, and expression evaluation is <i>program synthesis</i>.</p>
<p>GenVoca features were originally implemented using C preprocessor (<code>#ifdef feature ... #endif</code>) techniques. A more advanced technique, called mixin layers, showed the connection of features to object-oriented collaboration-based designs.</p>
<h2>AHEAD</h2>
<p><i><b>Algebraic Hierarchical Equations for Application Design (AHEAD)</b></i>  generalized GenVoca in two ways. First it revealed the internal structure of GenVoca values as tuples. Every program has multiple representations, such as source, documentation, bytecode, and makefiles. A GenVoca value is a tuple of program representations. In a product line of parsers, for example, a base parser f is defined by its grammar g<sub>f</sub>, Java source s<sub>f</sub>, and documentation d<sub>f</sub>. Program f is modeled by the tuple f=[g<sub>f</sub>, s<sub>f</sub>, d<sub>f</sub>]. Each program representation may have subrepresentations, and they too may have subrepresentations, recursively. In general, a GenVoca value is a tuple of nested tuples that define a hierarchy of representations for a particular program.</p>
<p>Second, AHEAD expresses features as nested tuples of unary functions called <i><b>deltas</b></i>. Deltas can be <i><b>program refinements</b></i> (semantics-preserving transformations), <i><b>extensions</b></i> (semantics-extending transformations), or <i><b>interactions</b></i> (semantics-altering transformations). We use the neutral term “delta” to represent all of these possibilities, as each occurs in FOSD.</p>
<p>To illustrate, suppose feature j extends a grammar by <img class="mwe-math-fallback-image-inline tex" alt="\Delta" src="//upload.wikimedia.org/math/6/5/9/659d23f0ed16cdb87b1d41c7b58b52f4.png">g<sub>j</sub> (new rules and tokens are added), extends source code by <img class="mwe-math-fallback-image-inline tex" alt="\Delta" src="//upload.wikimedia.org/math/6/5/9/659d23f0ed16cdb87b1d41c7b58b52f4.png">s<sub>j</sub> (new classes and members are added and existing methods are modified), and extends documentation by <img class="mwe-math-fallback-image-inline tex" alt="\Delta" src="//upload.wikimedia.org/math/6/5/9/659d23f0ed16cdb87b1d41c7b58b52f4.png">d<sub>j</sub>. The tuple of deltas for feature j is modeled by j=[<img class="mwe-math-fallback-image-inline tex" alt="\Delta" src="//upload.wikimedia.org/math/6/5/9/659d23f0ed16cdb87b1d41c7b58b52f4.png">g<sub>j</sub>,<img class="mwe-math-fallback-image-inline tex" alt="\Delta" src="//upload.wikimedia.org/math/6/5/9/659d23f0ed16cdb87b1d41c7b58b52f4.png">s<sub>j</sub>,<img class="mwe-math-fallback-image-inline tex" alt="\Delta" src="//upload.wikimedia.org/math/6/5/9/659d23f0ed16cdb87b1d41c7b58b52f4.png">d<sub>j</sub>], which we call a <i><b>delta tuple</b></i>. Elements of delta tuples can themselves be delta tuples. As an example, <img class="mwe-math-fallback-image-inline tex" alt="\Delta" src="//upload.wikimedia.org/math/6/5/9/659d23f0ed16cdb87b1d41c7b58b52f4.png">s<sub>j</sub> represents the changes that are made to each class in s<sub>f</sub> by feature j, i.e., <img class="mwe-math-fallback-image-inline tex" alt="\Delta" src="//upload.wikimedia.org/math/6/5/9/659d23f0ed16cdb87b1d41c7b58b52f4.png">s<sub>j</sub>=[<img class="mwe-math-fallback-image-inline tex" alt="\Delta" src="//upload.wikimedia.org/math/6/5/9/659d23f0ed16cdb87b1d41c7b58b52f4.png">c<sub>1</sub>…<img class="mwe-math-fallback-image-inline tex" alt="\Delta" src="//upload.wikimedia.org/math/6/5/9/659d23f0ed16cdb87b1d41c7b58b52f4.png">c<sub>n</sub>]. The representations of a program are computed recursively by composing tuples element-wise. The representations for parser p (whose GenVoca expression is j•f) are:</p>
<p>WHATSON? 6d073256-fa12-45a2-8886-4893ee196cd4</p>
<pre>
  p<sub>2</sub> = j • f                            -- GenVoca expression
     = [<img class="mwe-math-fallback-image-inline tex" alt="\Delta" src="//upload.wikimedia.org/math/6/5/9/659d23f0ed16cdb87b1d41c7b58b52f4.png">g<sub>j</sub>, <img class="mwe-math-fallback-image-inline tex" alt="\Delta" src="//upload.wikimedia.org/math/6/5/9/659d23f0ed16cdb87b1d41c7b58b52f4.png">s<sub>j</sub>, <img class="mwe-math-fallback-image-inline tex" alt="\Delta" src="//upload.wikimedia.org/math/6/5/9/659d23f0ed16cdb87b1d41c7b58b52f4.png">d<sub>j</sub>] • [g<sub>f</sub>, s<sub>f</sub>, d<sub>f</sub>]   -- substitution
     = [<img class="mwe-math-fallback-image-inline tex" alt="\Delta" src="//upload.wikimedia.org/math/6/5/9/659d23f0ed16cdb87b1d41c7b58b52f4.png">g<sub>j</sub>•g<sub>f</sub>, <img class="mwe-math-fallback-image-inline tex" alt="\Delta" src="//upload.wikimedia.org/math/6/5/9/659d23f0ed16cdb87b1d41c7b58b52f4.png">s<sub>j</sub>•s<sub>f</sub>, <img class="mwe-math-fallback-image-inline tex" alt="\Delta" src="//upload.wikimedia.org/math/6/5/9/659d23f0ed16cdb87b1d41c7b58b52f4.png">d<sub>j</sub>•d<sub>f</sub>]         -- compose tuples element-wise
</pre>
<p>That is, the grammar of p is the base grammar composed with its extension (<img class="mwe-math-fallback-image-inline tex" alt="\Delta" src="//upload.wikimedia.org/math/6/5/9/659d23f0ed16cdb87b1d41c7b58b52f4.png">g<sub>j</sub>•g<sub>f</sub>), the source of p is the base source composed with its extension (<img class="mwe-math-fallback-image-inline tex" alt="\Delta" src="//upload.wikimedia.org/math/6/5/9/659d23f0ed16cdb87b1d41c7b58b52f4.png">s<sub>j</sub>•s<sub>f</sub>), and so on. As elements of delta tuples can themselves be delta tuples, composition recurses, e.g., <img class="mwe-math-fallback-image-inline tex" alt="\Delta" src="//upload.wikimedia.org/math/6/5/9/659d23f0ed16cdb87b1d41c7b58b52f4.png">s<sub>j</sub>•s<sub>f</sub>= [<img class="mwe-math-fallback-image-inline tex" alt="\Delta" src="//upload.wikimedia.org/math/6/5/9/659d23f0ed16cdb87b1d41c7b58b52f4.png">c<sub>1</sub>…<img class="mwe-math-fallback-image-inline tex" alt="\Delta" src="//upload.wikimedia.org/math/6/5/9/659d23f0ed16cdb87b1d41c7b58b52f4.png">c<sub>n</sub>]•[c<sub>1</sub>…c<sub>n</sub>]=[<img class="mwe-math-fallback-image-inline tex" alt="\Delta" src="//upload.wikimedia.org/math/6/5/9/659d23f0ed16cdb87b1d41c7b58b52f4.png">c<sub>1</sub>•c<sub>1</sub>…<img class="mwe-math-fallback-image-inline tex" alt="\Delta" src="//upload.wikimedia.org/math/6/5/9/659d23f0ed16cdb87b1d41c7b58b52f4.png">c<sub>n</sub>•c<sub>n</sub>]. Summarizing, GenVoca values are nested tuples of program artifacts, and features are nested delta tuples, where • recursively composes them. This is the essence of AHEAD.</p>
<p>The ideas presented above concretely expose two FOSD principles. The <i><b>Principle of Uniformity</b></i> states that all program artifacts are treated and refined in the same way. (This is evidenced by deltas for different artifact types above). The <i><b>Principle of Scalability</b></i> states all levels of abstractions are treated uniformly. (This gives rise to the hierarchical nesting of tuples above).</p>
<p>The original implementation of AHEAD is the AHEAD Tool Suite and Jak language, which exhibits both the Principles of Uniformity and Scalability. Next-generation tools include CIDE  and FeatureHouse.</p>
<h2>FOMDD</h2>
<p><i><b>Feature Oriented Model Driven Design (FOMDD)</b></i>  combines the ideas of AHEAD with <i><b>Model Driven Design (MDD)</b></i> (a.k.a. <i><b>Model-Driven Architecture (MDA)</b></i>). AHEAD functions capture the lockstep update of program artifacts when a feature is added to a program. But there are other functional relationships among program artifacts that express derivations. For example, the relationship between a grammar g<sub>f</sub> and its parser source s<sub>f</sub> is defined by a compiler-compiler tool, e.g., javacc. Similarly, the relationship between Java source s<sub>f</sub> and its bytecode b<sub>f</sub> is defined by the javac compiler. A commuting diagram expresses these relationships. Objects are program representations, downward arrows are derivations, and horizontal arrows are deltas. The figure to the right shows the commuting diagram for program p<sub>3</sub> = i•j•h = [g<sub>3</sub>,s<sub>3</sub>,b<sub>3</sub>].</p>
<p>A fundamental property of a commuting diagram is that all paths between two objects are equivalent. For example, one way to derive the bytecode b<sub>3</sub> of parser p<sub>3</sub> (lower right object in the above figure) from grammar g<sub>f</sub> of parser f (upper left object) is to derive the bytecode b<sub>f</sub> and refine to b<sub>3</sub>, while another way refines g<sub>f</sub> to g<sub>3</sub>, and then derive b<sub>3</sub>:</p>
<p>WHATSON? 2527987c-2796-47d8-8b33-a4564ef51ae2</p>
<pre>
  <img class="mwe-math-fallback-image-inline tex" alt="\Delta" src="//upload.wikimedia.org/math/6/5/9/659d23f0ed16cdb87b1d41c7b58b52f4.png">b<sub>i</sub> • <img class="mwe-math-fallback-image-inline tex" alt="\Delta" src="//upload.wikimedia.org/math/6/5/9/659d23f0ed16cdb87b1d41c7b58b52f4.png">b<sub>j</sub> • javac • javacc = javac • javacc • <img class="mwe-math-fallback-image-inline tex" alt="\Delta" src="//upload.wikimedia.org/math/6/5/9/659d23f0ed16cdb87b1d41c7b58b52f4.png">g<sub>i</sub> • <img class="mwe-math-fallback-image-inline tex" alt="\Delta" src="//upload.wikimedia.org/math/6/5/9/659d23f0ed16cdb87b1d41c7b58b52f4.png">g<sub>j</sub>
</pre>
<p>There are <img class="mwe-math-fallback-image-inline tex" alt="\tbinom{4}{2}" src="//upload.wikimedia.org/math/0/a/4/0a4cbf3d399078c07acc5b12989ff355.png"> possible paths to derive the bytecode b<sub>3</sub> of parser p<sub>3</sub> from the grammar g<sub>f</sub> of parser f. Each path represents a metaprogram whose execution synthesizes the target object (b<sub>3</sub>) from the starting object (g<sub>f</sub>). There is a potential optimization: traversing each arrow of a commuting diagram has a cost. The cheapest (i.e., shortest) path between two objects in a commuting diagram is a <i><b>geodesic</b></i>, which represents the most efficient metaprogram that produces the target object from a given object.</p>
<p>Commuting diagrams are important for at least two reasons: (1) there is the possibility of optimizing the synthesis of artifacts (e.g., geodesics) and (2) they specify different ways of constructing a target object from a starting object. A path through a diagram corresponds to a tool chain: for an FOMDD model to be consistent, it should be proven (or demonstrated through testing) that all tool chains that map one object to another in fact yield equivalent results. (If different paths/tool chains yield different results, then either there is a bug in one or more of the tools or the FOMDD model is wrong).</p>
<h2>Applications</h2>
<ul>
<li>Network Protocols</li>
<li>Extensible Database Systems</li>
<li>Data Structures</li>
<li>Distributed Army Fire Support Simulator</li>
<li>Production System Compiler</li>
<li>Graph Product Line</li>
<li>Extensible Java Preprocessors</li>
<li>Web Portlets</li>
<li>SVG Applications</li>
</ul>
<h2>See also</h2>
<ul>
<li>FOSD MetaModels—product lines of product lines</li>
<li>FOSD Program Cubes—multi-dimensional product lines</li>
<li>FOSD Feature Algebras—basic operations from which FOSD features (0-ary and 1-ary) functions are defined</li>
<li>FOSD Feature Interactions—general concepts for feature interactions</li>
</ul>
</body>
</html>