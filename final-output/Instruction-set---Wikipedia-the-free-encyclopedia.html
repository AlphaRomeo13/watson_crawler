<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Instruction-set---Wikipedia-the-free-encyclopedia.html</title></head>
<body>
<h1>Instruction set</h1>
<p>An <b>instruction set</b>, or <b>instruction set architecture</b> (<b>ISA</b>), is the part of the computer architecture related to programming, including the native data types, instructions, registers, addressing modes, memory architecture, interrupt and exception handling, and external I/O. An ISA includes a specification of the set of opcodes (machine language), and the native commands implemented by a particular processor.</p>
<p></p>
<h2>Contents</h2>
<ul>
<li>1 Overview</li>
<li>2 Classification of instruction sets</li>
<li>3 Machine language
<ul>
<li>3.1 Instruction types
<ul>
<li>3.1.1 Data handling and memory operations</li>
<li>3.1.2 Arithmetic and logic operations</li>
<li>3.1.3 Control flow operations</li>
</ul>
</li>
<li>3.2 Complex instructions</li>
<li>3.3 Parts of an instruction</li>
<li>3.4 Instruction length</li>
<li>3.5 Representation</li>
<li>3.6 Design</li>
</ul>
</li>
<li>4 Instruction set implementation
<ul>
<li>4.1 Code density</li>
<li>4.2 Number of operands</li>
<li>4.3 Register pressure</li>
</ul>
</li>
<li>5 See also
<ul>
<li>5.1 Categories of ISA</li>
</ul>
</li>
<li>6 References</li>
<li>7 Further reading</li>
<li>8 External links</li>
</ul>
<ul>
<li>3.1 Instruction types
<ul>
<li>3.1.1 Data handling and memory operations</li>
<li>3.1.2 Arithmetic and logic operations</li>
<li>3.1.3 Control flow operations</li>
</ul>
</li>
<li>3.2 Complex instructions</li>
<li>3.3 Parts of an instruction</li>
<li>3.4 Instruction length</li>
<li>3.5 Representation</li>
<li>3.6 Design</li>
</ul>
<ul>
<li>3.1.1 Data handling and memory operations</li>
<li>3.1.2 Arithmetic and logic operations</li>
<li>3.1.3 Control flow operations</li>
</ul>
<ul>
<li>4.1 Code density</li>
<li>4.2 Number of operands</li>
<li>4.3 Register pressure</li>
</ul>
<ul>
<li>5.1 Categories of ISA</li>
</ul>
<p></p>
<h2>Overview</h2>
<p>Instruction set architecture is distinguished from the microarchitecture, which is the set of processor design techniques used to implement the instruction set. Computers with different microarchitectures can share a common instruction set. For example, the Intel Pentium and the AMD Athlon implement nearly identical versions of the x86 instruction set, but have radically different internal designs.</p>
<p>The concept of an <i>architecture</i>, distinct from the design of a specific machine, was developed by Fred Brooks at IBM during the design phase of System/360.</p>
<p>Prior to NPL [System/360], the company's computer designers had been free to honor cost objectives not only by selecting technologies but also by fashioning functional and architectural refinements. The SPREAD compatibility objective, in contrast, postulated a single architecture for a series of five processors spanning a wide range of cost and performance. None of the five engineering design teams could count on being able to bring about adjustments in architectural specifications as a way of easing difficulties in achieving cost and performance objectives.</p>
<p>Some virtual machines that support bytecode as their ISA such as Smalltalk, the Java virtual machine, and Microsoft's Common Language Runtime, implement this by translating the bytecode for commonly used code paths into native machine code. In addition, these virtual machines execute less frequently used code paths by interpretation (see: Just-in-time compilation). Transmeta implemented the x86 instruction set atop VLIW processors in this fashion.</p>
<h2>Classification of instruction sets</h2>
<p>A complex instruction set computer (CISC) has many specialized instructions, some of which may only be rarely used in practical programs. A reduced instruction set computer (RISC) simplifies the processor by only implementing instructions that are frequently used in programs; unusual operations are implemented as subroutines, where the extra processor execution time is offset by their rare use. Theoretically important types are the minimal instruction set computer and the one instruction set computer, but these are not implemented in commercial processors. Another variation is the very long instruction word (VLIW) where the processor receives many instructions encoded and retrieved in one instruction word.</p>
<h2>Machine language</h2>
<p>Machine language is built up from discrete <i>statements</i> or <i>instructions</i>. On the processing architecture, a given instruction may specify:</p>
<ul>
<li>Particular registers for arithmetic, addressing, or control functions</li>
<li>Particular memory locations or offsets</li>
<li>Particular addressing modes used to interpret the operands</li>
</ul>
<p>More complex operations are built up by combining these simple instructions, which are executed sequentially, or as otherwise directed by control flow instructions.</p>
<h3>Instruction types</h3>
<p>Examples of operations common to many instruction sets include:</p>
<h4>Data handling and memory operations</h4>
<ul>
<li><i>Set</i> a register to a fixed constant value.</li>
<li><i>Move</i> data from a memory location to a register, or vice versa. Used to store the contents of a register, result of a computation, or to retrieve stored data to perform a computation on it later.</li>
<li><i>Read</i> and <i>write</i> data from hardware devices.</li>
</ul>
<h4>Arithmetic and logic operations</h4>
<ul>
<li><i>Add</i>, <i>subtract</i>, <i>multiply</i>, or <i>divide</i> the values of two registers, placing the result in a register, possibly setting one or more condition codes in a status register.</li>
<li>Perform bitwise operations, e.g., taking the <i>conjunction</i> and <i>disjunction</i> of corresponding bits in a pair of registers, taking the <i>negation</i> of each bit in a register.</li>
<li><i>Compare</i> two values in registers (for example, to see if one is less, or if they are equal).</li>
</ul>
<h4>Control flow operations</h4>
<ul>
<li><i>Branch</i> to another location in the program and execute instructions there.</li>
<li><i>Conditionally branch</i> to another location if a certain condition holds.</li>
<li><i>Indirectly branch</i> to another location, while saving the location of the next instruction as a point to return to (a <i>call</i>).</li>
</ul>
<h3>Complex instructions</h3>
<p>CISC processors include "complex" instructions in their instruction set. A single "complex" instruction does something that may take many instructions on other computers. Such instructions are typified by instructions that take multiple steps, control multiple functional units, or otherwise appear on a larger scale than the bulk of simple instructions implemented by the given processor. Some examples of "complex" instructions include:</p>
<ul>
<li>Saving many registers on the stack at once.</li>
<li>Moving large blocks of memory.</li>
<li>complicated integer and floating-point arithmetic (sine, cosine, square root, etc.).</li>
<li>SIMD instructions, a single instruction performing an operation on many values in parallel.</li>
<li>Performing an atomic test-and-set instruction or other read-modify-write atomic instruction.</li>
<li>Instructions that perform ALU operations with an operand from memory rather than a register.</li>
</ul>
<p>A complex instruction type that has become particularly popular recently is the SIMD or Single-Instruction Stream Multiple-Data Stream operation or vector instruction, that is an operation that performs the same arithmetic operation on multiple pieces of data at the same time. SIMD have the ability of manipulating large vectors and matrices in minimal time. SIMD instructions allow easy parallelization of algorithms commonly involved in sound, image, and video processing. Various SIMD implementations have been brought to market under trade names such as MMX, 3DNow! and AltiVec.</p>
<p>Specialised processor types like GPUs for example also provide complex instruction sets. Nonetheless many of these specialised processor complex instruction sets do not have a publicly available native instruction set and native assembly language for proprietary hardware related reasons and are usually only accessible to software developers through standardized higher level languages and APIs. The OpenGL virtual instruction set and virtual assembly language ARB assembly language and CUDA are examples of such hardware abstraction layers on top of the specialised processor native instruction set.</p>
<h3>Parts of an instruction</h3>
<p>On traditional architectures, an instruction includes an opcode that specifies the operation to perform, such as <i>add contents of memory to register</i>â€”and zero or more operand specifiers, which may specify registers, memory locations, or literal data. The operand specifiers may have addressing modes determining their meaning or may be in fixed fields. In very long instruction word (VLIW) architectures, which include many microcode architectures, multiple simultaneous opcodes and operands are specified in a single instruction.</p>
<p>Some exotic instruction sets do not have an opcode field (such as Transport Triggered Architectures (TTA) or the Forth virtual machine), only operand(s). Other unusual "0-operand" instruction sets lack any operand specifier fields, such as some stack machines including NOSC.</p>
<h3>Instruction length</h3>
<p>The size or length of an instruction varies widely, from as little as four bits in some microcontrollers to many hundreds of bits in some VLIW systems. Processors used in personal computers, mainframes, and supercomputers have instruction sizes between 8 and 64 bits. The longest possible instruction on x86 is 15 bytes (120 bits). Within an instruction set, different instructions may have different lengths. In some architectures, notably most reduced instruction set computers (RISC), instructions are a fixed length, typically corresponding with that architecture's word size. In other architectures, instructions have variable length, typically integral multiples of a byte or a halfword. Some such as the ARM with <i>Thumb-extension</i> have <i>mixed</i> variable encoding, that is two fixed, usually 32-bit and 16-bit encodings, where instructions can not be mixed freely but must be switched between on a branch (or exception boundary in ARMv8).</p>
<p>A RISC instruction set normally has a fixed instruction width (often 4 bytes = 32 bits), whereas a typical CISC instruction set may have instructions of widely varying length (1 to 15 bytes for x86). Fixed-width instructions are less complicated to handle than variable-width instructions for several reasons (not having to check whether an instruction straddles a cache line or virtual memory page boundary for instance), and are therefore somewhat easier to optimize for speed.</p>
<h3>Representation</h3>
<p>The instructions constituting a program are rarely specified using their internal, numeric form (machine code); they may be specified by programmers using an assembly language or, more commonly, may be generated from programming languages by compilers.</p>
<h3>Design</h3>
<p>The design of instruction sets is a complex issue. There were two stages in history for the microprocessor. The first was the CISC (Complex Instruction Set Computer), which had many different instructions. In the 1970s, however, places like IBM did research and found that many instructions in the set could be eliminated. The result was the RISC (Reduced Instruction Set Computer), an architecture that uses a smaller set of instructions. A simpler instruction set may offer the potential for higher speeds, reduced processor size, and reduced power consumption. However, a more complex set may optimize common operations, improve memory/cache efficiency, or simplify programming.</p>
<p>Some instruction set designers reserve one or more opcodes for some kind of system call or software interrupt. For example, MOS Technology 6502 uses 00<sub>H</sub>, Zilog Z80 uses the eight codes C7,CF,D7,DF,E7,EF,F7,FF<sub>H</sub> while Motorola 68000 use codes in the range A000..AFFF<sub>H</sub>.</p>
<p>Fast virtual machines are much easier to implement if an instruction set meets the Popek and Goldberg virtualization requirements.</p>
<p>The NOP slide used in Immunity Aware Programming is much easier to implement if the "unprogrammed" state of the memory is interpreted as a NOP.</p>
<p>On systems with multiple processors, non-blocking synchronization algorithms are much easier to implement if the instruction set includes support for something such as "fetch-and-add", "load-link/store-conditional" (LL/SC), or "atomic compare and swap".</p>
<h2>Instruction set implementation</h2>
<p>Any given instruction set can be implemented in a variety of ways. All ways of implementing a particular instruction set provide the same programming model, and all implementations of that instruction set are able to run the same binary executables. The various ways of implementing an instruction set give different tradeoffs between cost, performance, power consumption, size, etc.</p>
<p>When designing the microarchitecture of a processor, engineers use blocks of "hard-wired" electronic circuitry (often designed separately) such as adders, multiplexers, counters, registers, ALUs etc. Some kind of register transfer language is then often used to describe the decoding and sequencing of each instruction of an ISA using this physical microarchitecture. There are two basic ways to build a control unit to implement this description (although many designs use middle ways or compromises):</p>
<ol>
<li>Some computer designs "hardwire" the complete instruction set decoding and sequencing (just like the rest of the microarchitecture).</li>
<li>Other designs employ microcode routines or tables (or both) to do thisâ€”typically as on-chip ROMs or PLAs or both (although separate RAMs and ROMs have been used historically).</li>
</ol>
<p>Some designs use a combination of hardwired design and microcode for the control unit.</p>
<p>Some CPU designs compile the instruction set to a writable RAM or flash inside the CPU (such as the Rekursiv processor and the Imsys Cjip), or an FPGA (reconfigurable computing). The Western Digital MCP-1600 is an older example, using a dedicated, separate ROM for microcode.</p>
<p>An ISA can also be emulated in software by an interpreter. Naturally, due to the interpretation overhead, this is slower than directly running programs on the emulated hardware, unless the hardware running the emulator is an order of magnitude faster. Today, it is common practice for vendors of new ISAs or microarchitectures to make software emulators available to software developers before the hardware implementation is ready.</p>
<p>Often the details of the implementation have a strong influence on the particular instructions selected for the instruction set. For example, many implementations of the instruction pipeline only allow a single memory load or memory store per instruction, leading to a load-store architecture (RISC). For another example, some early ways of implementing the instruction pipeline led to a delay slot.</p>
<p>The demands of high-speed digital signal processing have pushed in the opposite directionâ€”forcing instructions to be implemented in a particular way. For example, to perform digital filters fast enough, the MAC instruction in a typical digital signal processor (DSP) must use a kind of Harvard architecture that can fetch an instruction and two data words simultaneously, and it requires a single-cycle multiplyâ€“accumulate multiplier.</p>
<h3>Code density</h3>
<p>In early computers, memory was expensive, so minimizing the size of a program to make sure it would fit in the limited memory was often central. Thus the combined size of all the instructions needed to perform a particular task, the <i>code density</i>, was an important characteristic of any instruction set. Computers with high code density often have complex instructions for procedure entry, parameterized returns, loops etc. (therefore retroactively named <i>Complex Instruction Set Computers</i>, CISC). However, more typical, or frequent, "CISC" instructions merely combine a basic ALU operation, such as "add", with the access of one or more operands in memory (using addressing modes such as direct, indirect, indexed etc.). Certain architectures may allow two or three operands (including the result) directly in memory or may be able to perform functions such as automatic pointer increment etc. Software-implemented instruction sets may have even more complex and powerful instructions.</p>
<p><i>Reduced instruction-set computers</i>, RISC, were first widely implemented during a period of rapidly growing memory subsystems. They sacrifice code density to simplify implementation circuitry, and try to increase performance via higher clock frequencies and more registers. A single RISC instruction typically performs only a single operation, such as an "add" of registers or a "load" from a memory location into a register. A RISC instruction set normally has a fixed instruction width, whereas a typical CISC instruction set has instructions of widely varying length. However, as RISC computers normally require more and often longer instructions to implement a given task, they inherently make less optimal use of bus bandwidth and cache memories.</p>
<p>Certain embedded RISC ISAs like Thumb and AVR32 typically exhibit very high density owing to a technique called code compression. This technique packs two 16-bit instructions into one 32-bit instruction, which is then unpacked at the decode stage and executed as two instructions.</p>
<p>Minimal instruction set computers (MISC) are a form of stack machine, where there are few separate instructions (16-64), so that multiple instructions can be fit into a single machine word. These type of cores often take little silicon to implement, so they can be easily realized in an FPGA or in a multi-core form. The code density of MISC is similar to the code density of RISC; the increased instruction density is offset by requiring more of the primitive instructions to do a task.</p>
<p>There has been research into executable compression as a mechanism for improving code density. The mathematics of Kolmogorov complexity describes the challenges and limits of this.</p>
<h3>Number of operands</h3>
<p>Instruction sets may be categorized by the maximum number of operands <i>explicitly</i> specified in instructions.</p>
<p>(In the examples that follow, <i>a</i>, <i>b</i>, and <i>c</i> are (direct or calculated) addresses referring to memory cells, while <i>reg1</i> and so on refer to machine registers.)</p>
<p><code>C = A+B</code></p>
<ul>
<li>0-operand (<i>zero-address machines</i>), so called stack machines: All arithmetic operations take place using the top one or two positions on the stack: <b>push</b> <i>a</i>, <b>push</b> <i>b</i>, <b>add</b>, <b>pop</b> <i>c</i>.
<ul>
<li><i>C = A+B</i> needs <b>4 instructions</b>. For stack machines, the terms "0-operand" and "zero-address" apply to arithmetic instructions, but not to all instructions, as 1-operand push and pop instructions are used to access memory.</li>
</ul>
</li>
<li>1-operand (<i>one-address machines</i>), so called accumulator machines, include early computers and many small microcontrollers: most instructions specify a single right operand (that is, constant, a register, or a memory location), with the implicit accumulator as the left operand (and the destination if there is one): <b>load</b> <i>a</i>, <b>add</b> <i>b</i>, <b>store</b> <i>c</i>.
<ul>
<li><i>C = A+B</i> needs <b>3 instructions</b>.</li>
</ul>
</li>
<li>2-operand â€” many CISC and RISC machines fall under this category:
<ul>
<li>CISC â€” <b>move</b> <i>A</i> to <i>C</i>; then <b>add</b> <i>B</i> to <i>C</i>.
<ul>
<li><i>C = A+B</i> needs <b>2 instructions</b>. This effectively 'stores' the result without an explicit <i>store</i> instruction.</li>
<li>CISC â€” Often machines are limited to one memory operand per instruction: <b>load</b> <i>a,reg1</i>; <b>add</b> <i>b,reg1</i>; <b>store</b> <i>reg1,c</i>; This requires a load/store pair for any memory movement regardless of whether the <b>add</b> result is an augmentation stored to a different place, as in C = A+B, or the same memory location: A = A+B.
<ul>
<li><i>C = A+B</i> needs <b>3 instructions</b>.</li>
</ul>
</li>
</ul>
</li>
<li>RISC â€” Requiring explicit memory loads, the instructions would be: <b>load</b> <i>a,reg1</i>; <b>load</b> <i>b,reg2</i>; <b>add</b> <i>reg1,reg2</i>; <b>store</b> <i>reg2,c</i>.
<ul>
<li><i>C = A+B</i> needs <b>4 instructions</b>.</li>
</ul>
</li>
</ul>
</li>
<li>3-operand, allowing better reuse of data:
<ul>
<li>CISC â€” It becomes either a single instruction:<b>add</b> <i>a,b,c</i>
<ul>
<li><i>C = A+B</i> needs <b>1 instruction</b>.</li>
<li>or more typically: <b>move</b> <i>a,reg1</i>; <b>add</b> <i>reg1,b,c</i> as most machines are limited to two memory operands.
<ul>
<li><i>C = A+B</i> needs <b>2 instructions</b>.</li>
</ul>
</li>
</ul>
</li>
<li>RISC â€” arithmetic instructions use registers only, so explicit 2-operand load/store instructions are needed: <b>load</b> <i>a,reg1</i>; <b>load</b> <i>b,reg2</i>; <b>add</b> <i>reg1+reg2-&gt;reg3</i>; <b>store</b> <i>reg3,c</i>;
<ul>
<li><i>C = A+B</i> needs <b>4 instructions</b>.</li>
<li>Unlike 2-operand or 1-operand, this leaves all three values a, b, and c in registers available for further reuse.</li>
</ul>
</li>
</ul>
</li>
<li>more operandsâ€”some CISC machines permit a variety of addressing modes that allow more than 3 operands (registers or memory accesses), such as the VAX "POLY" polynomial evaluation instruction.</li>
</ul>
<ul>
<li><i>C = A+B</i> needs <b>4 instructions</b>. For stack machines, the terms "0-operand" and "zero-address" apply to arithmetic instructions, but not to all instructions, as 1-operand push and pop instructions are used to access memory.</li>
</ul>
<ul>
<li><i>C = A+B</i> needs <b>3 instructions</b>.</li>
</ul>
<ul>
<li>CISC â€” <b>move</b> <i>A</i> to <i>C</i>; then <b>add</b> <i>B</i> to <i>C</i>.
<ul>
<li><i>C = A+B</i> needs <b>2 instructions</b>. This effectively 'stores' the result without an explicit <i>store</i> instruction.</li>
<li>CISC â€” Often machines are limited to one memory operand per instruction: <b>load</b> <i>a,reg1</i>; <b>add</b> <i>b,reg1</i>; <b>store</b> <i>reg1,c</i>; This requires a load/store pair for any memory movement regardless of whether the <b>add</b> result is an augmentation stored to a different place, as in C = A+B, or the same memory location: A = A+B.
<ul>
<li><i>C = A+B</i> needs <b>3 instructions</b>.</li>
</ul>
</li>
</ul>
</li>
<li>RISC â€” Requiring explicit memory loads, the instructions would be: <b>load</b> <i>a,reg1</i>; <b>load</b> <i>b,reg2</i>; <b>add</b> <i>reg1,reg2</i>; <b>store</b> <i>reg2,c</i>.
<ul>
<li><i>C = A+B</i> needs <b>4 instructions</b>.</li>
</ul>
</li>
</ul>
<ul>
<li><i>C = A+B</i> needs <b>2 instructions</b>. This effectively 'stores' the result without an explicit <i>store</i> instruction.</li>
<li>CISC â€” Often machines are limited to one memory operand per instruction: <b>load</b> <i>a,reg1</i>; <b>add</b> <i>b,reg1</i>; <b>store</b> <i>reg1,c</i>; This requires a load/store pair for any memory movement regardless of whether the <b>add</b> result is an augmentation stored to a different place, as in C = A+B, or the same memory location: A = A+B.
<ul>
<li><i>C = A+B</i> needs <b>3 instructions</b>.</li>
</ul>
</li>
</ul>
<ul>
<li><i>C = A+B</i> needs <b>3 instructions</b>.</li>
</ul>
<ul>
<li><i>C = A+B</i> needs <b>4 instructions</b>.</li>
</ul>
<ul>
<li>CISC â€” It becomes either a single instruction:<b>add</b> <i>a,b,c</i>
<ul>
<li><i>C = A+B</i> needs <b>1 instruction</b>.</li>
<li>or more typically: <b>move</b> <i>a,reg1</i>; <b>add</b> <i>reg1,b,c</i> as most machines are limited to two memory operands.
<ul>
<li><i>C = A+B</i> needs <b>2 instructions</b>.</li>
</ul>
</li>
</ul>
</li>
<li>RISC â€” arithmetic instructions use registers only, so explicit 2-operand load/store instructions are needed: <b>load</b> <i>a,reg1</i>; <b>load</b> <i>b,reg2</i>; <b>add</b> <i>reg1+reg2-&gt;reg3</i>; <b>store</b> <i>reg3,c</i>;
<ul>
<li><i>C = A+B</i> needs <b>4 instructions</b>.</li>
<li>Unlike 2-operand or 1-operand, this leaves all three values a, b, and c in registers available for further reuse.</li>
</ul>
</li>
</ul>
<ul>
<li><i>C = A+B</i> needs <b>1 instruction</b>.</li>
<li>or more typically: <b>move</b> <i>a,reg1</i>; <b>add</b> <i>reg1,b,c</i> as most machines are limited to two memory operands.
<ul>
<li><i>C = A+B</i> needs <b>2 instructions</b>.</li>
</ul>
</li>
</ul>
<ul>
<li><i>C = A+B</i> needs <b>2 instructions</b>.</li>
</ul>
<ul>
<li><i>C = A+B</i> needs <b>4 instructions</b>.</li>
<li>Unlike 2-operand or 1-operand, this leaves all three values a, b, and c in registers available for further reuse.</li>
</ul>
<p>Due to the large number of bits needed to encode the three registers of a 3-operand instruction, RISC processors using 16-bit instructions are invariably 2-operand machines, such as the Atmel AVR, the TI MSP430, and some versions of the ARM Thumb. RISC processors using 32-bit instructions are usually 3-operand machines, such as processors implementing the Power Architecture, the SPARC architecture, the MIPS architecture, the ARM architecture, and the AVR32 architecture.</p>
<p>Each instruction specifies some number of operands (registers, memory locations, or immediate values) <i>explicitly</i>. Some instructions give one or both operands implicitly, such as by being stored on top of the stack or in an implicit register. If some of the operands are given implicitly, fewer operands need be specified in the instruction. When a "destination operand" explicitly specifies the destination, an additional operand must be supplied. Consequently, the number of operands encoded in an instruction may differ from the mathematically necessary number of arguments for a logical or arithmetic operation (the arity). Operands are either encoded in the "opcode" representation of the instruction, or else are given as values or addresses following the instruction.</p>
<h3>Register pressure</h3>
<p><i>Register pressure</i> is defined as the number of free architectural registers available to use at any given point of time in a program's execution. The number of programmable registers is inversely proportional to the amount of register pressure for any ISA. Register pressure is critical because the higher the register pressure, the more register spills and more trips to the memory.</p>
<p>While embedded RISC ISAs like Thumb suffer from extremely high register pressure due to lack of available programmable registers, general-purpose RISC ISAs like MIPS and Alpha enjoy low register pressure. Interestingly, CISC ISAs like x86-64 offer low register pressure despite the fact that they have fewer programmable registers. This is a manifestation of the many addressing modes and optimizations such as sub-register addressing, absolute addressing, PC-relative addressing, and register-to-register spills, which these ISAs offer.</p>
<h2>See also</h2>
<ul>
<li>Comparison of CPU architectures</li>
<li>Computer architecture</li>
<li>CPU design</li>
<li>Emulator</li>
<li>Instruction set simulator</li>
<li>OVPsim full systems simulator providing ability to create/model/emulate any instruction set using C and standard APIs</li>
<li>Register transfer language (RTL)</li>
<li>List of instruction sets</li>
</ul>
<h3>Categories of ISA</h3>
<ul>
<li>EPIC: Explicitly Parallel Instruction Computing</li>
<li>Vector processor</li>
<li>SIMD: Single Instruction Multiple Data</li>
<li>Flynn's Taxonomy</li>
<li>Orthogonal instruction set</li>
</ul>
</body>
</html>