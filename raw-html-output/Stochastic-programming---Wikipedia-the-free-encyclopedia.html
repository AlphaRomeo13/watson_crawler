<h1 id="firstHeading" class="firstHeading" lang="en"><span dir="auto">Stochastic programming</span></h1>
<p>In the field of <a href="/wiki/Mathematical_optimization" title="Mathematical optimization">mathematical optimization</a>, <b>stochastic programming</b> is a framework for <a href="/wiki/Mathematical_model" title="Mathematical model">modeling</a> <a href="/wiki/Optimization_(mathematics)" title="Optimization (mathematics)" class="mw-redirect">optimization</a> problems that involve <a href="/wiki/Uncertainty" title="Uncertainty">uncertainty</a>. Whereas deterministic optimization problems are formulated with known parameters, real world problems almost invariably include some unknown parameters. When the parameters are known only within certain bounds, one approach to tackling such problems is called <a href="/wiki/Robust_optimization" title="Robust optimization">robust optimization</a>. Here the goal is to find a solution which is feasible for all such data and <a href="/wiki/Optimization_(mathematics)" title="Optimization (mathematics)" class="mw-redirect">optimal</a> in some sense. <a href="/wiki/Stochastic" title="Stochastic">Stochastic</a> programming <a href="/wiki/Mathematical_model" title="Mathematical model">models</a> are similar in style but take advantage of the fact that <a href="/wiki/Probability_distributions" title="Probability distributions" class="mw-redirect">probability distributions</a> governing the data are known or can be estimated. The goal here is to find some policy that is feasible for all (or almost all) the possible data instances and maximizes the expectation of some function of the decisions and the <a href="/wiki/Random_variable" title="Random variable">random variables</a>. More generally, such models are formulated, solved analytically or numerically, and analyzed in order to provide useful information to a decision-maker.<sup id="cite_ref-1" class="reference"><a href="#cite_note-1"><span>[</span>1<span>]</span></a></sup></p>
<p>As an example, consider two-stage <a href="/wiki/Linear_program" title="Linear program" class="mw-redirect">linear programs</a>. Here the decision maker takes some action in the first stage, after which a random event occurs affecting the outcome of the first-stage decision. A recourse decision can then be made in the second stage that compensates for any bad effects that might have been experienced as a result of the first-stage decision. The optimal policy from such a model is a single first-stage policy and a collection of recourse decisions (a decision rule) defining which second-stage action should be taken in response to each random outcome.</p>
<p>Stochastic programming has applications in a broad range of areas ranging from <a href="/wiki/Finance" title="Finance">finance</a> to <a href="/wiki/Transportation" title="Transportation" class="mw-redirect">transportation</a> to energy optimization.<sup id="cite_ref-2" class="reference"><a href="#cite_note-2"><span>[</span>2<span>]</span></a></sup><sup id="cite_ref-3" class="reference"><a href="#cite_note-3"><span>[</span>3<span>]</span></a></sup> We present an example of optimizing an <a href="/wiki/Investment_portfolio" title="Investment portfolio" class="mw-redirect">investment portfolio</a> over time.</p>
<p></p>
<h2>Contents</h2>
<ul>
<li class="toclevel-1 tocsection-1"><a href="#Two-Stage_Problems"><span class="tocnumber">1</span> <span class="toctext">Two-Stage Problems</span></a>
<ul>
<li class="toclevel-2 tocsection-2"><a href="#Distributional_assumption"><span class="tocnumber">1.1</span> <span class="toctext">Distributional assumption</span></a></li>
<li class="toclevel-2 tocsection-3"><a href="#Discretization"><span class="tocnumber">1.2</span> <span class="toctext">Discretization</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-4"><a href="#Stochastic_linear_program"><span class="tocnumber">2</span> <span class="toctext">Stochastic linear program</span></a>
<ul>
<li class="toclevel-2 tocsection-5"><a href="#Deterministic_equivalent_of_a_stochastic_problem"><span class="tocnumber">2.1</span> <span class="toctext">Deterministic equivalent of a stochastic problem</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-6"><a href="#Scenario_Construction"><span class="tocnumber">3</span> <span class="toctext">Scenario Construction</span></a>
<ul>
<li class="toclevel-2 tocsection-7"><a href="#Monte_Carlo_sampling_and_Sample_Average_Approximation_.28SAA.29_Method"><span class="tocnumber">3.1</span> <span class="toctext">Monte Carlo sampling and Sample Average Approximation (SAA) Method</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-8"><a href="#Statistical_Inference"><span class="tocnumber">4</span> <span class="toctext">Statistical Inference</span></a>
<ul>
<li class="toclevel-2 tocsection-9"><a href="#Consistency_of_SAA_estimators"><span class="tocnumber">4.1</span> <span class="toctext">Consistency of SAA estimators</span></a></li>
<li class="toclevel-2 tocsection-10"><a href="#Asymptotics_of_the_SAA_optimal_value"><span class="tocnumber">4.2</span> <span class="toctext">Asymptotics of the SAA optimal value</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-11"><a href="#Multistage_Portfolio_Optimization"><span class="tocnumber">5</span> <span class="toctext">Multistage Portfolio Optimization</span></a>
<ul>
<li class="toclevel-2 tocsection-12"><a href="#Stagewise_independent_random_process"><span class="tocnumber">5.1</span> <span class="toctext">Stagewise independent random process</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-13"><a href="#Biological_applications"><span class="tocnumber">6</span> <span class="toctext">Biological applications</span></a></li>
<li class="toclevel-1 tocsection-14"><a href="#Economic_applications"><span class="tocnumber">7</span> <span class="toctext">Economic applications</span></a></li>
<li class="toclevel-1 tocsection-15"><a href="#Software_tools"><span class="tocnumber">8</span> <span class="toctext">Software tools</span></a>
<ul>
<li class="toclevel-2 tocsection-16"><a href="#Modelling_languages"><span class="tocnumber">8.1</span> <span class="toctext">Modelling languages</span></a></li>
<li class="toclevel-2 tocsection-17"><a href="#Solvers"><span class="tocnumber">8.2</span> <span class="toctext">Solvers</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-18"><a href="#See_also"><span class="tocnumber">9</span> <span class="toctext">See also</span></a></li>
<li class="toclevel-1 tocsection-19"><a href="#References"><span class="tocnumber">10</span> <span class="toctext">References</span></a></li>
<li class="toclevel-1 tocsection-20"><a href="#Further_reading"><span class="tocnumber">11</span> <span class="toctext">Further reading</span></a></li>
<li class="toclevel-1 tocsection-21"><a href="#External_links"><span class="tocnumber">12</span> <span class="toctext">External links</span></a></li>
</ul>
<ul>
<li class="toclevel-2 tocsection-2"><a href="#Distributional_assumption"><span class="tocnumber">1.1</span> <span class="toctext">Distributional assumption</span></a></li>
<li class="toclevel-2 tocsection-3"><a href="#Discretization"><span class="tocnumber">1.2</span> <span class="toctext">Discretization</span></a></li>
</ul>
<ul>
<li class="toclevel-2 tocsection-5"><a href="#Deterministic_equivalent_of_a_stochastic_problem"><span class="tocnumber">2.1</span> <span class="toctext">Deterministic equivalent of a stochastic problem</span></a></li>
</ul>
<ul>
<li class="toclevel-2 tocsection-7"><a href="#Monte_Carlo_sampling_and_Sample_Average_Approximation_.28SAA.29_Method"><span class="tocnumber">3.1</span> <span class="toctext">Monte Carlo sampling and Sample Average Approximation (SAA) Method</span></a></li>
</ul>
<ul>
<li class="toclevel-2 tocsection-9"><a href="#Consistency_of_SAA_estimators"><span class="tocnumber">4.1</span> <span class="toctext">Consistency of SAA estimators</span></a></li>
<li class="toclevel-2 tocsection-10"><a href="#Asymptotics_of_the_SAA_optimal_value"><span class="tocnumber">4.2</span> <span class="toctext">Asymptotics of the SAA optimal value</span></a></li>
</ul>
<ul>
<li class="toclevel-2 tocsection-12"><a href="#Stagewise_independent_random_process"><span class="tocnumber">5.1</span> <span class="toctext">Stagewise independent random process</span></a></li>
</ul>
<ul>
<li class="toclevel-2 tocsection-16"><a href="#Modelling_languages"><span class="tocnumber">8.1</span> <span class="toctext">Modelling languages</span></a></li>
<li class="toclevel-2 tocsection-17"><a href="#Solvers"><span class="tocnumber">8.2</span> <span class="toctext">Solvers</span></a></li>
</ul>
<p></p>
<h2><span class="mw-headline" id="Two-Stage_Problems">Two-Stage Problems</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Stochastic_programming&amp;action=edit&amp;section=1" title="Edit section: Two-Stage Problems">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>The basic idea of two-stage stochastic programming is that (optimal) decisions should be based on data available at the time the decisions are made and should not depend on future observations. Two-stage formulation is widely used in stochastic programming. The general formulation of a two-stage stochastic programming problem is given by:</p>
<p><img class="mwe-math-fallback-image-inline tex" alt="
\min_{x\in X}\{ g(x)= f(x) + E[Q(x,\xi)]\}
" src="//upload.wikimedia.org/math/a/a/9/aa9a6f21757a388b66242cb5158cea6d.png"></p>
<p>where <img class="mwe-math-fallback-image-inline tex" alt="Q(x,\xi) " src="//upload.wikimedia.org/math/9/7/b/97beb105bc2bc3ca9d2f324bacf9ebee.png"> is the optimal value of the second-stage problem</p>
<p><img class="mwe-math-fallback-image-inline tex" alt="
\min_{y}\{ q(y,\xi)| T(\xi)x+W(\xi) y = h(\xi)\}
" src="//upload.wikimedia.org/math/c/3/4/c342ebfd120b1cabfd1284692bf13393.png"></p>
<p>The classical two-stage linear stochastic programming problems can be formulated as</p>
<p><img class="mwe-math-fallback-image-inline tex" alt="
\begin{array}{llr}
\min\limits_{x\in \mathbb{R}^n}   &amp;g(x)= c^T x + E[Q(x,\xi)]    &amp;   \\
\text{subject to} &amp; Ax    =    b &amp;\\
		    &amp; x     \geq 0 &amp;
\end{array}
" src="//upload.wikimedia.org/math/e/9/0/e90d2e7e86455b8c804f298106264345.png"></p>
<p>where <img class="mwe-math-fallback-image-inline tex" alt=" Q(x,\xi)" src="//upload.wikimedia.org/math/9/7/b/97beb105bc2bc3ca9d2f324bacf9ebee.png"> is the optimal value of the second-stage problem</p>
<p><img class="mwe-math-fallback-image-inline tex" alt="
\begin{array}{llr}
\min\limits_{y\in \mathbb{R}^m}   &amp; q(\xi)^T y     &amp;   \\
\text{subject to} &amp; T(\xi)x+W(\xi)y    =    h(\xi) &amp;\\
		    &amp; y     \geq 0 &amp;
\end{array}
" src="//upload.wikimedia.org/math/2/4/e/24e0d29088f48ccdf1ab6cb6f01ae8fa.png"></p>
<p>In such formulation <img class="mwe-math-fallback-image-inline tex" alt="x\in \mathbb{R}^n" src="//upload.wikimedia.org/math/f/b/d/fbde4e1b6c7d4d43e94f24c44a89518b.png"> is the first-stage decision variable vector, <img class="mwe-math-fallback-image-inline tex" alt="y\in \mathbb{R}^m" src="//upload.wikimedia.org/math/d/4/f/d4f39298b5d825f804a03de1417fbeab.png"> is the second-stage decision variable vector, and <img class="mwe-math-fallback-image-inline tex" alt="\xi(q,T,W,h)" src="//upload.wikimedia.org/math/0/4/8/048ebc41707431914d986487e02a2bf5.png"> contains the data of the second-stage problem. In this formulation, at the first stage we have to make a "here-and-now" decision <img class="mwe-math-fallback-image-inline tex" alt="x" src="//upload.wikimedia.org/math/9/d/d/9dd4e461268c8034f5c8564e155c67a6.png"> before the realization of the uncertain data <img class="mwe-math-fallback-image-inline tex" alt="\xi" src="//upload.wikimedia.org/math/5/8/f/58fb07e3d4fa708afd0734aab363fd36.png">, viewed as a random vector, is known. At the second stage, after a realization of <img class="mwe-math-fallback-image-inline tex" alt="\xi" src="//upload.wikimedia.org/math/5/8/f/58fb07e3d4fa708afd0734aab363fd36.png"> becomes available, we optimize our behavior by solving an appropriate optimization problem.</p>
<p>At the first stage we optimize (minimize in the above formulation) the cost <img class="mwe-math-fallback-image-inline tex" alt="c^Tx" src="//upload.wikimedia.org/math/1/6/d/16d375770daf856d3738ee0901d13a5a.png"> of the first-stage decision plus the expected cost of the (optimal) second-stage decision. We can view the second-stage problem simply as an optimization problem which describes our supposedly optimal behavior when the uncertain data is revealed, or we can consider its solution as a recourse action where the term <img class="mwe-math-fallback-image-inline tex" alt="Wy" src="//upload.wikimedia.org/math/6/0/d/60d836b639b4f4b2db7788cf21bcd33d.png"> compensates for a possible inconsistency of the system <img class="mwe-math-fallback-image-inline tex" alt="Tx\leq h" src="//upload.wikimedia.org/math/c/1/c/c1c8c2addaf8ef4ccf8451cc8cf4b0fd.png"> and <img class="mwe-math-fallback-image-inline tex" alt="q^Ty" src="//upload.wikimedia.org/math/0/7/7/077bf16edb9a5d374cfeccc9243203f3.png"> is the cost of this recourse action.</p>
<p>The considered two-stage problem is <i>linear</i> because the objective functions and the constraints are linear. Conceptually this is not essential and one can consider more general two-stage stochastic programs. For example, if the first-stage problem is integer, one could add integrality constraints to the first-stage problem so that the feasible set is discrete. Non-linear objectives and constraints could also be incorporated if needed.<sup id="cite_ref-4" class="reference"><a href="#cite_note-4"><span>[</span>4<span>]</span></a></sup></p>
<h3><span class="mw-headline" id="Distributional_assumption">Distributional assumption</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Stochastic_programming&amp;action=edit&amp;section=2" title="Edit section: Distributional assumption">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>The formulation of the above two-stage problem assumes that the second-stage data <img class="mwe-math-fallback-image-inline tex" alt="\xi" src="//upload.wikimedia.org/math/5/8/f/58fb07e3d4fa708afd0734aab363fd36.png"> can be modeled as a random vector with a <i><b>known</b></i> probability distribution (not just uncertain). This would be justified in many situations. For example <img class="mwe-math-fallback-image-inline tex" alt="\xi" src="//upload.wikimedia.org/math/5/8/f/58fb07e3d4fa708afd0734aab363fd36.png"> could be information derived from historical data and the distribution does not significantly change over the considered period of time. In such situations one may reliably estimate the required probability distribution and the optimization <i>on average</i> could be justified by the Law of Large Numbers. Another example is that <img class="mwe-math-fallback-image-inline tex" alt="\xi" src="//upload.wikimedia.org/math/5/8/f/58fb07e3d4fa708afd0734aab363fd36.png"> could be realizations of a simulation model whose outputs are stochastic. The empirical distribution of the sample could be used as an approximation to the true but unknown output distribution.</p>
<h3><span class="mw-headline" id="Discretization">Discretization</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Stochastic_programming&amp;action=edit&amp;section=3" title="Edit section: Discretization">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>To solve the two-stage stochastic problem numerically, one often need to assume that the random vector <img class="mwe-math-fallback-image-inline tex" alt="\xi" src="//upload.wikimedia.org/math/5/8/f/58fb07e3d4fa708afd0734aab363fd36.png"> has a finite number of possible realizations, called <i>scenarios</i>, say <img class="mwe-math-fallback-image-inline tex" alt="\xi_1,\dots,\xi_K" src="//upload.wikimedia.org/math/d/4/c/d4c610b1ac7bb4be39c4328b2a0d9036.png">, with respective probability masses <img class="mwe-math-fallback-image-inline tex" alt="p_1,\dots,p_K" src="//upload.wikimedia.org/math/3/0/0/300ca154efdf7431b8f3c8ad112defff.png">. Then the expectation in the first-stage problem's objective function can be written as the summation:</p>
<p><img class="mwe-math-fallback-image-inline tex" alt="
E[Q(x,\xi)]=\sum\limits_{k=1}^{K} p_kQ(x,\xi_k)
" src="//upload.wikimedia.org/math/2/3/d/23d3b03c74f138ee71877ad1c195aeca.png"></p>
<p>and, moreover, the two-stage problem can be formulated as one large linear programming problem (this is called the deterministic equivalent of the original problem, see section <a href="#Deterministic_equivalent_of_a_stochastic_problem">Deterministic equivalent of a stochastic problem</a>).</p>
<p>When <img class="mwe-math-fallback-image-inline tex" alt="\xi" src="//upload.wikimedia.org/math/5/8/f/58fb07e3d4fa708afd0734aab363fd36.png"> has an infinite (or very large) number of possible realizations the standard approach is then to represent this distribution by scenarios. This approach raises three questions, namely:</p>
<ol>
<li>How to construct scenarios, see <a href="#Scenario_Construction">Scenario Construction</a>;</li>
<li>How to solve the deterministic equivalent. Optimizers such as <a href="/wiki/CPLEX" title="CPLEX">CPLEX</a>, <a href="/wiki/GNU_Linear_Programming_Kit" title="GNU Linear Programming Kit">GLPK</a> and <a href="/wiki/Gurobi" title="Gurobi">Gurobi</a> can solve large linear/nonlinear problems. NEOS <sup id="cite_ref-neos_5-0" class="reference"><a href="#cite_note-neos-5"><span>[</span>5<span>]</span></a></sup> server hosted at the <a href="/wiki/Argonne_National_Laboratory" title="Argonne National Laboratory">Argonne National Laboratory</a> allows free access to many modern solvers. The structure of a deterministic equivalent is particularly amenable to apply decomposition methods,<sup id="cite_ref-6" class="reference"><a href="#cite_note-6"><span>[</span>6<span>]</span></a></sup> such as <a href="/wiki/Benders%27_decomposition" title="Benders' decomposition">Benders' decomposition</a> or scenario decomposition;</li>
<li>How to measure quality of the obtained solution with respect to the "true" optimum.</li>
</ol>
<p>These questions are not independent. For example, the number of scenarios constructed will affect both the tractability of the deterministic equivalent and the quality of the obtained solutions.</p>
<h2><span class="mw-headline" id="Stochastic_linear_program">Stochastic linear program</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Stochastic_programming&amp;action=edit&amp;section=4" title="Edit section: Stochastic linear program">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>A stochastic <a href="/wiki/Linear_program" title="Linear program" class="mw-redirect">linear program</a> is a specific instance of the classical two-stage stochastic program. A stochastic LP is built from a collection of multi-period linear programs (LPs), each having the same structure but somewhat different data. The <img class="mwe-math-fallback-image-inline tex" alt="k^{th}" src="//upload.wikimedia.org/math/d/4/6/d4678fd2396484f6c98c4f3af24c3b03.png"> two-period LP, representing the <img class="mwe-math-fallback-image-inline tex" alt="k^{th}" src="//upload.wikimedia.org/math/d/4/6/d4678fd2396484f6c98c4f3af24c3b03.png"> scenario, may be regarded as having the following form:</p>
<p><img class="mwe-math-fallback-image-inline tex" alt="	
\begin{array}{lccccccc}
\text{Minimize} &amp; f^T x &amp; + &amp; g^T y &amp; + &amp; h_k^Tz_k &amp;  &amp;  \\ 	
\text{subject to} &amp; Tx &amp; + &amp; Uy &amp;  &amp;  &amp; = &amp; r \\ 	
 &amp;  &amp;  &amp; V_k y &amp; + &amp; W_kz_k &amp; = &amp; s_k \\ 
 &amp; x &amp; , &amp; y &amp; , &amp; z_k &amp; \geq &amp; 0
\end{array}
" src="//upload.wikimedia.org/math/7/d/7/7d70f426bc582372d61a562fed6eb195.png"></p>
<p>The vectors <img class="mwe-math-fallback-image-inline tex" alt="x" src="//upload.wikimedia.org/math/9/d/d/9dd4e461268c8034f5c8564e155c67a6.png"> and <img class="mwe-math-fallback-image-inline tex" alt="y" src="//upload.wikimedia.org/math/4/1/5/415290769594460e2e485922904f345d.png"> contain the first-period variables, whose values must be chosen immediately. The vector <img class="mwe-math-fallback-image-inline tex" alt="z_k" src="//upload.wikimedia.org/math/6/8/9/68971407c637f6163d40770cc048e5de.png"> contains all of the variables for subsequent periods. The constraints <img class="mwe-math-fallback-image-inline tex" alt="Tx + Uy = r" src="//upload.wikimedia.org/math/4/a/7/4a76616b510677801b8c2176086026a3.png"> involve only first-period variables and are the same in every scenario. The other constraints involve variables of later periods and differ in some respects from scenario to scenario, reflecting uncertainty about the future.</p>
<p>Note that solving the <img class="mwe-math-fallback-image-inline tex" alt="k^{th}" src="//upload.wikimedia.org/math/d/4/6/d4678fd2396484f6c98c4f3af24c3b03.png"> two-period LP is equivalent to assuming the <img class="mwe-math-fallback-image-inline tex" alt="k^{th}" src="//upload.wikimedia.org/math/d/4/6/d4678fd2396484f6c98c4f3af24c3b03.png"> scenario in the second period with no uncertainty. In order to incorporate uncertainties in the second stage, one should assign probabilities to different scenarios and solve the corresponding deterministic equivalent.</p>
<h3><span class="mw-headline" id="Deterministic_equivalent_of_a_stochastic_problem">Deterministic equivalent of a stochastic problem</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Stochastic_programming&amp;action=edit&amp;section=5" title="Edit section: Deterministic equivalent of a stochastic problem">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>With a finite number of scenarios, two-stage stochastic linear programs can be modelled as large linear programming problems. This formulation is often called the deterministic equivalent linear program, or abbreviated to deterministic equivalent. (Strictly speaking a deterministic equivalent is any mathematical program that can be used to compute the optimal first-stage decision, so these will exist for continuous probability distributions as well, when one can represent the second-stage cost in some closed form.) For example, to form the deterministic equivalent to the above stochastic linear program, we assign a probability <img class="mwe-math-fallback-image-inline tex" alt="p_k" src="//upload.wikimedia.org/math/3/7/7/377c9c2305a4c8c5ecfbdba04536e8c4.png"> to each scenario <img class="mwe-math-fallback-image-inline tex" alt="k=1,\dots,K" src="//upload.wikimedia.org/math/9/c/e/9ceb89d7cf4146cebfe024128da9d412.png">. Then we can minimize the expected value of the objective, subject to the constraints from all scenarios:</p>
<p><img class="mwe-math-fallback-image-inline tex" alt="
\begin{array}{lccccccccccccc}
\text{Minimize} &amp; f^T x &amp; + &amp; g^T y &amp; + &amp; p_1h_1^Tz_1 &amp; + &amp; p_2h_2^Tz_2 &amp; + &amp; \cdots &amp; + &amp; p_Kh_K^Tz_K &amp;  &amp;  \\ 
\text{subject to} &amp; Tx &amp; + &amp; Uy &amp;  &amp;  &amp;  &amp;  &amp;  &amp;  &amp;  &amp;  &amp; = &amp; r \\ 
 &amp;  &amp;  &amp; V_1 y &amp; + &amp; W_1z_1 &amp;  &amp;  &amp;  &amp;  &amp;  &amp;  &amp; = &amp; s_1 \\ 
 &amp;  &amp;  &amp; V_2 y &amp;  &amp;  &amp; + &amp; W_2z_2 &amp;  &amp;  &amp;  &amp;  &amp; = &amp; s_2 \\ 
 &amp;  &amp;  &amp; \vdots &amp;  &amp;  &amp;  &amp;  &amp;  &amp; \ddots &amp;  &amp;  &amp;  &amp; \vdots \\ 
 &amp;  &amp;  &amp; V_Ky &amp;  &amp;  &amp;  &amp;  &amp;  &amp;  &amp; + &amp; W_Kz_K &amp; = &amp; s_K \\ 
 &amp; x &amp; , &amp; y &amp; , &amp; z_1 &amp; , &amp; z_2 &amp; , &amp; \ldots &amp; , &amp; z_K &amp; \geq &amp; 0 \\ 
\end{array}
" src="//upload.wikimedia.org/math/1/1/4/114d2b7cfcacce1dd3ce59767efbd740.png"></p>
<p>We have a different vector <img class="mwe-math-fallback-image-inline tex" alt="z_k" src="//upload.wikimedia.org/math/6/8/9/68971407c637f6163d40770cc048e5de.png"> of later-period variables for each scenario <img class="mwe-math-fallback-image-inline tex" alt="k" src="//upload.wikimedia.org/math/8/c/e/8ce4b16b22b58894aa86c421e8759df3.png">. The first-period variables <img class="mwe-math-fallback-image-inline tex" alt="x" src="//upload.wikimedia.org/math/9/d/d/9dd4e461268c8034f5c8564e155c67a6.png"> and <img class="mwe-math-fallback-image-inline tex" alt="y" src="//upload.wikimedia.org/math/4/1/5/415290769594460e2e485922904f345d.png"> are the same in every scenario, however, because we must make a decision for the first period before we know which scenario will be realized. As a result, the constraints involving just <img class="mwe-math-fallback-image-inline tex" alt="x" src="//upload.wikimedia.org/math/9/d/d/9dd4e461268c8034f5c8564e155c67a6.png"> and <img class="mwe-math-fallback-image-inline tex" alt="y" src="//upload.wikimedia.org/math/4/1/5/415290769594460e2e485922904f345d.png"> need only be specified once, while the remaining constraints must be given separately for each scenario.</p>
<h2><span class="mw-headline" id="Scenario_Construction">Scenario Construction</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Stochastic_programming&amp;action=edit&amp;section=6" title="Edit section: Scenario Construction">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>In practice it might be possible to construct scenarios by eliciting expert's opinions on the future. The number of constructed scenarios should be relatively modest so that the obtained deterministic equivalent can be solved with reasonable computational effort. It is often claimed that a solution that is optimal using only a few scenarios provides more adaptable plans than one that assumes a single scenario only. In some cases such a claim could be verified by a simulation. In theory some measures of guarantee that an obtained solution solves the original problem with reasonable accuracy. Typically in applications only the <i>first stage</i> optimal solution <img class="mwe-math-fallback-image-inline tex" alt="x^*" src="//upload.wikimedia.org/math/d/2/8/d282fd3350bb3ec2d1e940574e8fd42d.png"> has a practical value since almost always a "true" realization of the random data will be different from the set of constructed (generated) scenarios.</p>
<p>Suppose <img class="mwe-math-fallback-image-inline tex" alt="\xi" src="//upload.wikimedia.org/math/5/8/f/58fb07e3d4fa708afd0734aab363fd36.png"> contains <img class="mwe-math-fallback-image-inline tex" alt="d" src="//upload.wikimedia.org/math/8/2/7/8277e0910d750195b448797616e091ad.png"> independent random components, each of which has three possible realizations (for example, future realizations of each random parameters are classified as low, medium and high), then the total number of scenarios is <img class="mwe-math-fallback-image-inline tex" alt="K=3^d" src="//upload.wikimedia.org/math/f/e/f/fef3143b6533ed32bb79ab1e22b6f2cc.png">. Such <i>exponential growth</i> of the number of scenarios makes model development using expert opinion very difficult even for reasonable size <img class="mwe-math-fallback-image-inline tex" alt="d" src="//upload.wikimedia.org/math/8/2/7/8277e0910d750195b448797616e091ad.png">. The situation becomes even worse if some random components of <img class="mwe-math-fallback-image-inline tex" alt="\xi" src="//upload.wikimedia.org/math/5/8/f/58fb07e3d4fa708afd0734aab363fd36.png"> have continuous distributions.</p>
<h3><span class="mw-headline" id="Monte_Carlo_sampling_and_Sample_Average_Approximation_.28SAA.29_Method">Monte Carlo sampling and Sample Average Approximation (SAA) Method</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Stochastic_programming&amp;action=edit&amp;section=7" title="Edit section: Monte Carlo sampling and Sample Average Approximation (SAA) Method">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>A common approach to reduce the scenario set to a manageable size is by using Monte Carlo simulation. Suppose the total number of scenarios is very large or even infinite. Suppose further that we can generate a sample <img class="mwe-math-fallback-image-inline tex" alt="\xi^1,\xi^2,\dots,\xi^N" src="//upload.wikimedia.org/math/6/6/6/6663e216d8d2b8b4976c43fbb12859a8.png"> of <img class="mwe-math-fallback-image-inline tex" alt="N" src="//upload.wikimedia.org/math/8/d/9/8d9c307cb7f3c4a32822a51922d1ceaa.png"> replications of the random vector <img class="mwe-math-fallback-image-inline tex" alt="\xi" src="//upload.wikimedia.org/math/5/8/f/58fb07e3d4fa708afd0734aab363fd36.png">. Usually the sample is assumed to be independent identically distributed (i.i.d sample). Given a sample, the expectation function <img class="mwe-math-fallback-image-inline tex" alt="q(x)=E[Q(x,\xi)]" src="//upload.wikimedia.org/math/4/6/b/46bb451ee2d7e12bd8d868f4c61556c3.png"> is approximated by the sample average</p>
<p><img class="mwe-math-fallback-image-inline tex" alt="
\hat{q}_N(x) = \frac{1}{N} \sum_{j=1}^N Q(x,\xi^j)
" src="//upload.wikimedia.org/math/c/0/c/c0c36f0e99776288ba2c979f1d7242ad.png"></p>
<p>and consequently the first-stage problem is given by</p>
<p><img class="mwe-math-fallback-image-inline tex" alt="
\begin{array}{rlrrr}
\hat{g}_N(x)=&amp;\min\limits_{x\in \mathbb{R}^n}   &amp; c^T x + \frac{1}{N} \sum_{j=1}^N Q(x,\xi^j)    &amp;   \\
&amp;\text{subject to} &amp; Ax    &amp;=&amp;    b \\
&amp;		    &amp; x     &amp;\geq&amp; 0
\end{array}
" src="//upload.wikimedia.org/math/2/1/e/21eac82da6aa8677b26e80ccc6671236.png"></p>
<p>This formulation is known as the <i>Sample Average Approximation</i> method. The SAA problem is a function of the considered sample and in that sense is random. For a given sample <img class="mwe-math-fallback-image-inline tex" alt="\xi^1,\xi^2,\dots,\xi^N" src="//upload.wikimedia.org/math/6/6/6/6663e216d8d2b8b4976c43fbb12859a8.png"> the SAA problem is of the same form as a two-stage stochastic linear programming problem with the scenarios <img class="mwe-math-fallback-image-inline tex" alt="\xi^j" src="//upload.wikimedia.org/math/0/d/a/0da9baa4c955a556a9fa5db68eb79869.png">., <img class="mwe-math-fallback-image-inline tex" alt="j=1,\dots,N" src="//upload.wikimedia.org/math/0/5/9/059aa8a9df66c521674722e69afbe58e.png">, each taken with the same probability <img class="mwe-math-fallback-image-inline tex" alt="p_j=\frac{1}{N}" src="//upload.wikimedia.org/math/f/0/7/f07cb95f7a2e8ce61dbbda27161954c5.png">.</p>
<h2><span class="mw-headline" id="Statistical_Inference">Statistical Inference</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Stochastic_programming&amp;action=edit&amp;section=8" title="Edit section: Statistical Inference">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Consider the following stochastic programming problem</p>
<p>Here <img class="mwe-math-fallback-image-inline tex" alt="X" src="//upload.wikimedia.org/math/0/2/1/02129bb861061d1a052c592e2dc6b383.png"> is a nonempty closed subset of <img class="mwe-math-fallback-image-inline tex" alt="\mathbb{R}^n" src="//upload.wikimedia.org/math/3/0/c/30c28f76ef7517dbd19df4d4c683dbe6.png">, <img class="mwe-math-fallback-image-inline tex" alt="\xi" src="//upload.wikimedia.org/math/5/8/f/58fb07e3d4fa708afd0734aab363fd36.png"> is a random vector whose probability distribution <img class="mwe-math-fallback-image-inline tex" alt="P" src="//upload.wikimedia.org/math/4/4/c/44c29edb103a2872f519ad0c9a0fdaaa.png"> is supported on a set <img class="mwe-math-fallback-image-inline tex" alt="\Xi \subset \mathbb{R}^d" src="//upload.wikimedia.org/math/4/e/d/4ed43410d51bc733e26bd9ee54480662.png">, and <img class="mwe-math-fallback-image-inline tex" alt="Q: X \times \Xi \rightarrow \mathbb{R}" src="//upload.wikimedia.org/math/5/e/b/5ebb9cb007782dae9484242deebd422a.png">. In the framework of two-stage stochastic programming, <img class="mwe-math-fallback-image-inline tex" alt="Q(x,\xi)" src="//upload.wikimedia.org/math/9/7/b/97beb105bc2bc3ca9d2f324bacf9ebee.png"> is given by the optimal value of the corresponding second-stage problem.</p>
<p>Assume that <img class="mwe-math-fallback-image-inline tex" alt="g(x)" src="//upload.wikimedia.org/math/e/8/4/e84fec1e074026d6fa8e3155482c35c3.png"> is well defined and <i>finite valued</i> for all <img class="mwe-math-fallback-image-inline tex" alt="x\in X" src="//upload.wikimedia.org/math/7/3/5/735b05e6097f98da56f2ca14b8005d36.png">. This implies that for every <img class="mwe-math-fallback-image-inline tex" alt="x\in X" src="//upload.wikimedia.org/math/7/3/5/735b05e6097f98da56f2ca14b8005d36.png"> the value <img class="mwe-math-fallback-image-inline tex" alt="Q(x,\xi)" src="//upload.wikimedia.org/math/9/7/b/97beb105bc2bc3ca9d2f324bacf9ebee.png"> is finite almost surely.</p>
<p>Suppose that we have a sample <img class="mwe-math-fallback-image-inline tex" alt="\xi^1,\dots,\xi^N" src="//upload.wikimedia.org/math/4/9/7/497285f2fa65ca77ebdd33a461a5950a.png"> of <img class="mwe-math-fallback-image-inline tex" alt="N" src="//upload.wikimedia.org/math/8/d/9/8d9c307cb7f3c4a32822a51922d1ceaa.png">realizations of the random vector <img class="mwe-math-fallback-image-inline tex" alt="\xi" src="//upload.wikimedia.org/math/5/8/f/58fb07e3d4fa708afd0734aab363fd36.png">. This random sample can be viewed as historical data of <img class="mwe-math-fallback-image-inline tex" alt="N" src="//upload.wikimedia.org/math/8/d/9/8d9c307cb7f3c4a32822a51922d1ceaa.png"> observations of <img class="mwe-math-fallback-image-inline tex" alt="\xi" src="//upload.wikimedia.org/math/5/8/f/58fb07e3d4fa708afd0734aab363fd36.png">, or it can be generated by Monte Carlo sampling techniques. Then we can formulate a corresponding <i>sample average approximation</i></p>
<p>By the <a href="/wiki/Law_of_Large_Numbers" title="Law of Large Numbers" class="mw-redirect">Law of Large Numbers</a> we have that, under some regularity conditions <img class="mwe-math-fallback-image-inline tex" alt="\frac{1}{N} \sum_{j=1}^N Q(x,\xi^j)" src="//upload.wikimedia.org/math/6/1/d/61dfc54084ee23f09cfcb8e3b36183a3.png"> converges pointwise with probability 1 to <img class="mwe-math-fallback-image-inline tex" alt="E[Q(x,\xi)]" src="//upload.wikimedia.org/math/e/e/d/eed1927613821187b6aee908639a93ff.png"> as <img class="mwe-math-fallback-image-inline tex" alt="N \rightarrow \infty" src="//upload.wikimedia.org/math/e/c/4/ec4668d92fc0fc5cfc89732fbc840c0d.png">. Moreover, under mild additional conditions the convergence is uniform. We also have <img class="mwe-math-fallback-image-inline tex" alt="E[\hat{g}_N(x)]=g(x)" src="//upload.wikimedia.org/math/a/9/6/a96927a9bf39d401ffa708227e945e6f.png">, i.e., <img class="mwe-math-fallback-image-inline tex" alt="\hat{g}_N(x)" src="//upload.wikimedia.org/math/6/6/c/66c23b19f2ec9c8a812844a44143a8d2.png"> is an <i>unbiased</i> estimator of <img class="mwe-math-fallback-image-inline tex" alt="g(x)" src="//upload.wikimedia.org/math/e/8/4/e84fec1e074026d6fa8e3155482c35c3.png">. Therefore it is natural to expect that the optimal value and optimal solutions of the SAA problem converge to their counterparts of the true problem as <img class="mwe-math-fallback-image-inline tex" alt="N \rightarrow \infty" src="//upload.wikimedia.org/math/e/c/4/ec4668d92fc0fc5cfc89732fbc840c0d.png">.</p>
<h3><span class="mw-headline" id="Consistency_of_SAA_estimators">Consistency of SAA estimators</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Stochastic_programming&amp;action=edit&amp;section=9" title="Edit section: Consistency of SAA estimators">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Suppose the feasible set <img class="mwe-math-fallback-image-inline tex" alt="X" src="//upload.wikimedia.org/math/0/2/1/02129bb861061d1a052c592e2dc6b383.png"> of the SAA problem is fixed, i.e., it is independent of the sample. Let <img class="mwe-math-fallback-image-inline tex" alt="\vartheta^*" src="//upload.wikimedia.org/math/a/8/4/a844f51efda5cd4dd420c2dc000d9e3b.png"> and <img class="mwe-math-fallback-image-inline tex" alt="S^*" src="//upload.wikimedia.org/math/c/9/7/c978220d0883c8ecfff145151e364724.png"> be the optimal value and the set of optimal solutions, respectively, of the true problem and let <img class="mwe-math-fallback-image-inline tex" alt="\hat{\vartheta}_N" src="//upload.wikimedia.org/math/8/3/c/83ca8dbcdb8cbed51f26e1c3385331da.png"> and <img class="mwe-math-fallback-image-inline tex" alt="\hat{S}_N" src="//upload.wikimedia.org/math/b/3/0/b30ddf686c05003c1801c1f1e4449474.png"> be the optimal value and the set of optimal solutions, respectively, of the SAA problem.</p>
<ol>
<li>Let <img class="mwe-math-fallback-image-inline tex" alt="g: X \rightarrow \mathbb{R}" src="//upload.wikimedia.org/math/7/6/d/76d86f6721ba1baf51d9df3c28b6f017.png"> and <img class="mwe-math-fallback-image-inline tex" alt="\hat{g}_N: X \rightarrow \mathbb{R}" src="//upload.wikimedia.org/math/2/8/b/28b5be7aefda995771fb9739f182c2b3.png"> be a sequence of (deterministic) real valued functions. The following two properties are equivalent:
<ul>
<li>for any <img class="mwe-math-fallback-image-inline tex" alt="\overline{x}\in X" src="//upload.wikimedia.org/math/c/0/a/c0a06f98acc7ba3107b338cc4d6356ca.png"> and any sequence <img class="mwe-math-fallback-image-inline tex" alt="\{x_N\}\subset X" src="//upload.wikimedia.org/math/e/8/1/e81d09ff8066daaa69db31be039b8d8e.png"> converging to <img class="mwe-math-fallback-image-inline tex" alt="\overline{x}" src="//upload.wikimedia.org/math/3/4/f/34fd2436571a41ac9080dd4e238e72a5.png"> it follows that <img class="mwe-math-fallback-image-inline tex" alt="\hat{g}_N(x_N)" src="//upload.wikimedia.org/math/2/6/9/269d91ca369ed5e9cff4b4940b9115ad.png"> converges to <img class="mwe-math-fallback-image-inline tex" alt="g(\overline{x})" src="//upload.wikimedia.org/math/8/4/f/84f0d836895bb562bee342abefcd2014.png"></li>
<li>the function <img class="mwe-math-fallback-image-inline tex" alt="f(\cdot)" src="//upload.wikimedia.org/math/a/1/0/a1044326f95cfbf46f9859c97cf280be.png"> is continuous on <img class="mwe-math-fallback-image-inline tex" alt="X" src="//upload.wikimedia.org/math/0/2/1/02129bb861061d1a052c592e2dc6b383.png"> and <img class="mwe-math-fallback-image-inline tex" alt="\hat{g}_N(\cdot)" src="//upload.wikimedia.org/math/5/8/f/58f16dd009088b076894fe6174485688.png"> converges to <img class="mwe-math-fallback-image-inline tex" alt="g(\cdot)" src="//upload.wikimedia.org/math/c/6/2/c620d7d6a70dfcd11203cafe53c70c31.png"> uniformly on any compact subset of <img class="mwe-math-fallback-image-inline tex" alt="X" src="//upload.wikimedia.org/math/0/2/1/02129bb861061d1a052c592e2dc6b383.png"></li>
</ul>
</li>
<li>If the objective of the SAA problem <img class="mwe-math-fallback-image-inline tex" alt="\hat{g}_N(x)" src="//upload.wikimedia.org/math/6/6/c/66c23b19f2ec9c8a812844a44143a8d2.png"> converges to the true problem's objective <img class="mwe-math-fallback-image-inline tex" alt="g(x)" src="//upload.wikimedia.org/math/e/8/4/e84fec1e074026d6fa8e3155482c35c3.png"> with probability 1, as <img class="mwe-math-fallback-image-inline tex" alt="N \rightarrow \infty" src="//upload.wikimedia.org/math/e/c/4/ec4668d92fc0fc5cfc89732fbc840c0d.png">, uniformly on the feasible set <img class="mwe-math-fallback-image-inline tex" alt="X" src="//upload.wikimedia.org/math/0/2/1/02129bb861061d1a052c592e2dc6b383.png">. Then <img class="mwe-math-fallback-image-inline tex" alt="\hat{\vartheta}_N" src="//upload.wikimedia.org/math/8/3/c/83ca8dbcdb8cbed51f26e1c3385331da.png"> converges to <img class="mwe-math-fallback-image-inline tex" alt="\vartheta^*" src="//upload.wikimedia.org/math/a/8/4/a844f51efda5cd4dd420c2dc000d9e3b.png"> with probability 1 as <img class="mwe-math-fallback-image-inline tex" alt="N \rightarrow \infty" src="//upload.wikimedia.org/math/e/c/4/ec4668d92fc0fc5cfc89732fbc840c0d.png">.</li>
<li>Suppose that there exists a compact set <img class="mwe-math-fallback-image-inline tex" alt="C \subset \mathbb{R}^n" src="//upload.wikimedia.org/math/4/3/1/43176a95cf46f0499562a8095cefc94b.png"> such that
<ul>
<li>the set <img class="mwe-math-fallback-image-inline tex" alt="S" src="//upload.wikimedia.org/math/5/d/b/5dbc98dcc983a70728bd082d1a47546e.png"> of optimal solutions of the true problem is nonempty and is contained in <img class="mwe-math-fallback-image-inline tex" alt="C" src="//upload.wikimedia.org/math/0/d/6/0d61f8370cad1d412f80b84d143e1257.png"></li>
<li>the function <img class="mwe-math-fallback-image-inline tex" alt="g(x)" src="//upload.wikimedia.org/math/e/8/4/e84fec1e074026d6fa8e3155482c35c3.png"> is finite valued and continuous on <img class="mwe-math-fallback-image-inline tex" alt="C" src="//upload.wikimedia.org/math/0/d/6/0d61f8370cad1d412f80b84d143e1257.png"></li>
<li>the sequence of functions <img class="mwe-math-fallback-image-inline tex" alt="\hat{g}_N(x)" src="//upload.wikimedia.org/math/6/6/c/66c23b19f2ec9c8a812844a44143a8d2.png"> converges to <img class="mwe-math-fallback-image-inline tex" alt="g(x)" src="//upload.wikimedia.org/math/e/8/4/e84fec1e074026d6fa8e3155482c35c3.png"> with probability 1, as <img class="mwe-math-fallback-image-inline tex" alt="N \rightarrow \infty" src="//upload.wikimedia.org/math/e/c/4/ec4668d92fc0fc5cfc89732fbc840c0d.png">, uniformly in <img class="mwe-math-fallback-image-inline tex" alt="x\in C" src="//upload.wikimedia.org/math/7/1/e/71e2d1d76963d7609a1844748ec9c174.png"></li>
<li>for <img class="mwe-math-fallback-image-inline tex" alt="N" src="//upload.wikimedia.org/math/8/d/9/8d9c307cb7f3c4a32822a51922d1ceaa.png"> large enough the set <img class="mwe-math-fallback-image-inline tex" alt="\hat{S}_N" src="//upload.wikimedia.org/math/b/3/0/b30ddf686c05003c1801c1f1e4449474.png"> is nonempty and <img class="mwe-math-fallback-image-inline tex" alt="\hat{S}_N \subset C" src="//upload.wikimedia.org/math/b/5/e/b5e6082471179fc1a00e18bacefb8a1d.png"> with probability 1</li>
</ul>
</li>
</ol>
<ul>
<li>for any <img class="mwe-math-fallback-image-inline tex" alt="\overline{x}\in X" src="//upload.wikimedia.org/math/c/0/a/c0a06f98acc7ba3107b338cc4d6356ca.png"> and any sequence <img class="mwe-math-fallback-image-inline tex" alt="\{x_N\}\subset X" src="//upload.wikimedia.org/math/e/8/1/e81d09ff8066daaa69db31be039b8d8e.png"> converging to <img class="mwe-math-fallback-image-inline tex" alt="\overline{x}" src="//upload.wikimedia.org/math/3/4/f/34fd2436571a41ac9080dd4e238e72a5.png"> it follows that <img class="mwe-math-fallback-image-inline tex" alt="\hat{g}_N(x_N)" src="//upload.wikimedia.org/math/2/6/9/269d91ca369ed5e9cff4b4940b9115ad.png"> converges to <img class="mwe-math-fallback-image-inline tex" alt="g(\overline{x})" src="//upload.wikimedia.org/math/8/4/f/84f0d836895bb562bee342abefcd2014.png"></li>
<li>the function <img class="mwe-math-fallback-image-inline tex" alt="f(\cdot)" src="//upload.wikimedia.org/math/a/1/0/a1044326f95cfbf46f9859c97cf280be.png"> is continuous on <img class="mwe-math-fallback-image-inline tex" alt="X" src="//upload.wikimedia.org/math/0/2/1/02129bb861061d1a052c592e2dc6b383.png"> and <img class="mwe-math-fallback-image-inline tex" alt="\hat{g}_N(\cdot)" src="//upload.wikimedia.org/math/5/8/f/58f16dd009088b076894fe6174485688.png"> converges to <img class="mwe-math-fallback-image-inline tex" alt="g(\cdot)" src="//upload.wikimedia.org/math/c/6/2/c620d7d6a70dfcd11203cafe53c70c31.png"> uniformly on any compact subset of <img class="mwe-math-fallback-image-inline tex" alt="X" src="//upload.wikimedia.org/math/0/2/1/02129bb861061d1a052c592e2dc6b383.png"></li>
</ul>
<ul>
<li>the set <img class="mwe-math-fallback-image-inline tex" alt="S" src="//upload.wikimedia.org/math/5/d/b/5dbc98dcc983a70728bd082d1a47546e.png"> of optimal solutions of the true problem is nonempty and is contained in <img class="mwe-math-fallback-image-inline tex" alt="C" src="//upload.wikimedia.org/math/0/d/6/0d61f8370cad1d412f80b84d143e1257.png"></li>
<li>the function <img class="mwe-math-fallback-image-inline tex" alt="g(x)" src="//upload.wikimedia.org/math/e/8/4/e84fec1e074026d6fa8e3155482c35c3.png"> is finite valued and continuous on <img class="mwe-math-fallback-image-inline tex" alt="C" src="//upload.wikimedia.org/math/0/d/6/0d61f8370cad1d412f80b84d143e1257.png"></li>
<li>the sequence of functions <img class="mwe-math-fallback-image-inline tex" alt="\hat{g}_N(x)" src="//upload.wikimedia.org/math/6/6/c/66c23b19f2ec9c8a812844a44143a8d2.png"> converges to <img class="mwe-math-fallback-image-inline tex" alt="g(x)" src="//upload.wikimedia.org/math/e/8/4/e84fec1e074026d6fa8e3155482c35c3.png"> with probability 1, as <img class="mwe-math-fallback-image-inline tex" alt="N \rightarrow \infty" src="//upload.wikimedia.org/math/e/c/4/ec4668d92fc0fc5cfc89732fbc840c0d.png">, uniformly in <img class="mwe-math-fallback-image-inline tex" alt="x\in C" src="//upload.wikimedia.org/math/7/1/e/71e2d1d76963d7609a1844748ec9c174.png"></li>
<li>for <img class="mwe-math-fallback-image-inline tex" alt="N" src="//upload.wikimedia.org/math/8/d/9/8d9c307cb7f3c4a32822a51922d1ceaa.png"> large enough the set <img class="mwe-math-fallback-image-inline tex" alt="\hat{S}_N" src="//upload.wikimedia.org/math/b/3/0/b30ddf686c05003c1801c1f1e4449474.png"> is nonempty and <img class="mwe-math-fallback-image-inline tex" alt="\hat{S}_N \subset C" src="//upload.wikimedia.org/math/b/5/e/b5e6082471179fc1a00e18bacefb8a1d.png"> with probability 1</li>
</ul>
<p>In some situations the feasible set <img class="mwe-math-fallback-image-inline tex" alt="X" src="//upload.wikimedia.org/math/0/2/1/02129bb861061d1a052c592e2dc6b383.png"> of the SAA problem is estimated, then the corresponding SAA problem takes the form</p>
<p>where <img class="mwe-math-fallback-image-inline tex" alt="X_N" src="//upload.wikimedia.org/math/c/7/3/c73f410ed4a2845b868ebb7d337044a1.png"> is a subset of <img class="mwe-math-fallback-image-inline tex" alt="\mathbb{R}^n" src="//upload.wikimedia.org/math/3/0/c/30c28f76ef7517dbd19df4d4c683dbe6.png"> depending on the sample and therefore is random. Nevertheless consistency results for SAA estimators can still be derived under some additional assumptions:</p>
<ol>
<li>Suppose that there exists a compact set <img class="mwe-math-fallback-image-inline tex" alt="C \subset \mathbb{R}^n" src="//upload.wikimedia.org/math/4/3/1/43176a95cf46f0499562a8095cefc94b.png"> such that
<ul>
<li>the set <img class="mwe-math-fallback-image-inline tex" alt="S" src="//upload.wikimedia.org/math/5/d/b/5dbc98dcc983a70728bd082d1a47546e.png"> of optimal solutions of the true problem is nonempty and is contained in <img class="mwe-math-fallback-image-inline tex" alt="C" src="//upload.wikimedia.org/math/0/d/6/0d61f8370cad1d412f80b84d143e1257.png"></li>
<li>the function <img class="mwe-math-fallback-image-inline tex" alt="g(x)" src="//upload.wikimedia.org/math/e/8/4/e84fec1e074026d6fa8e3155482c35c3.png"> is finite valued and continuous on <img class="mwe-math-fallback-image-inline tex" alt="C" src="//upload.wikimedia.org/math/0/d/6/0d61f8370cad1d412f80b84d143e1257.png"></li>
<li>the sequence of functions <img class="mwe-math-fallback-image-inline tex" alt="\hat{g}_N(x)" src="//upload.wikimedia.org/math/6/6/c/66c23b19f2ec9c8a812844a44143a8d2.png"> converges to <img class="mwe-math-fallback-image-inline tex" alt="g(x)" src="//upload.wikimedia.org/math/e/8/4/e84fec1e074026d6fa8e3155482c35c3.png"> with probability 1, as <img class="mwe-math-fallback-image-inline tex" alt="N \rightarrow \infty" src="//upload.wikimedia.org/math/e/c/4/ec4668d92fc0fc5cfc89732fbc840c0d.png">, uniformly in <img class="mwe-math-fallback-image-inline tex" alt="x\in C" src="//upload.wikimedia.org/math/7/1/e/71e2d1d76963d7609a1844748ec9c174.png"></li>
<li>for <img class="mwe-math-fallback-image-inline tex" alt="N" src="//upload.wikimedia.org/math/8/d/9/8d9c307cb7f3c4a32822a51922d1ceaa.png"> large enough the set <img class="mwe-math-fallback-image-inline tex" alt="\hat{S}_N" src="//upload.wikimedia.org/math/b/3/0/b30ddf686c05003c1801c1f1e4449474.png"> is nonempty and <img class="mwe-math-fallback-image-inline tex" alt="\hat{S}_N \subset C" src="//upload.wikimedia.org/math/b/5/e/b5e6082471179fc1a00e18bacefb8a1d.png"> with probability 1</li>
<li>if <img class="mwe-math-fallback-image-inline tex" alt=" x_N \in X_N" src="//upload.wikimedia.org/math/d/1/a/d1acaf5f5b5e3d9dcb22add3da866e9d.png"> and <img class="mwe-math-fallback-image-inline tex" alt=" x_N " src="//upload.wikimedia.org/math/f/a/e/fae0cb55362fb97a05a362a5ee425432.png"> converges with probability 1 to a point <img class="mwe-math-fallback-image-inline tex" alt=" x" src="//upload.wikimedia.org/math/9/d/d/9dd4e461268c8034f5c8564e155c67a6.png">, then <img class="mwe-math-fallback-image-inline tex" alt=" x \in X" src="//upload.wikimedia.org/math/7/3/5/735b05e6097f98da56f2ca14b8005d36.png"></li>
<li>for some point <img class="mwe-math-fallback-image-inline tex" alt=" x \in S^*" src="//upload.wikimedia.org/math/7/3/9/73938d95955f0fe689a35c532fc413bc.png"> there exists a sequence <img class="mwe-math-fallback-image-inline tex" alt=" x_N \in X_N" src="//upload.wikimedia.org/math/d/1/a/d1acaf5f5b5e3d9dcb22add3da866e9d.png"> such that <img class="mwe-math-fallback-image-inline tex" alt=" x_N \rightarrow x" src="//upload.wikimedia.org/math/b/5/5/b55a10b9a875296d34bed3d2185fa25b.png"> with probability 1.</li>
</ul>
</li>
</ol>
<ul>
<li>the set <img class="mwe-math-fallback-image-inline tex" alt="S" src="//upload.wikimedia.org/math/5/d/b/5dbc98dcc983a70728bd082d1a47546e.png"> of optimal solutions of the true problem is nonempty and is contained in <img class="mwe-math-fallback-image-inline tex" alt="C" src="//upload.wikimedia.org/math/0/d/6/0d61f8370cad1d412f80b84d143e1257.png"></li>
<li>the function <img class="mwe-math-fallback-image-inline tex" alt="g(x)" src="//upload.wikimedia.org/math/e/8/4/e84fec1e074026d6fa8e3155482c35c3.png"> is finite valued and continuous on <img class="mwe-math-fallback-image-inline tex" alt="C" src="//upload.wikimedia.org/math/0/d/6/0d61f8370cad1d412f80b84d143e1257.png"></li>
<li>the sequence of functions <img class="mwe-math-fallback-image-inline tex" alt="\hat{g}_N(x)" src="//upload.wikimedia.org/math/6/6/c/66c23b19f2ec9c8a812844a44143a8d2.png"> converges to <img class="mwe-math-fallback-image-inline tex" alt="g(x)" src="//upload.wikimedia.org/math/e/8/4/e84fec1e074026d6fa8e3155482c35c3.png"> with probability 1, as <img class="mwe-math-fallback-image-inline tex" alt="N \rightarrow \infty" src="//upload.wikimedia.org/math/e/c/4/ec4668d92fc0fc5cfc89732fbc840c0d.png">, uniformly in <img class="mwe-math-fallback-image-inline tex" alt="x\in C" src="//upload.wikimedia.org/math/7/1/e/71e2d1d76963d7609a1844748ec9c174.png"></li>
<li>for <img class="mwe-math-fallback-image-inline tex" alt="N" src="//upload.wikimedia.org/math/8/d/9/8d9c307cb7f3c4a32822a51922d1ceaa.png"> large enough the set <img class="mwe-math-fallback-image-inline tex" alt="\hat{S}_N" src="//upload.wikimedia.org/math/b/3/0/b30ddf686c05003c1801c1f1e4449474.png"> is nonempty and <img class="mwe-math-fallback-image-inline tex" alt="\hat{S}_N \subset C" src="//upload.wikimedia.org/math/b/5/e/b5e6082471179fc1a00e18bacefb8a1d.png"> with probability 1</li>
<li>if <img class="mwe-math-fallback-image-inline tex" alt=" x_N \in X_N" src="//upload.wikimedia.org/math/d/1/a/d1acaf5f5b5e3d9dcb22add3da866e9d.png"> and <img class="mwe-math-fallback-image-inline tex" alt=" x_N " src="//upload.wikimedia.org/math/f/a/e/fae0cb55362fb97a05a362a5ee425432.png"> converges with probability 1 to a point <img class="mwe-math-fallback-image-inline tex" alt=" x" src="//upload.wikimedia.org/math/9/d/d/9dd4e461268c8034f5c8564e155c67a6.png">, then <img class="mwe-math-fallback-image-inline tex" alt=" x \in X" src="//upload.wikimedia.org/math/7/3/5/735b05e6097f98da56f2ca14b8005d36.png"></li>
<li>for some point <img class="mwe-math-fallback-image-inline tex" alt=" x \in S^*" src="//upload.wikimedia.org/math/7/3/9/73938d95955f0fe689a35c532fc413bc.png"> there exists a sequence <img class="mwe-math-fallback-image-inline tex" alt=" x_N \in X_N" src="//upload.wikimedia.org/math/d/1/a/d1acaf5f5b5e3d9dcb22add3da866e9d.png"> such that <img class="mwe-math-fallback-image-inline tex" alt=" x_N \rightarrow x" src="//upload.wikimedia.org/math/b/5/5/b55a10b9a875296d34bed3d2185fa25b.png"> with probability 1.</li>
</ul>
<h3><span class="mw-headline" id="Asymptotics_of_the_SAA_optimal_value">Asymptotics of the SAA optimal value</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Stochastic_programming&amp;action=edit&amp;section=10" title="Edit section: Asymptotics of the SAA optimal value">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Suppose the sample <img class="mwe-math-fallback-image-inline tex" alt="\xi^1,\dots,\xi^N" src="//upload.wikimedia.org/math/4/9/7/497285f2fa65ca77ebdd33a461a5950a.png"> is i.i.d. and fix a point <img class="mwe-math-fallback-image-inline tex" alt="x \in X" src="//upload.wikimedia.org/math/7/3/5/735b05e6097f98da56f2ca14b8005d36.png">. Then the sample average estimator <img class="mwe-math-fallback-image-inline tex" alt="\hat{g}_N(x)" src="//upload.wikimedia.org/math/6/6/c/66c23b19f2ec9c8a812844a44143a8d2.png">, of <img class="mwe-math-fallback-image-inline tex" alt="g(x)" src="//upload.wikimedia.org/math/e/8/4/e84fec1e074026d6fa8e3155482c35c3.png">, is unbiased and have variance <img class="mwe-math-fallback-image-inline tex" alt="\frac{1}{N}\sigma^2(x)" src="//upload.wikimedia.org/math/e/e/b/eebc5d32871e0ce85c0ebca01977b66d.png">, where <img class="mwe-math-fallback-image-inline tex" alt="\sigma^2(x):=Var[Q(x,\xi)]" src="//upload.wikimedia.org/math/4/c/0/4c0a29ef9866efddca9be09a02954e49.png"> is supposed to be finite. Moreover, by the <a href="/wiki/Central_limit_theorem" title="Central limit theorem">central limit theorem</a> we have that</p>
<p>where <img class="mwe-math-fallback-image-inline tex" alt="\xrightarrow{\mathcal{D}}" src="//upload.wikimedia.org/math/8/5/8/858417ffc8cfb36d3313747577dbe8ae.png"> denotes convergence in <i>distribution</i> and <img class="mwe-math-fallback-image-inline tex" alt="Y_x" src="//upload.wikimedia.org/math/1/f/0/1f0cc6c860b291b49e1e1059e8a568d6.png"> has a normal distribution with mean <img class="mwe-math-fallback-image-inline tex" alt="0" src="//upload.wikimedia.org/math/c/f/c/cfcd208495d565ef66e7dff9f98764da.png"> and variance <img class="mwe-math-fallback-image-inline tex" alt="\sigma^2(x)" src="//upload.wikimedia.org/math/6/2/b/62b93eae914ba020173365ebe165be93.png">, written as <img class="mwe-math-fallback-image-inline tex" alt="\mathcal{N}(0,\sigma^2(0))" src="//upload.wikimedia.org/math/5/6/5/5655f431fe76dd64951ec13043eb5968.png">.</p>
<p>In other words, <img class="mwe-math-fallback-image-inline tex" alt="\hat{g}_N(x)" src="//upload.wikimedia.org/math/6/6/c/66c23b19f2ec9c8a812844a44143a8d2.png"> has <i>asymptotically normal</i> distribution, i.e., for large <img class="mwe-math-fallback-image-inline tex" alt="N" src="//upload.wikimedia.org/math/8/d/9/8d9c307cb7f3c4a32822a51922d1ceaa.png">, <img class="mwe-math-fallback-image-inline tex" alt="\hat{g}_N(x)" src="//upload.wikimedia.org/math/6/6/c/66c23b19f2ec9c8a812844a44143a8d2.png"> has approximately normal distribution with mean <img class="mwe-math-fallback-image-inline tex" alt="g(x)" src="//upload.wikimedia.org/math/e/8/4/e84fec1e074026d6fa8e3155482c35c3.png"> and variance <img class="mwe-math-fallback-image-inline tex" alt="\frac{1}{N}\sigma^2(x)" src="//upload.wikimedia.org/math/e/e/b/eebc5d32871e0ce85c0ebca01977b66d.png">. This leads to the following (approximate) <img class="mwe-math-fallback-image-inline tex" alt="100(1-\alpha)" src="//upload.wikimedia.org/math/3/a/5/3a5b355e21cd30f0487e3b58eaa85722.png">% confidence interval for <img class="mwe-math-fallback-image-inline tex" alt="f(x)" src="//upload.wikimedia.org/math/5/0/b/50bbd36e1fd2333108437a2ca378be62.png">:</p>
<p>where <img class="mwe-math-fallback-image-inline tex" alt="z_{\alpha/2}:=\Phi^{-1}(1-\alpha/2)" src="//upload.wikimedia.org/math/8/8/7/8874b7b289080f1ad8891e7f13ca706f.png"> (here <img class="mwe-math-fallback-image-inline tex" alt="\Phi(\cdot)" src="//upload.wikimedia.org/math/8/9/d/89d767697c1931e19b576aef0e242f9b.png"> denotes the cdf of the standard normal distribution) and</p>
<p>is the sample variance estimate of <img class="mwe-math-fallback-image-inline tex" alt="\sigma^2(x)" src="//upload.wikimedia.org/math/6/2/b/62b93eae914ba020173365ebe165be93.png">. That is, the error of estimation of <img class="mwe-math-fallback-image-inline tex" alt="g(x)" src="//upload.wikimedia.org/math/e/8/4/e84fec1e074026d6fa8e3155482c35c3.png"> is (stochastically) of order <img class="mwe-math-fallback-image-inline tex" alt=" O(\sqrt{N})" src="//upload.wikimedia.org/math/c/c/7/cc7837591b8c776fe4a17670ceb4a55e.png">.</p>
<h2><span class="mw-headline" id="Multistage_Portfolio_Optimization">Multistage Portfolio Optimization</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Stochastic_programming&amp;action=edit&amp;section=11" title="Edit section: Multistage Portfolio Optimization">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>We now present an example from finance of multi-stage stochastic programming. Suppose that at time <img class="mwe-math-fallback-image-inline tex" alt="t=0" src="//upload.wikimedia.org/math/3/e/8/3e8f7b0adf6d7024b951f29a18225e4a.png"> we have initial capital <img class="mwe-math-fallback-image-inline tex" alt="W_0" src="//upload.wikimedia.org/math/c/1/4/c1428343623f7f8b8f57e069953571e8.png"> to invest in <img class="mwe-math-fallback-image-inline tex" alt="n" src="//upload.wikimedia.org/math/7/b/8/7b8b965ad4bca0e41ab51de7b31363a1.png"> assets. Suppose further that we are allowed to rebalance our portfolio at times <img class="mwe-math-fallback-image-inline tex" alt="t=1,\dots,T-1" src="//upload.wikimedia.org/math/a/2/0/a2045e9902be9f11bd4db17adb23fcc8.png"> but without injecting additional cash into it. At each period <img class="mwe-math-fallback-image-inline tex" alt="t" src="//upload.wikimedia.org/math/e/3/5/e358efa489f58062f10dd7316b65649e.png"> we make a decision about redistributing the current wealth <img class="mwe-math-fallback-image-inline tex" alt="W_t" src="//upload.wikimedia.org/math/1/f/2/1f23b7344056336e50ed7ff881721734.png"> among the <img class="mwe-math-fallback-image-inline tex" alt="n" src="//upload.wikimedia.org/math/7/b/8/7b8b965ad4bca0e41ab51de7b31363a1.png"> assets. Let <img class="mwe-math-fallback-image-inline tex" alt="x_0=(x_{10},\dots,x_{n0})" src="//upload.wikimedia.org/math/2/d/8/2d8161ccbde973fe74fceefb9ac16259.png"> be the initial amounts invested in the n assets. We require that each <img class="mwe-math-fallback-image-inline tex" alt="x_{i0}" src="//upload.wikimedia.org/math/e/f/4/ef4dfc11e8543e58d096f96b65d7ecf4.png"> is nonnegative and that the balance equation <img class="mwe-math-fallback-image-inline tex" alt="\sum_{i=1}^{n}x_{i0}=W_0" src="//upload.wikimedia.org/math/f/b/f/fbf10251cd070bcf66c393bc7d6b46c7.png"> should hold.</p>
<p>Consider the total returns <img class="mwe-math-fallback-image-inline tex" alt="\xi_t=(\xi_{1t},\dots,\xi_{nt})" src="//upload.wikimedia.org/math/e/5/8/e5853762325ef027356f89709d5d188f.png"> for each period <img class="mwe-math-fallback-image-inline tex" alt="t=1,\dots,T" src="//upload.wikimedia.org/math/8/1/9/8193acb8dd86e557705e79faafbd9a8b.png">. This forms a vector-valued random process <img class="mwe-math-fallback-image-inline tex" alt="\xi_1,\dots,\xi_T" src="//upload.wikimedia.org/math/2/4/d/24dbe685c0a5818db936b0afc595e3ba.png">. At time period <img class="mwe-math-fallback-image-inline tex" alt="t=1" src="//upload.wikimedia.org/math/b/7/3/b73c3280b6f85a6ac520af103083f535.png">, we can rebalance the portfolio by specifying the amounts <img class="mwe-math-fallback-image-inline tex" alt="x_1=(x_{11},\dots,x_{n1})" src="//upload.wikimedia.org/math/f/b/1/fb1317f61b3823136e2a171d4f80da92.png"> invested in the respective assets. At that time the returns in the first period have been realized so it is reasonable to use this information in the rebalancing decision. Thus, the second-stage decisions, at time <img class="mwe-math-fallback-image-inline tex" alt="t=1" src="//upload.wikimedia.org/math/b/7/3/b73c3280b6f85a6ac520af103083f535.png">, are actually functions of realization of the random vector <img class="mwe-math-fallback-image-inline tex" alt="\xi_1" src="//upload.wikimedia.org/math/e/f/4/ef4f8f1b3a8cd0bad7687a799eede69c.png">, i.e., <img class="mwe-math-fallback-image-inline tex" alt="x_1=x_1(\xi_1)" src="//upload.wikimedia.org/math/6/1/7/6175b12228fbe3342bc65df3d1267916.png">. Similarly, at time <img class="mwe-math-fallback-image-inline tex" alt="t" src="//upload.wikimedia.org/math/e/3/5/e358efa489f58062f10dd7316b65649e.png"> the decision <img class="mwe-math-fallback-image-inline tex" alt="x_t=(x_{1t},\dots,x_{nt})" src="//upload.wikimedia.org/math/a/f/a/afac478410fe4e7d4acc96debbc9425b.png"> is a function <img class="mwe-math-fallback-image-inline tex" alt="x_t=x_t(\xi_{[t]})" src="//upload.wikimedia.org/math/c/5/9/c59634c6b60833ac426fa573666240ef.png"> of the available information given by <img class="mwe-math-fallback-image-inline tex" alt="\xi_{[t]}=(\xi_{1},\dots,\xi_{t})" src="//upload.wikimedia.org/math/b/2/e/b2e327c1ef372276632fd8a9c7e619ea.png"> the history of the random process up to time <img class="mwe-math-fallback-image-inline tex" alt="t" src="//upload.wikimedia.org/math/e/3/5/e358efa489f58062f10dd7316b65649e.png">. A sequence of functions <img class="mwe-math-fallback-image-inline tex" alt="x_t=x_t(\xi_{[t]})" src="//upload.wikimedia.org/math/c/5/9/c59634c6b60833ac426fa573666240ef.png">, <img class="mwe-math-fallback-image-inline tex" alt="t=0,\dots,T-1" src="//upload.wikimedia.org/math/3/3/5/3351936df6154c45552613ecd8dcfa48.png">, with <img class="mwe-math-fallback-image-inline tex" alt="x_0" src="//upload.wikimedia.org/math/0/b/2/0b21a666a81629962ade8afd967826ed.png"> being constant, defines an <i>implementable policy</i> of the decision process. It is said that such a policy is <i>feasible</i> if it satisfies the model constraints with probability 1, i.e., the nonnegativity constraints <img class="mwe-math-fallback-image-inline tex" alt="x_{it}(\xi_{[t]})\geq 0" src="//upload.wikimedia.org/math/1/5/1/1510eaa2f553c182a140fad3fc0a4e0f.png">, <img class="mwe-math-fallback-image-inline tex" alt="i=1,\dots,n" src="//upload.wikimedia.org/math/4/d/e/4de0f8ba6b80f41fe9152789af172da1.png">, <img class="mwe-math-fallback-image-inline tex" alt="t=0,\dots,T-1" src="//upload.wikimedia.org/math/3/3/5/3351936df6154c45552613ecd8dcfa48.png">, and the balance of wealth constraints,</p>
<p><img class="mwe-math-fallback-image-inline tex" alt="
\sum_{i=1}^{n}x_{it}(\xi_{[t]}) = W_t,
" src="//upload.wikimedia.org/math/a/f/8/af83f62b335b387ae7e4c3c755b52c38.png"></p>
<p>where in period <img class="mwe-math-fallback-image-inline tex" alt="t=1,\dots,T" src="//upload.wikimedia.org/math/8/1/9/8193acb8dd86e557705e79faafbd9a8b.png"> the wealth <img class="mwe-math-fallback-image-inline tex" alt="W_t" src="//upload.wikimedia.org/math/1/f/2/1f23b7344056336e50ed7ff881721734.png"> is given by</p>
<p><img class="mwe-math-fallback-image-inline tex" alt="
W_t = \sum_{i=1}^{n}\xi_{it} x_{i,t-1}(\xi_{[t-1]}),
" src="//upload.wikimedia.org/math/2/4/b/24b252899181231eba1f8825e67618ea.png"></p>
<p>which depends on the realization of the random process and the decisions up to time <img class="mwe-math-fallback-image-inline tex" alt="t" src="//upload.wikimedia.org/math/e/3/5/e358efa489f58062f10dd7316b65649e.png">.</p>
<p>Suppose the objective is to maximize the expected utility of this wealth at the last period, that is, to consider the problem</p>
<p><img class="mwe-math-fallback-image-inline tex" alt="
\max E[U(W_T)].
" src="//upload.wikimedia.org/math/8/d/8/8d8ceae3d00a0bd3f2fe0ad492678729.png"></p>
<p>This is a multistage stochastic programming problem, where stages are numbered from <img class="mwe-math-fallback-image-inline tex" alt="t=0" src="//upload.wikimedia.org/math/3/e/8/3e8f7b0adf6d7024b951f29a18225e4a.png"> to <img class="mwe-math-fallback-image-inline tex" alt="t=T-1" src="//upload.wikimedia.org/math/c/f/1/cf1811ee19ec04510ff7bb985dc28d17.png">. Optimization is performed over all implementable and feasible policies. To complete the problem description one also needs to define the probability distribution of the random process <img class="mwe-math-fallback-image-inline tex" alt="\xi_1,\dots,\xi_T" src="//upload.wikimedia.org/math/2/4/d/24dbe685c0a5818db936b0afc595e3ba.png">. This can be done in various ways. For example, one can construct a particular scenario tree defining time evolution of the process. If at every stage the random return of each asset is allowed to have two continuations, independent of other assets, then the total number of scenarios is <img class="mwe-math-fallback-image-inline tex" alt="2^{nT}" src="//upload.wikimedia.org/math/f/3/5/f35330a591d52473c6a6e971fa3a0034.png">.</p>
<p>In order to write <a href="/wiki/Dynamic_programming" title="Dynamic programming">dynamic programming</a> equations, consider the above multistage problem backward in time. At the last stage <img class="mwe-math-fallback-image-inline tex" alt="t=T-1" src="//upload.wikimedia.org/math/c/f/1/cf1811ee19ec04510ff7bb985dc28d17.png">, a realization <img class="mwe-math-fallback-image-inline tex" alt="\xi_{[T-1]}=(\xi_{1},\dots,\xi_{T-1})" src="//upload.wikimedia.org/math/9/b/e/9be3f5000b48028555274c7e8db7d6f7.png"> of the random process is known and <img class="mwe-math-fallback-image-inline tex" alt="x_{T-2}" src="//upload.wikimedia.org/math/6/b/f/6bfa815c945e1e8e7dc4d08d00416554.png"> has been chosen. Therefore, one needs to solve the following problem</p>
<p><img class="mwe-math-fallback-image-inline tex" alt="
\begin{array}{lrclr}
\max\limits_{x_{T-1}}   &amp; E[U(W_T)|\xi_{[T-1]}]    &amp;   \\
\text{subject to} &amp; W_T   &amp;=&amp;    \sum_{i=1}^{n}\xi_{iT}x_{i,T-1} \\
                    &amp;\sum_{i=1}^{n}x_{i,T-1}&amp;=&amp;W_{T-1}\\
		    &amp; x_{T-1}     &amp;\geq&amp; 0
\end{array}
" src="//upload.wikimedia.org/math/d/7/8/d784a26949d29f7673cdc834b94a4521.png"></p>
<p>where <img class="mwe-math-fallback-image-inline tex" alt="E[U(W_T)|\xi_{[T-1]}]" src="//upload.wikimedia.org/math/5/3/1/531fd941c3cf4a90379e737b3fc1fd18.png"> denotes the conditional expectation of <img class="mwe-math-fallback-image-inline tex" alt="U(W_T)" src="//upload.wikimedia.org/math/0/6/7/067bbb4a51ad06e50d17f81fa73828ae.png"> given <img class="mwe-math-fallback-image-inline tex" alt="\xi_{[T-1]}" src="//upload.wikimedia.org/math/6/b/2/6b28d68b9340ae7433ea57db45bce290.png">. The optimal value of the above problem depends on <img class="mwe-math-fallback-image-inline tex" alt="W_{T-1}" src="//upload.wikimedia.org/math/8/6/8/868bcf2ba6993670ecef7d0bfb43f276.png"> and <img class="mwe-math-fallback-image-inline tex" alt="\xi_{[T-1]}" src="//upload.wikimedia.org/math/6/b/2/6b28d68b9340ae7433ea57db45bce290.png"> and is denoted <img class="mwe-math-fallback-image-inline tex" alt="Q_{T-1}(W_{T-1},\xi_{[T-1]})" src="//upload.wikimedia.org/math/5/6/a/56a0787d2287acbc1a085fb2af934f57.png">.</p>
<p>Similarly, at stages <img class="mwe-math-fallback-image-inline tex" alt="t=T-2,\dots,1" src="//upload.wikimedia.org/math/b/c/8/bc8a4f3d8efe06e14dbdca8916c477bd.png">, one should solve the problem</p>
<p><img class="mwe-math-fallback-image-inline tex" alt="
\begin{array}{lrclr}
\max\limits_{x_{t}}   &amp; E[Q_{t+1}(W_{t+1},\xi_{[t+1]})|\xi_{[t]}]    &amp;   \\
\text{subject to} &amp; W_{t+1}   &amp;=&amp;    \sum_{i=1}^{n}\xi_{i,t+1}x_{i,t} \\
                    &amp;\sum_{i=1}^{n}x_{i,t}&amp;=&amp;W_{t}\\
		    &amp; x_{t}     &amp;\geq&amp; 0
\end{array}
" src="//upload.wikimedia.org/math/f/7/4/f7419680184a3d1b4b3fb2425933b84c.png"></p>
<p>whose optimal value is denoted by <img class="mwe-math-fallback-image-inline tex" alt="Q_{t}(W_{t},\xi_{[t]})" src="//upload.wikimedia.org/math/2/0/5/205eaa3519f8286756aa12367755ea80.png">. Finally, at stage <img class="mwe-math-fallback-image-inline tex" alt="t=0" src="//upload.wikimedia.org/math/3/e/8/3e8f7b0adf6d7024b951f29a18225e4a.png">, one solves the problem</p>
<p><img class="mwe-math-fallback-image-inline tex" alt="
\begin{array}{lrclr}
\max\limits_{x_{0}}   &amp; E[Q_{1}(W_{1},\xi_{[1]})]    &amp;   \\
\text{subject to} &amp; W_{1}   &amp;=&amp;    \sum_{i=1}^{n}\xi_{i,1}x_{i0} \\
                    &amp;\sum_{i=1}^{n}x_{i0}&amp;=&amp;W_{0}\\
		    &amp; x_{0}     &amp;\geq&amp; 0
\end{array}
" src="//upload.wikimedia.org/math/b/7/e/b7ef17d5d17926655f1a0e708ec467dc.png"></p>
<h3><span class="mw-headline" id="Stagewise_independent_random_process">Stagewise independent random process</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Stochastic_programming&amp;action=edit&amp;section=12" title="Edit section: Stagewise independent random process">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>For a general distribution of the process <img class="mwe-math-fallback-image-inline tex" alt="\xi_t" src="//upload.wikimedia.org/math/c/e/f/cefd328c3e84e0165e92015b499ed122.png">, it may be hard to solve these dynamic programming equations. The situation simplifies dramatically if the process <img class="mwe-math-fallback-image-inline tex" alt="\xi_t" src="//upload.wikimedia.org/math/c/e/f/cefd328c3e84e0165e92015b499ed122.png"> is stagewise independent, i.e., <img class="mwe-math-fallback-image-inline tex" alt="\xi_t" src="//upload.wikimedia.org/math/c/e/f/cefd328c3e84e0165e92015b499ed122.png"> is (stochastically) independent of <img class="mwe-math-fallback-image-inline tex" alt="\xi_1,\dots,\xi_{t-1}" src="//upload.wikimedia.org/math/b/6/a/b6ace41a9b157a0973ebb00162336463.png"> for <img class="mwe-math-fallback-image-inline tex" alt="t=2,\dots,T" src="//upload.wikimedia.org/math/7/3/1/7319876b95222e5b4a245b50b4a3231c.png">. In this case, the corresponding conditional expectations become unconditional expectations, and the function <img class="mwe-math-fallback-image-inline tex" alt="Q_t(W_t)" src="//upload.wikimedia.org/math/1/5/d/15dc7ea43b2839c0250a8cd2520d5229.png">, <img class="mwe-math-fallback-image-inline tex" alt="t=1,\dots,T-1" src="//upload.wikimedia.org/math/a/2/0/a2045e9902be9f11bd4db17adb23fcc8.png"> does not depend on <img class="mwe-math-fallback-image-inline tex" alt="\xi_{[t]}" src="//upload.wikimedia.org/math/9/6/c/96cd9075848d14e54640f283ba9b4fe5.png">. That is, <img class="mwe-math-fallback-image-inline tex" alt="Q_{T-1}(W_{T-1})" src="//upload.wikimedia.org/math/6/5/a/65a2e3e06131b25df141f4921306b51f.png"> is the optimal value of the problem</p>
<p><img class="mwe-math-fallback-image-inline tex" alt="
\begin{array}{lrclr}
\max\limits_{x_{T-1}}   &amp; E[U(W_T)]    &amp;   \\
\text{subject to} &amp; W_T   &amp;=&amp;    \sum_{i=1}^{n}\xi_{iT}x_{i,T-1} \\
                    &amp;\sum_{i=1}^{n}x_{i,T-1}&amp;=&amp;W_{T-1}\\
		    &amp; x_{T-1}     &amp;\geq&amp; 0
\end{array}
" src="//upload.wikimedia.org/math/4/6/a/46a6e9e2dc56eb9a9961c2eefb9948ec.png"></p>
<p>and <img class="mwe-math-fallback-image-inline tex" alt="Q_t(W_t)" src="//upload.wikimedia.org/math/1/5/d/15dc7ea43b2839c0250a8cd2520d5229.png"> is the optimal value of</p>
<p><img class="mwe-math-fallback-image-inline tex" alt="
\begin{array}{lrclr}
\max\limits_{x_{t}}   &amp; E[Q_{t+1}(W_{t+1})]    &amp;   \\
\text{subject to} &amp; W_{t+1}   &amp;=&amp;    \sum_{i=1}^{n}\xi_{i,t+1}x_{i,t} \\
                    &amp;\sum_{i=1}^{n}x_{i,t}&amp;=&amp;W_{t}\\
		    &amp; x_{t}     &amp;\geq&amp; 0
\end{array}
" src="//upload.wikimedia.org/math/3/d/0/3d06ac0233f66acb8f2608a6e5cb4bee.png"></p>
<p>for <img class="mwe-math-fallback-image-inline tex" alt="t=T-2,\dots,1" src="//upload.wikimedia.org/math/b/c/8/bc8a4f3d8efe06e14dbdca8916c477bd.png">.</p>
<h2><span class="mw-headline" id="Biological_applications">Biological applications</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Stochastic_programming&amp;action=edit&amp;section=13" title="Edit section: Biological applications">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Stochastic <a href="/wiki/Dynamic_programming" title="Dynamic programming">dynamic programming</a> is frequently used to model <a href="/wiki/Ethology" title="Ethology">animal behaviour</a> in such fields as <a href="/wiki/Behavioural_ecology" title="Behavioural ecology" class="mw-redirect">behavioural ecology</a>.<sup id="cite_ref-7" class="reference"><a href="#cite_note-7"><span>[</span>7<span>]</span></a></sup><sup id="cite_ref-8" class="reference"><a href="#cite_note-8"><span>[</span>8<span>]</span></a></sup> Empirical tests of models of <a href="/wiki/Optimal_foraging_theory" title="Optimal foraging theory">optimal foraging</a>, <a href="/wiki/Biological_life_cycle" title="Biological life cycle">life-history</a> transitions such as <a href="/wiki/Fledge" title="Fledge">fledging in birds</a> and egg laying in <a href="/wiki/Parasitoid" title="Parasitoid">parasitoid</a> wasps have shown the value of this modelling technique in explaining the evolution of behavioural decision making. These models are typically many-staged, rather than two-staged.</p>
<h2><span class="mw-headline" id="Economic_applications">Economic applications</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Stochastic_programming&amp;action=edit&amp;section=14" title="Edit section: Economic applications">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Stochastic dynamic programming is a useful tool in understanding decision making under uncertainty. The accumulation of capital stock under uncertainty is one example; often it is used by resource economists to analyze <a href="/wiki/Bioeconomics" title="Bioeconomics" class="mw-disambig">bioeconomic problems</a><sup id="cite_ref-9" class="reference"><a href="#cite_note-9"><span>[</span>9<span>]</span></a></sup> where the uncertainty enters in such as weather, etc.</p>
<h2><span class="mw-headline" id="Software_tools">Software tools</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Stochastic_programming&amp;action=edit&amp;section=15" title="Edit section: Software tools">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<h3><span class="mw-headline" id="Modelling_languages">Modelling languages</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Stochastic_programming&amp;action=edit&amp;section=16" title="Edit section: Modelling languages">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>All discrete stochastic programming problems can be represented with any <a href="/wiki/Algebraic_modeling_language" title="Algebraic modeling language">algebraic modeling language</a>, manually implementing explicit or implicit non-anticipativity to make sure the resulting model respects the structure of the information made available at each stage. An instance of an SP problem generated by a general modelling language tends to grow quite large (linearly in the number of scenarios), and its matrix looses the structure that is intrinsic to this class of problems, which could otherwise be exploited at solution time by specific decomposition algorithms. Extensions to modelling languages specifically designed for SP are starting to appear, see:</p>
<ul>
<li><a href="/wiki/AIMMS" title="AIMMS">AIMMS</a> - supports the definition of SP problems</li>
<li><a href="/w/index.php?title=FuncDesigner&amp;action=edit&amp;redlink=1" class="new" title="FuncDesigner (page does not exist)">FuncDesigner</a> - free software that includes stochastic programming and optimization by <a href="/w/index.php?title=OpenOpt&amp;action=edit&amp;redlink=1" class="new" title="OpenOpt (page does not exist)">OpenOpt</a> solvers; <a rel="nofollow" class="external text" href="http://openopt.org/StochasticProgramming#Local_nonlinear_optimization_example">example1</a>, <a rel="nofollow" class="external text" href="http://openopt.org/StochasticProgramming#Global_nonlinear_optimization_example">example2</a>, <a rel="nofollow" class="external text" href="http://openopt.org/StochasticProgramming#Example_with_15_unknown_variables">example3</a></li>
<li><a href="/wiki/SAMPL" title="SAMPL">SAMPL</a> - a set of extensions to <a href="/wiki/AMPL" title="AMPL">AMPL</a> specifically designed to express stochastic programs (includes syntax for chance constraints, integrated chance constraints and <a href="/wiki/Robust_optimization" title="Robust optimization">Robust Optimization</a> problems)</li>
</ul>
<p>They both can generate SMPS instance level format, which conveys in a non-redundant form the structure of the problem to the solver.</p>
<h3><span class="mw-headline" id="Solvers">Solvers</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Stochastic_programming&amp;action=edit&amp;section=17" title="Edit section: Solvers">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<ul>
<li><a href="/wiki/FortSP" title="FortSP">FortSP</a> - solver for stochastic programming problems; it accepts SMPS input and implements various decomposition algorithms.</li>
<li>NEOS Solvers - Three solvers are available in the <a rel="nofollow" class="external text" href="http://neos.mcs.anl.gov/neos/solvers/">Neos Server</a>: Bouncing Nested Benders Solvers (BNBS) for multi-stage stochastic linear programs, ddsip for two-stage stochastic programs with integer recourse, and Stochastic Decomposition (SD) for two-stage stochastic linear programs.</li>
<li><a rel="nofollow" class="external text" href="http://www.coin-or.org/projects/Smi.xml">COIN-OR Stochastic Modeling Interface</a> - An open source project within <a href="/wiki/COIN-OR" title="COIN-OR">COIN-OR</a>. It can read Stochastic MPS<sup id="cite_ref-10" class="reference"><a href="#cite_note-10"><span>[</span>10<span>]</span></a></sup> input format as well as supports direct interfaces for scenario input, and generates the deterministic equivalent linear program for solution by COIN-OR solvers.</li>
</ul>
<h2><span class="mw-headline" id="See_also">See also</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Stochastic_programming&amp;action=edit&amp;section=18" title="Edit section: See also">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul>
<li><a href="/wiki/Probabilistic-based_design_optimization" title="Probabilistic-based design optimization">Probabilistic-based design optimization</a></li>
<li><a href="/wiki/SAMPL" title="SAMPL">SAMPL algebraic modeling language</a></li>
<li><a href="/wiki/Scenario_optimization" title="Scenario optimization">Scenario optimization</a></li>
<li><a href="/wiki/Stochastic_optimization" title="Stochastic optimization">Stochastic optimization</a></li>
</ul>
<h2><span class="mw-headline" id="References">References</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Stochastic_programming&amp;action=edit&amp;section=19" title="Edit section: References">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ol class="references">
<li id="cite_note-1"><span class="mw-cite-backlink"><b><a href="#cite_ref-1">^</a></b></span> <span class="reference-text"><span class="citation book">Shapiro, Alexander; Dentcheva, Darinka; <a href="/wiki/Andrzej_Piotr_Ruszczy%C5%84ski" title="Andrzej Piotr Ruszczyński">Ruszczyński</a>, Andrzej (2009). <a rel="nofollow" class="external text" href="http://www2.isye.gatech.edu/people/faculty/Alex_Shapiro/SPbook.pdf"><i>Lectures on stochastic programming: Modeling and theory</i></a>. MPS/SIAM Series on Optimization <b>9</b>. Philadelphia, PA: Society for Industrial and Applied Mathematics (SIAM). Mathematical Programming Society (MPS). pp. xvi+436. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a> <a href="/wiki/Special:BookSources/978-0-89871-687-0" title="Special:BookSources/978-0-89871-687-0">978-0-89871-687-0</a>. <a href="/wiki/Mathematical_Reviews" title="Mathematical Reviews">MR</a> <a rel="nofollow" class="external text" href="//www.ams.org/mathscinet-getitem?mr=2562798">2562798</a>.</span><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStochastic+programming&amp;rft.au=Dentcheva%2C+Darinka&amp;rft.aufirst=Alexander&amp;rft.aulast=Shapiro&amp;rft.au=Ruszczy%C5%84ski%2C+Andrzej&amp;rft.au=Shapiro%2C+Alexander&amp;rft.btitle=Lectures+on+stochastic+programming%3A+Modeling+and+theory&amp;rft.date=2009&amp;rft.genre=book&amp;rft_id=http%3A%2F%2Fwww2.isye.gatech.edu%2Fpeople%2Ffaculty%2FAlex_Shapiro%2FSPbook.pdf&amp;rft.isbn=978-0-89871-687-0&amp;rft.mr=2562798&amp;rft.pages=xvi%2B436&amp;rft.place=Philadelphia%2C+PA&amp;rft.pub=Society+for+Industrial+and+Applied+Mathematics+%28SIAM%29&amp;rft.series=MPS%2FSIAM+Series+on+Optimization&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.volume=9" class="Z3988"><span style="display:none;"> </span></span></span></li>
<li id="cite_note-2"><span class="mw-cite-backlink"><b><a href="#cite_ref-2">^</a></b></span> <span class="reference-text">Stein W. Wallace and William T. Ziemba (eds.). <i>Applications of Stochastic Programming</i>. MPS-SIAM Book Series on Optimization 5, 2005.</span></li>
<li id="cite_note-3"><span class="mw-cite-backlink"><b><a href="#cite_ref-3">^</a></b></span> <span class="reference-text">Applications of stochastic programming are described at the following website, <a rel="nofollow" class="external text" href="http://stoprog.org">Stochastic Programming Community</a>.</span></li>
<li id="cite_note-4"><span class="mw-cite-backlink"><b><a href="#cite_ref-4">^</a></b></span> <span class="reference-text"><span class="citation book">Shapiro, Alexander; Philpott, Andy. <a rel="nofollow" class="external text" href="http://www2.isye.gatech.edu/people/faculty/Alex_Shapiro/TutorialSP.pdf"><i>A tutorial on Stochastic Programming</i></a>.</span><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStochastic+programming&amp;rft.aufirst=Alexander&amp;rft.aulast=Shapiro&amp;rft.au=Philpott%2C+Andy&amp;rft.au=Shapiro%2C+Alexander&amp;rft.btitle=A+tutorial+on+Stochastic+Programming&amp;rft.genre=book&amp;rft_id=http%3A%2F%2Fwww2.isye.gatech.edu%2Fpeople%2Ffaculty%2FAlex_Shapiro%2FTutorialSP.pdf&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook" class="Z3988"><span style="display:none;"> </span></span></span></li>
<li id="cite_note-neos-5"><span class="mw-cite-backlink"><b><a href="#cite_ref-neos_5-0">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external free" href="http://www.neos-server.org/neos/">http://www.neos-server.org/neos/</a></span></li>
<li id="cite_note-6"><span class="mw-cite-backlink"><b><a href="#cite_ref-6">^</a></b></span> <span class="reference-text"><span class="citation book"><a href="/wiki/Andrzej_Piotr_Ruszczy%C5%84ski" title="Andrzej Piotr Ruszczyński">Ruszczyński</a>, Andrzej; Shapiro, Alexander (2003). <i>Stochastic Programming</i>. Handbooks in Operations Research and Management Science <b>10</b>. Philadelphia: <a href="/wiki/Elsevier" title="Elsevier">Elsevier</a>. p. 700. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a> <a href="/wiki/Special:BookSources/978-0444508546" title="Special:BookSources/978-0444508546">978-0444508546</a>.</span><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStochastic+programming&amp;rft.aufirst=Andrzej&amp;rft.aulast=Ruszczy%C5%84ski&amp;rft.au=Ruszczy%C5%84ski%2C+Andrzej&amp;rft.au=Shapiro%2C+Alexander&amp;rft.btitle=Stochastic+Programming&amp;rft.date=2003&amp;rft.genre=book&amp;rft.isbn=978-0444508546&amp;rft.pages=700&amp;rft.place=Philadelphia&amp;rft.pub=Elsevier&amp;rft.series=Handbooks+in+Operations+Research+and+Management+Science&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.volume=10" class="Z3988"><span style="display:none;"> </span></span></span></li>
<li id="cite_note-7"><span class="mw-cite-backlink"><b><a href="#cite_ref-7">^</a></b></span> <span class="reference-text">Mangel, M. &amp; Clark, C. W. 1988. <i>Dynamic modeling in behavioral ecology.</i> Princeton University Press <a href="/wiki/Special:BookSources/0691085064" class="internal mw-magiclink-isbn">ISBN 0-691-08506-4</a></span></li>
<li id="cite_note-8"><span class="mw-cite-backlink"><b><a href="#cite_ref-8">^</a></b></span> <span class="reference-text">Houston, A. I &amp; McNamara, J. M. 1999. <i>Models of adaptive behaviour: an approach based on state</i>. Cambridge University Press <a href="/wiki/Special:BookSources/0521655390" class="internal mw-magiclink-isbn">ISBN 0-521-65539-0</a></span></li>
<li id="cite_note-9"><span class="mw-cite-backlink"><b><a href="#cite_ref-9">^</a></b></span> <span class="reference-text">Howitt, R., Msangi, S., Reynaud, A and K. Knapp. 2002. <a rel="nofollow" class="external text" href="http://www.agecon.ucdavis.edu/aredepart/facultydocs/Howitt/Polyapprox3a.pdf">"Using Polynomial Approximations to Solve Stochastic Dynamic Programming Problems: or A "Betty Crocker " Approach to SDP."</a> University of California, Davis, Department of Agricultural and Resource Economics Working Paper.</span></li>
<li id="cite_note-10"><span class="mw-cite-backlink"><b><a href="#cite_ref-10">^</a></b></span> <span class="reference-text">J.R. Birge, M.A.H. Dempster, H.I. Gassmann, E.A. Gunn, A.J. King and S.W. Wallace, <i>A standard input format for multiperiod stochastic linear programs</i>, COAL Newsletter #17 (1987) pp. 1-19.</span></li>
</ol>
<h2><span class="mw-headline" id="Further_reading">Further reading</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Stochastic_programming&amp;action=edit&amp;section=20" title="Edit section: Further reading">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul>
<li>John R. Birge and François V. Louveaux. <i>Introduction to Stochastic Programming</i>. Springer Verlag, New York, 1997.</li>
</ul>
<ul>
<li><span class="citation book">Kall, Peter; Wallace, Stein W. (1994). <a rel="nofollow" class="external text" href="http://stoprog.org/index.html?introductions.html"><i>Stochastic programming</i></a>. Wiley-Interscience Series in Systems and Optimization. Chichester: John Wiley &amp; Sons, Ltd. pp. xii+307. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a> <a href="/wiki/Special:BookSources/0-471-95158-7" title="Special:BookSources/0-471-95158-7">0-471-95158-7</a>. <a href="/wiki/Mathematical_Reviews" title="Mathematical Reviews">MR</a> <a rel="nofollow" class="external text" href="//www.ams.org/mathscinet-getitem?mr=1315300">1315300</a>.</span><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStochastic+programming&amp;rft.aufirst=Peter&amp;rft.au=Kall%2C+Peter&amp;rft.aulast=Kall&amp;rft.au=Wallace%2C+Stein+W.&amp;rft.btitle=Stochastic+programming&amp;rft.date=1994&amp;rft.genre=book&amp;rft_id=http%3A%2F%2Fstoprog.org%2Findex.html%3Fintroductions.html&amp;rft.isbn=0-471-95158-7&amp;rft.mr=1315300&amp;rft.pages=xii%2B307&amp;rft.place=Chichester&amp;rft.pub=John+Wiley+%26+Sons%2C+Ltd.&amp;rft.series=Wiley-Interscience+Series+in+Systems+and+Optimization&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook" class="Z3988"><span style="display:none;"> </span></span></li>
</ul>
<ul>
<li>G. Ch. Pflug: <i>Optimization of Stochastic Models. The Interface between Simulation and Optimization</i>. Kluwer, Dordrecht, 1996.</li>
</ul>
<ul>
<li><a href="/wiki/Andras_Prekopa" title="Andras Prekopa" class="mw-redirect">Andras Prekopa</a>. Stochastic Programming. Kluwer Academic Publishers, Dordrecht, 1995.</li>
</ul>
<ul>
<li><a href="/wiki/Andrzej_Piotr_Ruszczy%C5%84ski" title="Andrzej Piotr Ruszczyński">Andrzej Ruszczynski</a> and Alexander Shapiro (eds.) (2003) <i>Stochastic Programming</i>. Handbooks in Operations Research and Management Science, Vol. 10, Elsevier.</li>
</ul>
<ul>
<li><span class="citation book">Shapiro, Alexander; <a href="/wiki/Darinka_Dentcheva" title="Darinka Dentcheva">Dentcheva</a>, Darinka; <a href="/wiki/Andrzej_Piotr_Ruszczy%C5%84ski" title="Andrzej Piotr Ruszczyński">Ruszczyński</a>, Andrzej (2009). <a rel="nofollow" class="external text" href="http://www2.isye.gatech.edu/people/faculty/Alex_Shapiro/SPbook.pdf"><i>Lectures on stochastic programming: Modeling and theory</i></a>. MPS/SIAM Series on Optimization <b>9</b>. Philadelphia, PA: Society for Industrial and Applied Mathematics (SIAM). Mathematical Programming Society (MPS). pp. xvi+436. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a> <a href="/wiki/Special:BookSources/978-0-89871-687-0" title="Special:BookSources/978-0-89871-687-0">978-0-89871-687-0</a>. <a href="/wiki/Mathematical_Reviews" title="Mathematical Reviews">MR</a> <a rel="nofollow" class="external text" href="//www.ams.org/mathscinet-getitem?mr=2562798">2562798</a>.</span><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStochastic+programming&amp;rft.au=Dentcheva%2C+Darinka&amp;rft.aufirst=Alexander&amp;rft.aulast=Shapiro&amp;rft.au=Ruszczy%C5%84ski%2C+Andrzej&amp;rft.au=Shapiro%2C+Alexander&amp;rft.btitle=Lectures+on+stochastic+programming%3A+Modeling+and+theory&amp;rft.date=2009&amp;rft.genre=book&amp;rft_id=http%3A%2F%2Fwww2.isye.gatech.edu%2Fpeople%2Ffaculty%2FAlex_Shapiro%2FSPbook.pdf&amp;rft.isbn=978-0-89871-687-0&amp;rft.mr=2562798&amp;rft.pages=xvi%2B436&amp;rft.place=Philadelphia%2C+PA&amp;rft.pub=Society+for+Industrial+and+Applied+Mathematics+%28SIAM%29&amp;rft.series=MPS%2FSIAM+Series+on+Optimization&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.volume=9" class="Z3988"><span style="display:none;"> </span></span></li>
</ul>
<ul>
<li>Stein W. Wallace and William T. Ziemba (eds.) (2005) <i>Applications of Stochastic Programming</i>. MPS-SIAM Book Series on Optimization 5</li>
</ul>
<ul>
<li><span class="citation book">King, Alan J.; Wallace, Stein W. (2012). <a rel="nofollow" class="external text" href="http://www.springer.com/mathematics/probability/book/978-0-387-87816-4"><i>Modeling with Stochastic Programming</i></a>. Springer Series in Operations Research and Financial Engineering. New York: Springer. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a> <a href="/wiki/Special:BookSources/978-0-387-87816-4" title="Special:BookSources/978-0-387-87816-4">978-0-387-87816-4</a>.</span><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStochastic+programming&amp;rft.aufirst=Alan+J.&amp;rft.au=King%2C+Alan+J.&amp;rft.aulast=King&amp;rft.au=Wallace%2C+Stein+W.&amp;rft.btitle=Modeling+with+Stochastic+Programming&amp;rft.date=2012&amp;rft.genre=book&amp;rft_id=http%3A%2F%2Fwww.springer.com%2Fmathematics%2Fprobability%2Fbook%2F978-0-387-87816-4&amp;rft.isbn=978-0-387-87816-4&amp;rft.place=New+York&amp;rft.pub=Springer&amp;rft.series=Springer+Series+in+Operations+Research+and+Financial+Engineering&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook" class="Z3988"><span style="display:none;"> </span></span></li>
</ul>
<h2><span class="mw-headline" id="External_links">External links</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Stochastic_programming&amp;action=edit&amp;section=21" title="Edit section: External links">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul>
<li><a rel="nofollow" class="external text" href="http://stoprog.org">Stochastic Programming Community Home Page</a></li>
</ul>
