<h1 id="firstHeading" class="firstHeading" lang="en"><span dir="auto">Barrier (computer science)</span></h1>
<p>In <a href="/wiki/Parallel_computing" title="Parallel computing">parallel computing</a>, a <b>barrier</b> is a type of <a href="/wiki/Synchronization_(computer_science)" title="Synchronization (computer science)">synchronization</a> method. A barrier for a group of threads or processes in the source code means any thread/process must stop at this point and cannot proceed until all other threads/processes reach this barrier.</p>
<p>Many collective routines and directive-based parallel languages impose implicit barriers. For example, a parallel <i>do</i> loop in <a href="/wiki/Fortran" title="Fortran">Fortran</a> with <a href="/wiki/OpenMP" title="OpenMP">OpenMP</a> will not be allowed to continue on any thread until the last iteration is completed. This is in case the program relies on the result of the loop immediately after its completion. In <a href="/wiki/Message_passing" title="Message passing">message passing</a>, any global communication (such as reduction or scatter) may imply a barrier.</p>
<p></p>
<h2>Contents</h2>
<ul>
<li class="toclevel-1 tocsection-1"><a href="#Dynamic_barriers"><span class="tocnumber">1</span> <span class="toctext">Dynamic barriers</span></a></li>
<li class="toclevel-1 tocsection-2"><a href="#Processor_and_compiler_barriers"><span class="tocnumber">2</span> <span class="toctext">Processor and compiler barriers</span></a></li>
<li class="toclevel-1 tocsection-3"><a href="#See_also"><span class="tocnumber">3</span> <span class="toctext">See also</span></a></li>
<li class="toclevel-1 tocsection-4"><a href="#References"><span class="tocnumber">4</span> <span class="toctext">References</span></a></li>
</ul>
<p></p>
<h2><span class="mw-headline" id="Dynamic_barriers">Dynamic barriers</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Barrier_(computer_science)&amp;action=edit&amp;section=1" title="Edit section: Dynamic barriers">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Classic barrier constructs define the set of participating processes/threads statically. This is usually done either at program startup or when a barrier like the <a href="/wiki/POSIX_Threads" title="POSIX Threads">Pthreads</a> barrier is instantiated. This restricts the possible applications for which barriers can be used.</p>
<p>To support more dynamic programming paradigms like fork/join parallelism, the sets of participants have to be dynamic. Thus, the set of processes/threads participating in a barrier operation needs to be able to change over time. <a href="/wiki/X10_(programming_language)" title="X10 (programming language)">X10</a> introduced the concept of <i>clocks</i> for that purpose, which provide a dynamic barrier semantic. Building on clocks, <i>phasers</i><sup id="cite_ref-phasers_1-0" class="reference"><a href="#cite_note-phasers-1"><span>[</span>1<span>]</span></a></sup> have been proposed to add even more flexibility to barrier synchronization. With phasers it is possible to express data dependencies between the participating processes explicitly to avoid unnecessary over-synchronization.</p>
<h2><span class="mw-headline" id="Processor_and_compiler_barriers">Processor and compiler barriers</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Barrier_(computer_science)&amp;action=edit&amp;section=2" title="Edit section: Processor and compiler barriers">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p><b><a href="/wiki/Memory_barrier" title="Memory barrier">Memory barrier</a></b> is a class of instructions which cause a <a href="/wiki/CPU" title="CPU" class="mw-redirect">processor</a> to enforce an ordering constraint on memory operations issued before and after the barrier instruction.</p>
<p>A <b>barrier</b> can also be a high-level programming language statement which prevents the <a href="/wiki/Compiler" title="Compiler">compiler</a> from reordering other operations over the barrier statement during optimization passes. Such statements can potentially generate processor barrier instructions. Different classes of barrier exist and may apply to a specific set of operations only.</p>
<h2><span class="mw-headline" id="See_also">See also</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Barrier_(computer_science)&amp;action=edit&amp;section=3" title="Edit section: See also">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul>
<li><a href="/wiki/Rendezvous_(Plan_9)" title="Rendezvous (Plan 9)">Rendezvous (Plan 9)</a></li>
</ul>
<h2><span class="mw-headline" id="References">References</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Barrier_(computer_science)&amp;action=edit&amp;section=4" title="Edit section: References">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ol class="references">
<li id="cite_note-phasers-1"><span class="mw-cite-backlink"><b><a href="#cite_ref-phasers_1-0">^</a></b></span> <span class="reference-text"><span class="citation journal">Shirako, J.; Peixotto, D. M.; Sarkar, V.; Scherer, W. N. (2008). "Phasers". "Proceedings of the 22nd annual international conference on Supercomputing - ICS '08". p. 277. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="http://dx.doi.org/10.1145%2F1375527.1375568">10.1145/1375527.1375568</a>. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a> <a href="/wiki/Special:BookSources/9781605581583" title="Special:BookSources/9781605581583">9781605581583</a>.</span><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ABarrier+%28computer+science%29&amp;rft.atitle=Proceedings+of+the+22nd+annual+international+conference+on+Supercomputing++-+ICS+%2708&amp;rft.aufirst=J.&amp;rft.aulast=Shirako&amp;rft.au=Peixotto%2C+D.+M.&amp;rft.au=Sarkar%2C+V.&amp;rft.au=Scherer%2C+W.+N.&amp;rft.au=Shirako%2C+J.&amp;rft.btitle=Phasers&amp;rft.date=2008&amp;rft.genre=bookitem&amp;rft_id=info%3Adoi%2F10.1145%2F1375527.1375568&amp;rft.isbn=9781605581583&amp;rft.pages=277&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook" class="Z3988"><span style="display:none;"> </span></span> <span class="plainlinks noprint" style="font-size:smaller"><a class="external text" href="//en.wikipedia.org/w/index.php?title=Template:Cite_doi/10.1145.2F1375527.1375568&amp;action=edit&amp;editintro=Template:Cite_doi/editintro2">edit</a></span></span></li>
</ol>
<ul>
<li class="nv-view"><a href="/wiki/Template:Parallel_computing" title="Template:Parallel computing"><span title="View this template" style=";;background:none transparent;border:none;;">v</span></a></li>
<li class="nv-talk"><a href="/wiki/Template_talk:Parallel_computing" title="Template talk:Parallel computing"><span title="Discuss this template" style=";;background:none transparent;border:none;;">t</span></a></li>
<li class="nv-edit"><a class="external text" href="//en.wikipedia.org/w/index.php?title=Template:Parallel_computing&amp;action=edit"><span title="Edit this template" style=";;background:none transparent;border:none;;">e</span></a></li>
</ul>
<ul>
<li><a href="/wiki/Cloud_computing" title="Cloud computing">Cloud computing</a></li>
<li><a href="/wiki/High-performance_computing" title="High-performance computing" class="mw-redirect">High-performance computing</a></li>
<li><a href="/wiki/Computer_cluster" title="Computer cluster">Cluster computing</a></li>
<li><a href="/wiki/Distributed_computing" title="Distributed computing">Distributed computing</a></li>
<li><a href="/wiki/Grid_computing" title="Grid computing">Grid computing</a></li>
</ul>
<ul>
<li><a href="/wiki/Bit-level_parallelism" title="Bit-level parallelism">Bit</a></li>
<li><a href="/wiki/Instruction-level_parallelism" title="Instruction-level parallelism">Instruction</a></li>
<li><a href="/wiki/Data_parallelism" title="Data parallelism">Data</a></li>
<li><a href="/wiki/Memory-level_parallelism" title="Memory-level parallelism">Memory</a></li>
<li><a href="/wiki/Task_parallelism" title="Task parallelism">Task</a></li>
</ul>
<ul>
<li><a href="/wiki/Temporal_multithreading" title="Temporal multithreading">Temporal multithreading</a></li>
<li><a href="/wiki/Simultaneous_multithreading" title="Simultaneous multithreading">Simultaneous multithreading</a>
<ul>
<li><a href="/wiki/Hyper-threading" title="Hyper-threading">Hyper-threading</a></li>
</ul>
</li>
</ul>
<ul>
<li><a href="/wiki/Hyper-threading" title="Hyper-threading">Hyper-threading</a></li>
</ul>
<ul>
<li><a href="/wiki/Amdahl%27s_law" title="Amdahl's law">Amdahl's law</a></li>
<li><a href="/wiki/Gustafson%27s_law" title="Gustafson's law">Gustafson's law</a></li>
<li><a href="/wiki/Cost_efficiency" title="Cost efficiency">Cost efficiency</a></li>
<li><a href="/wiki/Karp%E2%80%93Flatt_metric" title="Karp–Flatt metric">Karp–Flatt metric</a></li>
<li><a href="/wiki/Parallel_slowdown" title="Parallel slowdown">slowdown</a></li>
<li><a href="/wiki/Speedup" title="Speedup">speedup</a></li>
</ul>
<ul>
<li><a href="/wiki/Process_(computing)" title="Process (computing)">Process</a></li>
<li><a href="/wiki/Thread_(computing)" title="Thread (computing)">Thread</a></li>
<li><a href="/wiki/Fiber_(computer_science)" title="Fiber (computer science)">Fiber</a></li>
<li><a href="/wiki/Parallel_random-access_machine" title="Parallel random-access machine">PRAM</a></li>
<li><a href="/wiki/Instruction_window" title="Instruction window">Instruction window</a></li>
</ul>
<ul>
<li><a href="/wiki/Multiprocessing" title="Multiprocessing">Multiprocessing</a></li>
<li><a href="/wiki/Memory_coherence" title="Memory coherence">Memory coherency</a></li>
<li><a href="/wiki/Cache_coherence" title="Cache coherence">Cache coherency</a></li>
<li><a href="/wiki/Cache_invalidation" title="Cache invalidation">Cache invalidation</a></li>
<li><strong class="selflink">Barrier</strong></li>
<li><a href="/wiki/Synchronization_(computer_science)" title="Synchronization (computer science)">Synchronization</a></li>
<li><a href="/wiki/Application_checkpointing" title="Application checkpointing">Application checkpointing</a></li>
</ul>
<ul>
<li><a href="/wiki/Parallel_programming_model" title="Parallel programming model">Models</a>
<ul>
<li><a href="/wiki/Implicit_parallelism" title="Implicit parallelism">Implicit parallelism</a></li>
<li><a href="/wiki/Explicit_parallelism" title="Explicit parallelism">Explicit parallelism</a></li>
<li><a href="/wiki/Concurrency_(computer_science)" title="Concurrency (computer science)">Concurrency</a></li>
</ul>
</li>
<li><a href="/wiki/Flynn%27s_taxonomy" title="Flynn's taxonomy">Flynn's taxonomy</a>
<ul>
<li><a href="/wiki/SISD" title="SISD">SISD</a></li>
<li><a href="/wiki/SIMD" title="SIMD">SIMD</a></li>
<li><a href="/wiki/MISD" title="MISD">MISD</a></li>
<li><a href="/wiki/MIMD" title="MIMD">MIMD</a>
<ul>
<li><a href="/wiki/SPMD" title="SPMD">SPMD</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="/wiki/Thread_(computing)" title="Thread (computing)">Thread</a></li>
<li><a href="/wiki/Non-blocking_algorithm" title="Non-blocking algorithm">Non-blocking algorithm</a></li>
</ul>
<ul>
<li><a href="/wiki/Implicit_parallelism" title="Implicit parallelism">Implicit parallelism</a></li>
<li><a href="/wiki/Explicit_parallelism" title="Explicit parallelism">Explicit parallelism</a></li>
<li><a href="/wiki/Concurrency_(computer_science)" title="Concurrency (computer science)">Concurrency</a></li>
</ul>
<ul>
<li><a href="/wiki/SISD" title="SISD">SISD</a></li>
<li><a href="/wiki/SIMD" title="SIMD">SIMD</a></li>
<li><a href="/wiki/MISD" title="MISD">MISD</a></li>
<li><a href="/wiki/MIMD" title="MIMD">MIMD</a>
<ul>
<li><a href="/wiki/SPMD" title="SPMD">SPMD</a></li>
</ul>
</li>
</ul>
<ul>
<li><a href="/wiki/SPMD" title="SPMD">SPMD</a></li>
</ul>
<ul>
<li><a href="/wiki/Multiprocessor" title="Multiprocessor" class="mw-redirect">Multiprocessor</a>
<ul>
<li><a href="/wiki/Symmetric_multiprocessing" title="Symmetric multiprocessing">Symmetric</a></li>
<li><a href="/wiki/Asymmetric_multiprocessing" title="Asymmetric multiprocessing">Asymmetric</a></li>
</ul>
</li>
<li><a href="/wiki/Semiconductor_memory" title="Semiconductor memory">Memory</a>
<ul>
<li><a href="/wiki/Non-uniform_memory_access" title="Non-uniform memory access">NUMA</a></li>
<li><a href="/wiki/Cache-only_memory_architecture" title="Cache-only memory architecture">COMA</a></li>
<li><a href="/wiki/Distributed_memory" title="Distributed memory">distributed</a></li>
<li><a href="/wiki/Shared_memory" title="Shared memory">shared</a></li>
<li><a href="/wiki/Distributed_shared_memory" title="Distributed shared memory">distributed shared</a></li>
</ul>
</li>
<li><a href="/wiki/Massively_parallel_(computing)" title="Massively parallel (computing)">MPP</a></li>
<li><a href="/wiki/Superscalar" title="Superscalar">Superscalar</a></li>
<li><a href="/wiki/Vector_processor" title="Vector processor">Vector processor</a></li>
<li><a href="/wiki/Supercomputer" title="Supercomputer">Supercomputer</a></li>
<li><a href="/wiki/Beowulf_cluster" title="Beowulf cluster">Beowulf cluster</a></li>
</ul>
<ul>
<li><a href="/wiki/Symmetric_multiprocessing" title="Symmetric multiprocessing">Symmetric</a></li>
<li><a href="/wiki/Asymmetric_multiprocessing" title="Asymmetric multiprocessing">Asymmetric</a></li>
</ul>
<ul>
<li><a href="/wiki/Non-uniform_memory_access" title="Non-uniform memory access">NUMA</a></li>
<li><a href="/wiki/Cache-only_memory_architecture" title="Cache-only memory architecture">COMA</a></li>
<li><a href="/wiki/Distributed_memory" title="Distributed memory">distributed</a></li>
<li><a href="/wiki/Shared_memory" title="Shared memory">shared</a></li>
<li><a href="/wiki/Distributed_shared_memory" title="Distributed shared memory">distributed shared</a></li>
</ul>
<ul>
<li><a href="/wiki/Ateji_PX" title="Ateji PX">Ateji PX</a></li>
<li><a href="/wiki/POSIX_Threads" title="POSIX Threads">POSIX Threads</a></li>
<li><a href="/wiki/OpenMP" title="OpenMP">OpenMP</a></li>
<li><a href="/wiki/OpenHMPP" title="OpenHMPP">OpenHMPP</a></li>
<li><a href="/wiki/OpenACC" title="OpenACC">OpenACC</a></li>
<li><a href="/wiki/Parallel_Virtual_Machine" title="Parallel Virtual Machine">PVM</a></li>
<li><a href="/wiki/Message_Passing_Interface" title="Message Passing Interface">MPI</a></li>
<li><a href="/wiki/Unified_Parallel_C" title="Unified Parallel C">UPC</a></li>
<li><a href="/wiki/Threading_Building_Blocks" title="Threading Building Blocks">TBB</a></li>
<li><a href="/wiki/Boost_(C%2B%2B_libraries)#Multithreading_.E2.80.93_Boost.Thread" title="Boost (C++ libraries)">Boost.Thread</a></li>
<li><a href="/wiki/Global_Arrays" title="Global Arrays">Global Arrays</a></li>
<li><a href="/wiki/Charm%2B%2B" title="Charm++">Charm++</a></li>
<li><a href="/wiki/Cilk" title="Cilk">Cilk</a>/<a href="/wiki/Cilk_Plus" title="Cilk Plus">Cilk Plus</a></li>
<li><a href="/wiki/Coarray_Fortran" title="Coarray Fortran">Coarray Fortran</a></li>
<li><a href="/wiki/OpenCL" title="OpenCL">OpenCL</a></li>
<li><a href="/wiki/CUDA" title="CUDA">CUDA</a></li>
<li><a href="/wiki/Dryad_(programming)" title="Dryad (programming)">Dryad</a></li>
<li><a href="/wiki/C%2B%2B_AMP" title="C++ AMP">C++ AMP</a></li>
<li><a href="/wiki/Parallel_LINQ" title="Parallel LINQ" class="mw-redirect">PLINQ</a></li>
<li><a href="/wiki/Parallel_Extensions#Task_Parallel_Library" title="Parallel Extensions">TPL</a></li>
</ul>
<ul>
<li><a href="/wiki/Embarrassingly_parallel" title="Embarrassingly parallel">Embarrassingly parallel</a></li>
<li><a href="/wiki/Software_lockout" title="Software lockout">Software lockout</a></li>
<li><a href="/wiki/Scalability" title="Scalability">Scalability</a></li>
<li><a href="/wiki/Race_condition#Computing" title="Race condition">Race condition</a></li>
<li><a href="/wiki/Deadlock" title="Deadlock">Deadlock</a></li>
<li><a href="/wiki/Deadlock#Livelock" title="Deadlock">Livelock</a></li>
<li><a href="/wiki/Resource_starvation" title="Resource starvation">Starvation</a></li>
<li><a href="/wiki/Deterministic_algorithm" title="Deterministic algorithm">Deterministic algorithm</a></li>
<li><a href="/wiki/Parallel_slowdown" title="Parallel slowdown">Parallel slowdown</a></li>
</ul>
<ul>
<li><img alt="Category" src="//upload.wikimedia.org/wikipedia/en/thumb/4/48/Folder_Hexagonal_Icon.svg/16px-Folder_Hexagonal_Icon.svg.png" width="16" height="14" srcset="//upload.wikimedia.org/wikipedia/en/thumb/4/48/Folder_Hexagonal_Icon.svg/24px-Folder_Hexagonal_Icon.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/4/48/Folder_Hexagonal_Icon.svg/32px-Folder_Hexagonal_Icon.svg.png 2x" data-file-width="36" data-file-height="31"> <a href="/wiki/Category:Parallel_computing" title="Category:Parallel computing">Category: parallel computing</a></li>
<li><img alt="" src="//upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/12px-Commons-logo.svg.png" width="12" height="16" srcset="//upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/18px-Commons-logo.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/24px-Commons-logo.svg.png 2x" data-file-width="1024" data-file-height="1376"> Media related to <a href="//commons.wikimedia.org/wiki/Category:parallel_computing" class="extiw" title="commons:Category:parallel computing">parallel computing</a> at Wikimedia Commons</li>
</ul>
<ul>
<li class="nv-view"><a href="/wiki/Template:Comp-sci-stub" title="Template:Comp-sci-stub"><span title="View this template" style="">v</span></a></li>
<li class="nv-talk"><a href="/wiki/Template_talk:Comp-sci-stub" title="Template talk:Comp-sci-stub"><span title="Discuss this template" style="">t</span></a></li>
<li class="nv-edit"><a class="external text" href="//en.wikipedia.org/w/index.php?title=Template:Comp-sci-stub&amp;action=edit"><span title="Edit this template" style="">e</span></a></li>
</ul>
