<h1 id="firstHeading" class="firstHeading" lang="en"><span dir="auto">Synchronization (computer science)</span></h1>
<p>In <a href="/wiki/Computer_science" title="Computer science">computer science</a>, <b>synchronization</b> refers to one of two distinct but related concepts: synchronization of <a href="/wiki/Process_(computer_science)" title="Process (computer science)" class="mw-redirect">processes</a>, and synchronization of data. <b>Process synchronization</b> refers to the idea that multiple processes are to join up or handshake at a certain point, in order to reach an agreement or commit to a certain sequence of action. <b>Data synchronization</b> refers to the idea of keeping multiple copies of a <a href="/wiki/Dataset" title="Dataset" class="mw-redirect">dataset</a> in coherence with one another, or to maintain <a href="/wiki/Data_integrity" title="Data integrity">data integrity</a>. Process synchronization primitives are commonly used to implement data synchronization.</p>
<p></p>
<h2>Contents</h2>
<ul>
<li class="toclevel-1 tocsection-1"><a href="#Thread_or_process_synchronization"><span class="tocnumber">1</span> <span class="toctext">Thread or process synchronization</span></a>
<ul>
<li class="toclevel-2 tocsection-2"><a href="#See"><span class="tocnumber">1.1</span> <span class="toctext">See</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-3"><a href="#Data_synchronization"><span class="tocnumber">2</span> <span class="toctext">Data synchronization</span></a></li>
<li class="toclevel-1 tocsection-4"><a href="#Mathematical_foundations"><span class="tocnumber">3</span> <span class="toctext">Mathematical foundations</span></a></li>
<li class="toclevel-1 tocsection-5"><a href="#See_also"><span class="tocnumber">4</span> <span class="toctext">See also</span></a></li>
<li class="toclevel-1 tocsection-6"><a href="#References"><span class="tocnumber">5</span> <span class="toctext">References</span></a></li>
<li class="toclevel-1 tocsection-7"><a href="#External_links"><span class="tocnumber">6</span> <span class="toctext">External links</span></a></li>
</ul>
<ul>
<li class="toclevel-2 tocsection-2"><a href="#See"><span class="tocnumber">1.1</span> <span class="toctext">See</span></a></li>
</ul>
<p></p>
<h2><span class="mw-headline" id="Thread_or_process_synchronization">Thread or process synchronization</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Synchronization_(computer_science)&amp;action=edit&amp;section=1" title="Edit section: Thread or process synchronization">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Thread synchronization or serialization, strictly defined, is the application of particular mechanisms to ensure that two concurrently-executing <a href="/wiki/Thread_(computer_science)" title="Thread (computer science)" class="mw-redirect">threads</a> or <a href="/wiki/Process_(computer_science)" title="Process (computer science)" class="mw-redirect">processes</a> do not execute specific portions of a program at the same time, referred to as <a href="/wiki/Mutual_exclusion" title="Mutual exclusion">mutual exclusion</a>. If one thread has begun to execute a serialized portion of the program called a <a href="/wiki/Critical_section" title="Critical section">critical section</a>, any other thread trying to execute this portion must wait until the first thread finishes. If such synchronization measures are not taken, it can result in a <a href="/wiki/Race_condition#Software" title="Race condition">race condition</a> where variable values are unpredictable and depend on the timings of the thread or process <a href="/wiki/Context_switch" title="Context switch">context switch</a>.</p>
<p>In addition to providing mutual exclusion, synchronization must also guard against the following:</p>
<ul>
<li><a href="/wiki/Deadlock" title="Deadlock">Deadlock</a> : This happens when two or more processes or threads are waiting for a lock to enter a critical section, which the other process is holding. This results in them indefinitely stalling and them making no further progress.</li>
<li><a href="/wiki/Resource_starvation" title="Resource starvation">Starvation</a>: In some instances, a process or thread could have unbounded waiting time to acquire a lock and never make any progress.</li>
<li><a href="/wiki/Priority_inversion" title="Priority inversion">Priority inversion</a>: In systems that have priorities for processes and threads, a medium priority task can pre-empt a higher priority task when using synchronization thereby violating the system rules. This is especially severe in real time systems which can cause missed deadlines.</li>
</ul>
<p>Synchronization is used to control access to state both in small-scale multiprocessing systems -- in multithreaded environments and multiprocessor computers -- and in distributed computers consisting of thousands of units -- in banking and database systems, in web servers, and so on.</p>
<h3><span class="mw-headline" id="See">See</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Synchronization_(computer_science)&amp;action=edit&amp;section=2" title="Edit section: See">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<ul>
<li><a href="/wiki/Lock_(computer_science)" title="Lock (computer science)">Lock (computer science)</a> and <a href="/wiki/Mutex" title="Mutex" class="mw-redirect">mutex</a></li>
<li><a href="/wiki/Monitor_(synchronization)" title="Monitor (synchronization)">Monitor (synchronization)</a>
<ul>
<li><a href="/wiki/Monitor_(synchronization)#Synchronization_primitives" title="Monitor (synchronization)">Synchronization primitives</a></li>
</ul>
</li>
<li><a href="/wiki/Semaphore_(programming)" title="Semaphore (programming)">Semaphore (programming)</a></li>
<li><a href="/wiki/Test-and-set" title="Test-and-set">Test-and-set</a></li>
<li><a href="/wiki/SCOOP_(software)" title="SCOOP (software)">Simple Concurrent Object-Oriented Programming (SCOOP)</a></li>
</ul>
<ul>
<li><a href="/wiki/Monitor_(synchronization)#Synchronization_primitives" title="Monitor (synchronization)">Synchronization primitives</a></li>
</ul>
<h2><span class="mw-headline" id="Data_synchronization">Data synchronization</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Synchronization_(computer_science)&amp;action=edit&amp;section=3" title="Edit section: Data synchronization">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>A distinctly different (but related) concept is that of <b>data synchronization</b>. This refers to the need to keep multiple copies of a set of data coherent with one another.</p>
<p>Examples include:</p>
<ul>
<li><a href="/wiki/File_synchronization" title="File synchronization">File synchronization</a>, such as syncing a hand-held MP3 player to a desktop computer.</li>
<li><a href="/wiki/Cluster_file_system" title="Cluster file system" class="mw-redirect">Cluster file systems</a>, which are <a href="/wiki/File_system" title="File system">file systems</a> that maintain data or indexes in a coherent fashion across a whole <a href="/wiki/Computing_cluster" title="Computing cluster" class="mw-redirect">computing cluster</a>.</li>
<li><a href="/wiki/Cache_coherency" title="Cache coherency" class="mw-redirect">Cache coherency</a>, maintaining multiple copies of data in sync across multiple <a href="/wiki/Cache_(computing)" title="Cache (computing)">caches</a>.</li>
<li><a href="/wiki/RAID" title="RAID">RAID</a>, where data is written in a redundant fashion across multiple disks, so that the loss of any one disk does not lead to a loss of data.</li>
<li><a href="/wiki/Database_replication" title="Database replication" class="mw-redirect">Database replication</a>, where copies of data on a <a href="/wiki/Database" title="Database">database</a> are kept in sync, despite possible large geographical separation.</li>
<li><a href="/wiki/Journaling_file_system" title="Journaling file system">Journaling</a>, a technique used by many modern file systems to make sure that file metadata are updated on a disk in a coherent, consistent manner.</li>
</ul>
<h2><span class="mw-headline" id="Mathematical_foundations">Mathematical foundations</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Synchronization_(computer_science)&amp;action=edit&amp;section=4" title="Edit section: Mathematical foundations">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Synchronization was originally a process based concept whereby a lock could be obtained on an object. Its primary usage was in databases. There are two types of (file) lock; read-only and read-write. Read-only locks may be obtained by many processes or threads. Read-write locks are exclusive, as they may only be used by a single process/thread at a time.<br>
Although locks were derived for file databases, data is also shared in memory between processes and threads. Sometimes more than one object (or file) is locked at a time. If they are not locked simultaneously they can overlap, causing a deadlock exception.<br>
<a href="/wiki/Java_(programming_language)" title="Java (programming language)">Java</a> and <a href="/wiki/Ada_(programming_language)" title="Ada (programming language)">Ada</a> only have exclusive locks because they are thread based and rely on the compare-and-swap processor instruction (see <a href="/wiki/Mutex" title="Mutex" class="mw-redirect">mutex</a>).<br>
An abstract mathematical foundation for synchronization primitives is given by the <a href="/wiki/History_monoid" title="History monoid">history monoid</a>. There are also many higher-level theoretical devices, such as <a href="/wiki/Process_calculi" title="Process calculi" class="mw-redirect">process calculi</a> and <a href="/wiki/Petri_net" title="Petri net">Petri nets</a>, which can be built on top of the history monoid.</p>
<h2><span class="mw-headline" id="See_also">See also</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Synchronization_(computer_science)&amp;action=edit&amp;section=5" title="Edit section: See also">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul>
<li><a href="/wiki/Futures_and_promises" title="Futures and promises">Futures and promises</a>, synchronization mechanisms in pure functional paradigms.</li>
</ul>
<h2><span class="mw-headline" id="References">References</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Synchronization_(computer_science)&amp;action=edit&amp;section=6" title="Edit section: References">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<h2><span class="mw-headline" id="External_links">External links</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Synchronization_(computer_science)&amp;action=edit&amp;section=7" title="Edit section: External links">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul>
<li><a rel="nofollow" class="external text" href="http://web.archive.org/web/20090209170415/http://ibm.com/developerworks/linux/library/l-linux-synchronization.html">Anatomy of Linux synchronization methods</a> at IBM developerWorks</li>
<li><a rel="nofollow" class="external text" href="http://greenteapress.com/semaphores/"><i>The Little Book of Semaphores</i></a>, by Allen B. Downey</li>
</ul>
<ul>
<li class="nv-view"><a href="/wiki/Template:Parallel_computing" title="Template:Parallel computing"><span title="View this template" style=";;background:none transparent;border:none;;">v</span></a></li>
<li class="nv-talk"><a href="/wiki/Template_talk:Parallel_computing" title="Template talk:Parallel computing"><span title="Discuss this template" style=";;background:none transparent;border:none;;">t</span></a></li>
<li class="nv-edit"><a class="external text" href="//en.wikipedia.org/w/index.php?title=Template:Parallel_computing&amp;action=edit"><span title="Edit this template" style=";;background:none transparent;border:none;;">e</span></a></li>
</ul>
<ul>
<li><a href="/wiki/Cloud_computing" title="Cloud computing">Cloud computing</a></li>
<li><a href="/wiki/High-performance_computing" title="High-performance computing" class="mw-redirect">High-performance computing</a></li>
<li><a href="/wiki/Computer_cluster" title="Computer cluster">Cluster computing</a></li>
<li><a href="/wiki/Distributed_computing" title="Distributed computing">Distributed computing</a></li>
<li><a href="/wiki/Grid_computing" title="Grid computing">Grid computing</a></li>
</ul>
<ul>
<li><a href="/wiki/Bit-level_parallelism" title="Bit-level parallelism">Bit</a></li>
<li><a href="/wiki/Instruction-level_parallelism" title="Instruction-level parallelism">Instruction</a></li>
<li><a href="/wiki/Data_parallelism" title="Data parallelism">Data</a></li>
<li><a href="/wiki/Memory-level_parallelism" title="Memory-level parallelism">Memory</a></li>
<li><a href="/wiki/Task_parallelism" title="Task parallelism">Task</a></li>
</ul>
<ul>
<li><a href="/wiki/Temporal_multithreading" title="Temporal multithreading">Temporal multithreading</a></li>
<li><a href="/wiki/Simultaneous_multithreading" title="Simultaneous multithreading">Simultaneous multithreading</a>
<ul>
<li><a href="/wiki/Hyper-threading" title="Hyper-threading">Hyper-threading</a></li>
</ul>
</li>
</ul>
<ul>
<li><a href="/wiki/Hyper-threading" title="Hyper-threading">Hyper-threading</a></li>
</ul>
<ul>
<li><a href="/wiki/Amdahl%27s_law" title="Amdahl's law">Amdahl's law</a></li>
<li><a href="/wiki/Gustafson%27s_law" title="Gustafson's law">Gustafson's law</a></li>
<li><a href="/wiki/Cost_efficiency" title="Cost efficiency">Cost efficiency</a></li>
<li><a href="/wiki/Karp%E2%80%93Flatt_metric" title="Karp–Flatt metric">Karp–Flatt metric</a></li>
<li><a href="/wiki/Parallel_slowdown" title="Parallel slowdown">slowdown</a></li>
<li><a href="/wiki/Speedup" title="Speedup">speedup</a></li>
</ul>
<ul>
<li><a href="/wiki/Process_(computing)" title="Process (computing)">Process</a></li>
<li><a href="/wiki/Thread_(computing)" title="Thread (computing)">Thread</a></li>
<li><a href="/wiki/Fiber_(computer_science)" title="Fiber (computer science)">Fiber</a></li>
<li><a href="/wiki/Parallel_random-access_machine" title="Parallel random-access machine">PRAM</a></li>
<li><a href="/wiki/Instruction_window" title="Instruction window">Instruction window</a></li>
</ul>
<ul>
<li><a href="/wiki/Multiprocessing" title="Multiprocessing">Multiprocessing</a></li>
<li><a href="/wiki/Memory_coherence" title="Memory coherence">Memory coherency</a></li>
<li><a href="/wiki/Cache_coherence" title="Cache coherence">Cache coherency</a></li>
<li><a href="/wiki/Cache_invalidation" title="Cache invalidation">Cache invalidation</a></li>
<li><a href="/wiki/Barrier_(computer_science)" title="Barrier (computer science)">Barrier</a></li>
<li><strong class="selflink">Synchronization</strong></li>
<li><a href="/wiki/Application_checkpointing" title="Application checkpointing">Application checkpointing</a></li>
</ul>
<ul>
<li><a href="/wiki/Parallel_programming_model" title="Parallel programming model">Models</a>
<ul>
<li><a href="/wiki/Implicit_parallelism" title="Implicit parallelism">Implicit parallelism</a></li>
<li><a href="/wiki/Explicit_parallelism" title="Explicit parallelism">Explicit parallelism</a></li>
<li><a href="/wiki/Concurrency_(computer_science)" title="Concurrency (computer science)">Concurrency</a></li>
</ul>
</li>
<li><a href="/wiki/Flynn%27s_taxonomy" title="Flynn's taxonomy">Flynn's taxonomy</a>
<ul>
<li><a href="/wiki/SISD" title="SISD">SISD</a></li>
<li><a href="/wiki/SIMD" title="SIMD">SIMD</a></li>
<li><a href="/wiki/MISD" title="MISD">MISD</a></li>
<li><a href="/wiki/MIMD" title="MIMD">MIMD</a>
<ul>
<li><a href="/wiki/SPMD" title="SPMD">SPMD</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="/wiki/Thread_(computing)" title="Thread (computing)">Thread</a></li>
<li><a href="/wiki/Non-blocking_algorithm" title="Non-blocking algorithm">Non-blocking algorithm</a></li>
</ul>
<ul>
<li><a href="/wiki/Implicit_parallelism" title="Implicit parallelism">Implicit parallelism</a></li>
<li><a href="/wiki/Explicit_parallelism" title="Explicit parallelism">Explicit parallelism</a></li>
<li><a href="/wiki/Concurrency_(computer_science)" title="Concurrency (computer science)">Concurrency</a></li>
</ul>
<ul>
<li><a href="/wiki/SISD" title="SISD">SISD</a></li>
<li><a href="/wiki/SIMD" title="SIMD">SIMD</a></li>
<li><a href="/wiki/MISD" title="MISD">MISD</a></li>
<li><a href="/wiki/MIMD" title="MIMD">MIMD</a>
<ul>
<li><a href="/wiki/SPMD" title="SPMD">SPMD</a></li>
</ul>
</li>
</ul>
<ul>
<li><a href="/wiki/SPMD" title="SPMD">SPMD</a></li>
</ul>
<ul>
<li><a href="/wiki/Multiprocessor" title="Multiprocessor" class="mw-redirect">Multiprocessor</a>
<ul>
<li><a href="/wiki/Symmetric_multiprocessing" title="Symmetric multiprocessing">Symmetric</a></li>
<li><a href="/wiki/Asymmetric_multiprocessing" title="Asymmetric multiprocessing">Asymmetric</a></li>
</ul>
</li>
<li><a href="/wiki/Semiconductor_memory" title="Semiconductor memory">Memory</a>
<ul>
<li><a href="/wiki/Non-uniform_memory_access" title="Non-uniform memory access">NUMA</a></li>
<li><a href="/wiki/Cache-only_memory_architecture" title="Cache-only memory architecture">COMA</a></li>
<li><a href="/wiki/Distributed_memory" title="Distributed memory">distributed</a></li>
<li><a href="/wiki/Shared_memory" title="Shared memory">shared</a></li>
<li><a href="/wiki/Distributed_shared_memory" title="Distributed shared memory">distributed shared</a></li>
</ul>
</li>
<li><a href="/wiki/Massively_parallel_(computing)" title="Massively parallel (computing)">MPP</a></li>
<li><a href="/wiki/Superscalar" title="Superscalar">Superscalar</a></li>
<li><a href="/wiki/Vector_processor" title="Vector processor">Vector processor</a></li>
<li><a href="/wiki/Supercomputer" title="Supercomputer">Supercomputer</a></li>
<li><a href="/wiki/Beowulf_cluster" title="Beowulf cluster">Beowulf cluster</a></li>
</ul>
<ul>
<li><a href="/wiki/Symmetric_multiprocessing" title="Symmetric multiprocessing">Symmetric</a></li>
<li><a href="/wiki/Asymmetric_multiprocessing" title="Asymmetric multiprocessing">Asymmetric</a></li>
</ul>
<ul>
<li><a href="/wiki/Non-uniform_memory_access" title="Non-uniform memory access">NUMA</a></li>
<li><a href="/wiki/Cache-only_memory_architecture" title="Cache-only memory architecture">COMA</a></li>
<li><a href="/wiki/Distributed_memory" title="Distributed memory">distributed</a></li>
<li><a href="/wiki/Shared_memory" title="Shared memory">shared</a></li>
<li><a href="/wiki/Distributed_shared_memory" title="Distributed shared memory">distributed shared</a></li>
</ul>
<ul>
<li><a href="/wiki/Ateji_PX" title="Ateji PX">Ateji PX</a></li>
<li><a href="/wiki/POSIX_Threads" title="POSIX Threads">POSIX Threads</a></li>
<li><a href="/wiki/OpenMP" title="OpenMP">OpenMP</a></li>
<li><a href="/wiki/OpenHMPP" title="OpenHMPP">OpenHMPP</a></li>
<li><a href="/wiki/OpenACC" title="OpenACC">OpenACC</a></li>
<li><a href="/wiki/Parallel_Virtual_Machine" title="Parallel Virtual Machine">PVM</a></li>
<li><a href="/wiki/Message_Passing_Interface" title="Message Passing Interface">MPI</a></li>
<li><a href="/wiki/Unified_Parallel_C" title="Unified Parallel C">UPC</a></li>
<li><a href="/wiki/Threading_Building_Blocks" title="Threading Building Blocks">TBB</a></li>
<li><a href="/wiki/Boost_(C%2B%2B_libraries)#Multithreading_.E2.80.93_Boost.Thread" title="Boost (C++ libraries)">Boost.Thread</a></li>
<li><a href="/wiki/Global_Arrays" title="Global Arrays">Global Arrays</a></li>
<li><a href="/wiki/Charm%2B%2B" title="Charm++">Charm++</a></li>
<li><a href="/wiki/Cilk" title="Cilk">Cilk</a>/<a href="/wiki/Cilk_Plus" title="Cilk Plus">Cilk Plus</a></li>
<li><a href="/wiki/Coarray_Fortran" title="Coarray Fortran">Coarray Fortran</a></li>
<li><a href="/wiki/OpenCL" title="OpenCL">OpenCL</a></li>
<li><a href="/wiki/CUDA" title="CUDA">CUDA</a></li>
<li><a href="/wiki/Dryad_(programming)" title="Dryad (programming)">Dryad</a></li>
<li><a href="/wiki/C%2B%2B_AMP" title="C++ AMP">C++ AMP</a></li>
<li><a href="/wiki/Parallel_LINQ" title="Parallel LINQ" class="mw-redirect">PLINQ</a></li>
<li><a href="/wiki/Parallel_Extensions#Task_Parallel_Library" title="Parallel Extensions">TPL</a></li>
</ul>
<ul>
<li><a href="/wiki/Embarrassingly_parallel" title="Embarrassingly parallel">Embarrassingly parallel</a></li>
<li><a href="/wiki/Software_lockout" title="Software lockout">Software lockout</a></li>
<li><a href="/wiki/Scalability" title="Scalability">Scalability</a></li>
<li><a href="/wiki/Race_condition#Computing" title="Race condition">Race condition</a></li>
<li><a href="/wiki/Deadlock" title="Deadlock">Deadlock</a></li>
<li><a href="/wiki/Deadlock#Livelock" title="Deadlock">Livelock</a></li>
<li><a href="/wiki/Resource_starvation" title="Resource starvation">Starvation</a></li>
<li><a href="/wiki/Deterministic_algorithm" title="Deterministic algorithm">Deterministic algorithm</a></li>
<li><a href="/wiki/Parallel_slowdown" title="Parallel slowdown">Parallel slowdown</a></li>
</ul>
<ul>
<li><img alt="Category" src="//upload.wikimedia.org/wikipedia/en/thumb/4/48/Folder_Hexagonal_Icon.svg/16px-Folder_Hexagonal_Icon.svg.png" width="16" height="14" srcset="//upload.wikimedia.org/wikipedia/en/thumb/4/48/Folder_Hexagonal_Icon.svg/24px-Folder_Hexagonal_Icon.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/4/48/Folder_Hexagonal_Icon.svg/32px-Folder_Hexagonal_Icon.svg.png 2x" data-file-width="36" data-file-height="31"> <a href="/wiki/Category:Parallel_computing" title="Category:Parallel computing">Category: parallel computing</a></li>
<li><img alt="" src="//upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/12px-Commons-logo.svg.png" width="12" height="16" srcset="//upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/18px-Commons-logo.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/24px-Commons-logo.svg.png 2x" data-file-width="1024" data-file-height="1376"> Media related to <a href="//commons.wikimedia.org/wiki/Category:parallel_computing" class="extiw" title="commons:Category:parallel computing">parallel computing</a> at Wikimedia Commons</li>
</ul>
