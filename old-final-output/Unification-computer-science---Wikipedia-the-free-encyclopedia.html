<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Unification-computer-science---Wikipedia-the-free-encyclopedia.html</title></head>
<body>
<h1>Unification (computer science)</h1>
<p><b>Unification</b>, in computer science and logic, is an algorithmic process of solving equations between symbolic expressions.</p>
<p>Depending on which expressions (also called <i>terms</i>) are allowed to occur in an equation set (also called <b>unification problem</b>), and which expressions are considered equal, several <b>frameworks</b> of unification are distinguished. If <i>higher-order variables</i>, that is, variables representing functions, are allowed in an expression, the process is called <b>higher-order unification</b>, otherwise <b>first-order unification</b>. If a solution is required to make both sides of each equation literally equal, the process is called <b>syntactical unification</b>, otherwise <b>semantical</b>, or <b>equational unification</b>, or <b>E-unification</b>, or <b>unification modulo theory</b>.</p>
<p>A <b>solution</b> of a unification problem is denoted as a substitution, that is, a mapping assigning a symbolic value to each variable of the problem's expressions. A unification <b>algorithm</b> should compute for a given problem a <b>complete</b>, and <b>minimal</b> substitution set, that is, a set covering all its solutions, and containing no redundant members. Depending on the framework, a complete and minimal substitution set may have at most one, at most finitely many, or possibly infinitely many members, or may not exist at all. In some frameworks it is generally impossible to decide whether any solution exists. For first-order syntactical unification, Martelli and Montanari gave an algorithm that reports unsolvability or computes a complete and minimal singleton substitution set containing the so-called <b>most general unifier</b>.</p>
<p>For example, using <i>x</i>,<i>y</i>,<i>z</i> as variables, the singleton equation set { <i>cons</i>(<i>x</i>,<i>cons</i>(<i>x</i>,<i>nil</i>)) = <i>cons</i>(2,<i>y</i>) } is a syntactic first-order unification problem that has the substitution { <i>x</i> ↦ 2, <i>y</i> ↦ <i>cons</i>(2,<i>nil</i>) } as its only solution. The syntactic first-order unification problem { <i>y</i> = <i>cons</i>(2,<i>y</i>) } has no solution over the set of finite terms; however, it has the single solution { <i>y</i> ↦ <i>cons</i>(2,<i>cons</i>(2,<i>cons</i>(2,...))) } over the set of infinite trees. The semantic first-order unification problem { <i>a</i>⋅<i>x</i> = <i>x</i>⋅<i>a</i> } has each substitution of the form { <i>x</i> ↦ <i>a</i>⋅...⋅<i>a</i> } as a solution in a semigroup, i.e. if (⋅) is considered associative; the same problem, viewed in an abelian group, where (⋅) is considered also commutative, has any substitution at all as a solution. The singleton set { <i>a</i> = <i>y</i>(<i>x</i>) } is a syntactic second-order unification problem, since <i>y</i> is a function variable. One solution is { <i>x</i> ↦ <i>a</i>, <i>y</i> ↦ (identity function) }; another one is { <i>y</i> ↦ (constant function mapping each value to <i>a</i>) }, for arbitrary <i>x</i>.</p>
<p>The first formal investigation of unification can be attributed to John Alan Robinson, who used first-order syntactical unification as a basic building block of his resolution procedure for first-order logic, a great step forward in automated reasoning technology, as it eliminated one source of combinatorial explosion: searching for instantiation of terms. Today, automated reasoning is still the main application area of unification. Syntactical first-order unification is used in logic programming and programming language type system implementation, especially in Hindley–Milner based type inference algorithms. Semantic unification is used in SMT solvers and term rewriting algorithms. Higher-order unification is used in proof assistants, for example Isabelle and Twelf, and restricted forms of higher-order unification (<b>higher-order pattern unification</b>) are used in some programming language implementations, such as lambdaProlog, as higher-order patterns are expressive, yet their associated unification procedure retains theoretical properties closer to first-order unification.</p>
<p></p>
<h2>Contents</h2>
<ul>
<li>1 Common formal definitions
<ul>
<li>1.1 Prerequisites</li>
<li>1.2 First-order term</li>
<li>1.3 Higher-order term</li>
<li>1.4 Substitution</li>
<li>1.5 Generalization, specialization</li>
<li>1.6 Unification problem, solution set</li>
</ul>
</li>
<li>2 Syntactic unification of first-order terms
<ul>
<li>2.1 A unification algorithm
<ul>
<li>2.1.1 Occurs check</li>
<li>2.1.2 Proof of termination</li>
</ul>
</li>
<li>2.2 Examples of syntactic unification of first-order terms</li>
<li>2.3 Application: Unification in logic programming</li>
<li>2.4 Application: Type inference</li>
</ul>
</li>
<li>3 Order-sorted unification</li>
<li>4 Unification of infinite terms</li>
<li>5 E-unification
<ul>
<li>5.1 Particular background knowledge sets E</li>
<li>5.2 One-sided paramodulation</li>
<li>5.3 Narrowing</li>
</ul>
</li>
<li>6 Higher-order unification</li>
<li>7 See also</li>
<li>8 Notes</li>
<li>9 References</li>
</ul>
<ul>
<li>1.1 Prerequisites</li>
<li>1.2 First-order term</li>
<li>1.3 Higher-order term</li>
<li>1.4 Substitution</li>
<li>1.5 Generalization, specialization</li>
<li>1.6 Unification problem, solution set</li>
</ul>
<ul>
<li>2.1 A unification algorithm
<ul>
<li>2.1.1 Occurs check</li>
<li>2.1.2 Proof of termination</li>
</ul>
</li>
<li>2.2 Examples of syntactic unification of first-order terms</li>
<li>2.3 Application: Unification in logic programming</li>
<li>2.4 Application: Type inference</li>
</ul>
<ul>
<li>2.1.1 Occurs check</li>
<li>2.1.2 Proof of termination</li>
</ul>
<ul>
<li>5.1 Particular background knowledge sets E</li>
<li>5.2 One-sided paramodulation</li>
<li>5.3 Narrowing</li>
</ul>
<p></p>
<h2>Common formal definitions</h2>
<h3>Prerequisites</h3>
<p>Formally, a unification approach presupposes</p>
<ul>
<li>An infinite set <i>V</i> of <b>variables</b>. For higher-order unification, it is convenient to choose <i>V</i> disjoint from the set of lambda-term bound variables.</li>
<li>A set <i>T</i> of <b>terms</b> such that <i>V</i> ⊆ <i>T</i>. For first-order unification and higher-order unification, <i>T</i> is usually the set of first-order terms (terms built from variable and function symbols) and lambda terms (terms containing some higher-order variables), respectively.</li>
<li>A mapping <i>vars</i>: <i>T</i> → ℙ(<i>V</i>), assigning to each term <i>t</i> the set <i>vars</i>(<i>t</i>) ⊊ <i>V</i> of <b>free variables</b> occurring in <i>t</i>.</li>
<li>An <b>equivalence relation</b> ≡ on <i>T</i>, indicating which terms are considered equal. For higher-order unification, usually <i>t</i> ≡ <i>u</i> if <i>t</i> and <i>u</i> are alpha equivalent. For first-order E-unification, ≡ reflects the background knowledge about certain function symbols; for example, if ⊕ is considered commutative, <i>t</i> ≡ <i>u</i> if <i>u</i> results from <i>t</i> by swapping the arguments of ⊕ at some (possibly all) occurrences.  If there is no background knowledge at all, then only literally, or syntactically, identical terms are considered equal; in this case, ≡ is called the <b>free theory</b> (because it is a free object), the <b>empty theory</b> (because the set of equational sentences, or the background knowledge, is empty), the <b>theory of uninterpreted functions</b> (because unification is done on uninterpreted terms), or the <b>theory of constructors</b> (because all function symbols just build up data terms, rather than operating on them).</li>
</ul>
<h3>First-order term</h3>
<p>Given a set <i>V</i> of variable symbols, a set <i>C</i> of constant symbols and sets <i>F</i><sub><i>n</i></sub> of <i>n</i>-ary function symbols, also called operator symbols, for each natural number <i>n</i> ≥ 1, the set of (unsorted first-order) terms <i>T</i> is recursively defined to be the smallest set with the following properties:</p>
<ul>
<li>every variable symbol is a term: <i>V</i> ⊆ <i>T</i>,</li>
<li>every constant symbol is a term: <i>C</i> ⊆ <i>T</i>,</li>
<li>from every <i>n</i> terms <i>t</i><sub>1</sub>,...,<i>t</i><sub><i>n</i></sub>, and every <i>n</i>-ary function symbol <i>f</i> ∈ <i>F</i><sub><i>n</i></sub>, a larger term <i>f</i>(<i>t</i><sub>1</sub>,...,<i>t</i><sub><i>n</i></sub>) can be built.</li>
</ul>
<p>For example, if <i>x</i> ∈ <i>V</i> is a variable symbol, 1 ∈ <i>C</i> is a constant symbol, and <i>add</i> ∈ <i>F</i><sub>2</sub> is a binary function symbol, then <i>x</i> ∈ <i>T</i>, 1 ∈ <i>T</i>, and (hence) <i>add</i>(<i>x</i>,1) ∈ <i>T</i> by the first, second, and third term building rule, respectively. The latter term is usually written as <i>x</i>+1, using infix notation and the more common operator symbol + for convenience.</p>
<h3>Higher-order term</h3>
<h3>Substitution</h3>
<p>A <b>substitution</b> is a mapping σ: <i>V</i> → <i>T</i> from variables to terms; the notation { <i>x</i><sub>1</sub> ↦ <i>t</i><sub>1</sub>, ..., <i>x</i><sub><i>k</i></sub> ↦ <i>t</i><sub><i>k</i></sub> } refers to a substitution mapping each variable <i>x</i><sub><i>i</i></sub> to the term <i>t</i><sub><i>i</i></sub>, for <i>i</i>=1,...,<i>k</i>, and every other variable to itself. <b>Applying</b> that substitution to a term <i>t</i> is written in postfix notation as <i>t</i> {<i>x</i><sub>1</sub> ↦ <i>t</i><sub>1</sub>, ..., <i>x</i><sub><i>k</i></sub> ↦ <i>t</i><sub><i>k</i></sub>}; it means to (simultaneously) replace every occurrence of each variable <i>x</i><sub><i>i</i></sub> in the term <i>t</i> by <i>t</i><sub><i>i</i></sub>. The result <i>t</i>σ of applying a substitution σ to a term <i>t</i> is called an <b>instance</b> of that term <i>t</i>. As a first-order example, applying the substitution { <i>x</i> ↦ <i>h</i>(<i>a</i>,<i>y</i>), <i>z</i> ↦ <i>b</i> } to the term</p>
<h3>Generalization, specialization</h3>
<p>If a term <i>t</i> has an instance equivalent to a term <i>u</i>, that is, if <i>t</i>σ ≡ <i>u</i> for some substitution σ, then <i>t</i> is called <b>more general</b> than <i>u</i>, and <i>u</i> is called <b>more special</b> than, or <b>subsumed</b> by, <i>t</i>. For example, <i>x</i> ⊕ <i>a</i> is more general than <i>a</i> ⊕ <i>b</i> if ⊕ is commutative, since then (<i>x</i> ⊕ <i>a</i>) {<i>x</i>↦<i>b</i>} = <i>b</i> ⊕ <i>a</i> ≡ <i>a</i> ⊕ <i>b</i>.</p>
<p>If ≡ is literal (syntactic) identity of terms, a term may be both more general and more special than another one only if both terms differ just in their variable names, not in their syntactic structure; such terms are called <b>variants</b>, or <b>renamings</b> of each other. For example, <i>f</i>(<i>x</i><sub>1</sub>,<i>a</i>,<i>g</i>(<i>z</i><sub>1</sub>),<i>y</i><sub>1</sub>) is a variant of <i>f</i>(<i>x</i><sub>2</sub>,<i>a</i>,<i>g</i>(<i>z</i><sub>2</sub>),<i>y</i><sub>2</sub>), since <i>f</i>(<i>x</i><sub>1</sub>,<i>a</i>,<i>g</i>(<i>z</i><sub>1</sub>),<i>y</i><sub>1</sub>) { <i>x</i><sub>1</sub> ↦ <i>x</i><sub>2</sub>, <i>y</i><sub>1</sub> ↦ <i>y</i><sub>2</sub>, <i>z</i><sub>1</sub> ↦ <i>z</i><sub>2</sub> } = <i>f</i>(<i>x</i><sub>2</sub>,<i>a</i>,<i>g</i>(<i>z</i><sub>2</sub>),<i>y</i><sub>2</sub>) and <i>f</i>(<i>x</i><sub>2</sub>,<i>a</i>,<i>g</i>(<i>z</i><sub>2</sub>),<i>y</i><sub>2</sub>) { <i>x</i><sub>2</sub> ↦ <i>x</i><sub>1</sub>, <i>y</i><sub>2</sub> ↦ <i>y</i><sub>1</sub>, <i>z</i><sub>2</sub> ↦ <i>z</i><sub>1</sub> } = <i>f</i>(<i>x</i><sub>1</sub>,<i>a</i>,<i>g</i>(<i>z</i><sub>1</sub>),<i>y</i><sub>1</sub>). However, <i>f</i>(<i>x</i><sub>1</sub>,<i>a</i>,<i>g</i>(<i>z</i><sub>1</sub>),<i>y</i><sub>1</sub>) is <i>not</i> a variant of <i>f</i>(<i>x</i><sub>2</sub>,<i>a</i>,<i>g</i>(<i>x</i><sub>2</sub>),<i>x</i><sub>2</sub>), since no substitution can transform the latter term into the former one. The latter term is therefore properly more special than the former one.</p>
<p>For arbitrary ≡, a term may be both more general and more special than a structurally different term. For example, if ⊕ is idempotent, that is, if always <i>x</i> ⊕ <i>x</i> ≡ <i>x</i>, then the term <i>x</i> ⊕ <i>y</i> is more general than (<i>x</i> ⊕ <i>y</i>) {<i>x</i> ↦ <i>z</i>, <i>y</i> ↦ <i>z</i>} = <i>z</i> ⊕ <i>z</i> ≡ <i>z</i>, and vice versa <i>z</i> is more general than <i>z</i> {<i>z</i> ↦ <i>x</i> ⊕ <i>y</i>} = <i>x</i> ⊕ <i>y</i>, although <i>x</i>⊕<i>y</i> and <i>z</i> are of different structure.</p>
<p>A substitution σ is <b>more special</b> than, or <b>subsumed</b> by, a substitution τ if <i>x</i>σ is more special than <i>x</i>τ for each variable <i>x</i>. For example, { <i>x</i> ↦ <i>f</i>(<i>u</i>), <i>y</i> ↦ <i>f</i>(<i>f</i>(<i>u</i>)) } is more special than { <i>x</i> ↦ <i>z</i>, <i>y</i> ↦ <i>f</i>(<i>z</i>) }, since <i>f</i>(<i>u</i>) and <i>f</i>(<i>f</i>(<i>u</i>)) is more special than <i>z</i> and <i>f</i>(<i>z</i>), respectively.</p>
<h3>Unification problem, solution set</h3>
<p>A <b>unification problem</b> is a finite set { <i>l</i><sub>1</sub> ≐ <i>r</i><sub>1</sub>, ..., <i>l</i><sub><i>n</i></sub> ≐ <i>r</i><sub><i>n</i></sub> } of potential equations, where <i>l</i><sub><i>i</i></sub>, <i>r</i><sub><i>i</i></sub> ∈ <i>T</i>. A substitution σ is a <b>solution</b> of that problem if <i>l</i><sub><i>i</i></sub>σ ≡ <i>r</i><sub><i>i</i></sub>σ for <i>i</i>=1,...,<i>n</i>. Such a substitution is also called a <b>unifier</b> of the unification problem. For example, if ⊕ is associative, the unification problem { <i>x</i> ⊕ <i>a</i> ≐ <i>a</i> ⊕ <i>x</i> } has the solutions {<i>x</i> ↦ <i>a</i>}, {<i>x</i> ↦ <i>a</i> ⊕ <i>a</i>}, {<i>x</i> ↦ <i>a</i> ⊕ <i>a</i> ⊕ <i>a</i>}, etc., while the problem { <i>x</i> ⊕ <i>a</i> ≐ <i>a</i> } has no solution.</p>
<p>For a given unification problem, a set <i>S</i> of unifiers is called <b>complete</b> if each solution substitution is subsumed by some substitution σ ∈ <i>S</i>; the set <i>S</i> is called <b>minimal</b> if none of its members subsumes another one.</p>
<h2>Syntactic unification of first-order terms</h2>
<p><i>Syntactic unification of first-order terms</i> is the most widely used unification framework. It is based on <i>T</i> being the set of <i>first-order terms</i> (over some given set <i>V</i> of variables, <i>C</i> of constants and <i>F</i><sub><i>n</i></sub> of <i>n</i>-ary function symbols) and on ≡ being <i>syntactic equality</i>. In this framework, each solvable unification problem {<i>l</i><sub>1</sub> ≐ <i>r</i><sub>1</sub>, ..., <i>l</i><sub><i>n</i></sub> ≐ <i>r</i><sub><i>n</i></sub>} has a complete, and obviously minimal, singleton solution set {σ}. Its member σ is called the <b>most general unifier (mgu)</b> of the problem. The terms on the left and the right hand side of each potential equation become syntactically equal when the mgu is applied i.e. <i>l</i><sub>1</sub>σ = <i>r</i><sub>1</sub>σ ∧ ... ∧ <i>l</i><sub><i>n</i></sub>σ = <i>r</i><sub><i>n</i></sub>σ. Any unifier of the problem is subsumed by the mgu σ. The mgu is unique up to variants: if <i>S</i><sub>1</sub> and <i>S</i><sub>2</sub> are both complete and minimal solution sets of the same syntactical unification problem, then <i>S</i><sub>1</sub> = { σ<sub>1</sub> } and <i>S</i><sub>2</sub> = { σ<sub>2</sub> } for some substitutions σ<sub>1</sub> and σ<sub>2</sub>, and <i>x</i>σ<sub>1</sub> is a variant of <i>x</i>σ<sub>2</sub> for each variable <i>x</i> occurring in the problem.</p>
<p>For example, the unification problem { <i>x</i> ≐ <i>z</i>, <i>y</i> ≐ <i>f</i>(<i>x</i>) } has a unifier { <i>x</i> ↦ <i>z</i>, <i>y</i> ↦ <i>f</i>(<i>z</i>) }, because</p>
<p>This is also the most general unifier. Other unifiers for the same problem are e.g. { <i>x</i> ↦ <i>f</i>(<i>x</i><sub>1</sub>), <i>y</i> ↦ <i>f</i>(<i>f</i>(<i>x</i><sub>1</sub>)), <i>z</i> ↦ <i>f</i>(<i>x</i><sub>1</sub>) }, { <i>x</i> ↦ <i>f</i>(<i>f</i>(<i>x</i><sub>1</sub>)), <i>y</i> ↦ <i>f</i>(<i>f</i>(<i>f</i>(<i>x</i><sub>1</sub>))), <i>z</i> ↦ <i>f</i>(<i>f</i>(<i>x</i><sub>1</sub>)) }, and so on; there are infinitely many similar unifiers.</p>
<p>As another example, the problem <i>g</i>(<i>x</i>,<i>x</i>) ≐ <i>f</i>(<i>y</i>) has no solution with respect to ≡ being literal identity, since any substitution applied to the left and right hand side will keep the outermost <i>g</i> and <i>f</i>, respectively, and terms with different outermost function symbols are syntactically different.</p>
<h3>A unification algorithm</h3>
<p>The first algorithm given by Robinson (1965) was rather inefficient; cf. box. The following faster algorithm originated from Martelli, Montanari (1982). This paper also lists preceding attempts to find an efficient syntactical unification algorithm, and states that linear-time algorithms were discovered independently by Martelli, Montanari (1976) and Paterson, Wegman (1978).</p>
<p>Given a finite set <i>G</i> = { <i>s</i><sub>1</sub> ≐ <i>t</i><sub>1</sub>, ..., <i>s</i><sub><i>n</i></sub> ≐ <i>t</i><sub><i>n</i></sub> } of potential equations, the algorithm applies rules to transform it to an equivalent set of equations of the form { <i>x</i><sub>1</sub> ≐ <i>u</i><sub>1</sub>, ..., <i>x</i><sub><i>m</i></sub> ≐ <i>u</i><sub><i>m</i></sub> } where <i>x</i><sub>1</sub>, ..., <i>x</i><sub><i>m</i></sub> are distinct variables and <i>u</i><sub>1</sub>, ..., <i>u</i><sub><i>m</i></sub> are terms containing none of the <i>x</i><sub><i>i</i></sub>. A set of this form can be read as a substitution. If there is no solution the algorithm terminates with ⊥; other authors use "Ω", "{}", or "<i>fail</i>" in that case. The operation of substituting all occurrences of variable <i>x</i> in problem <i>G</i> with term <i>t</i> is denoted <i>G</i> {<i>x</i> ↦ <i>t</i>}. For simplicity, constant symbols are regarded as function symbols having zero arguments.</p>
<h4>Occurs check</h4>
<p>An attempt to unify a variable <i>x</i> with a term containing <i>x</i> as a strict subterm <i>x</i>≐<i>f</i>(...,<i>x</i>,...) would lead to an infinite term as solution for <i>x</i>, since <i>x</i> would occur as a subterm of itself. In the set of (finite) first-order terms as defined above, the equation <i>x</i>≐<i>f</i>(...,<i>x</i>,...) has no solution; hence the <i>eliminate</i> rule may only be applied if <i>x</i> ∉ <i>vars</i>(<i>t</i>). Since that additional check, called <i>occurs check</i>, slows down the algorithm, it is omitted e.g. in most Prolog systems. From a theoretical point of view, omitting the check amounts to solving equations over infinite trees, see below.</p>
<h4>Proof of termination</h4>
<p>For the proof of termination of the algorithm consider a triple &lt;<i>n</i><sub><i>var</i></sub>,<i>n</i><sub><i>lhs</i></sub>,<i>n</i><sub><i>eqn</i></sub>&gt; where <i>n</i><sub><i>var</i></sub> is the number of variables that occur more than once in the equation set, <i>n</i><sub><i>lhs</i></sub> is the number of function symbols and constants on the left hand sides of potential equations, and <i>n</i><sub><i>eqn</i></sub> is the number of equations. When rule <i>eliminate</i> is applied, <i>n</i><sub><i>var</i></sub> decreases, since <i>x</i> is eliminated from <i>G</i> and kept only in { <i>x</i> ≐ <i>t</i> }. Applying any other rule can never increase <i>n</i><sub><i>var</i></sub> again. When rule <i>decompose</i>, <i>conflict</i>, or <i>swap</i> is applied, <i>n</i><sub><i>lhs</i></sub> decreases, since at least the left hand side's outermost <i>f</i> disappears. Applying any of the remaining rules <i>delete</i> or <i>check</i> can't increase <i>n</i><sub><i>lhs</i></sub>, but decreases <i>n</i><sub><i>eqn</i></sub>. Hence, any rule application decreases the triple &lt;<i>n</i><sub><i>var</i></sub>,<i>n</i><sub><i>lhs</i></sub>,<i>n</i><sub><i>eqn</i></sub>&gt; with respect to the lexicographical order, which is possible only a finite number of times.</p>
<p>Conor McBride observes that “by expressing the structure which unification exploits” in a dependently typed language such as Epigram, Robinson's algorithm can be made recursive on the number of variables, in which case a separate termination proof becomes unnecessary.</p>
<h3>Examples of syntactic unification of first-order terms</h3>
<p>In the Prolog syntactical convention a symbol starting with an upper case letter is a variable name; a symbol that starts with a lowercase letter is a function symbol; the comma is used as the logical <i>and</i> operator. For maths notation, <i>x,y,z</i> are used as variables, <i>f,g</i> as function symbols, and <i>a,b</i> as constants.</p>
<p>Succeeds in traditional Prolog and in Prolog II, unifying <i>x</i> with infinite term <i>x=f(f(f(f(...))))</i>.</p>
<p>The most general unifier of a syntactic first-order unification problem of size <i>n</i> may have a size of 2. For example, the problem { (((<i>a</i>*<i>z</i>)*<i>y</i>)*<i>x</i>)*<i>w</i> ≐ <i>w</i>*(<i>x</i>*(<i>y</i>*(<i>z</i>*<i>a</i>))) } has the most general unifier { <i>z</i> ↦ <i>a</i>, <i>y</i> ↦ <i>a</i>*<i>a</i>, <i>x</i> ↦ (<i>a</i>*<i>a</i>)*(<i>a</i>*<i>a</i>), <i>w</i> ↦ ((<i>a</i>*<i>a</i>)*(<i>a</i>*<i>a</i>))*((<i>a</i>*<i>a</i>)*(<i>a</i>*<i>a</i>)) }, cf. picture. In order to avoid exponential time complexity caused by such blow-up, advanced unification algorithms work on directed acyclic graphs (dags) rather than trees.</p>
<h3>Application: Unification in logic programming</h3>
<p>The concept of unification is one of the main ideas behind logic programming, best known through the language Prolog. It represents the mechanism of binding the contents of variables and can be viewed as a kind of one-time assignment. In Prolog, this operation is denoted by the equality symbol <tt>=</tt>, but is also done when instantiating variables (see below). It is also used in other languages by the use of the equality symbol <tt>=</tt>, but also in conjunction with many operations including <tt>+</tt>, <tt>-</tt>, <tt>*</tt>, <tt>/</tt>. Type inference algorithms are typically based on unification.</p>
<p>In Prolog:</p>
<ol>
<li>A variable which is uninstantiated—i.e. no previous unifications were performed on it—can be unified with an atom, a term, or another uninstantiated variable, thus effectively becoming its alias. In many modern Prolog dialects and in first-order logic, a variable cannot be unified with a term that contains it; this is the so-called <i>occurs check</i>.</li>
<li>Two atoms can only be unified if they are identical.</li>
<li>Similarly, a term can be unified with another term if the top function symbols and arities of the terms are identical and if the parameters can be unified simultaneously. Note that this is a recursive behavior.</li>
</ol>
<h3>Application: Type inference</h3>
<p>Unification is used during type inference, for instance in the functional programming language Haskell. On one hand, the programmer does not need to provide type information for every function, on the other hand it is used to detect typing errors. The Haskell expression 1:['a','b','c'] is not correctly typed, because the list construction function ":" is of type a-&gt;[a]-&gt;[a] and for the first argument "1" the polymorphic type variable "a" has to denote the type Int whereas "['a','b','c']" is of type [Char], but "a" cannot be both Char and Int at the same time.</p>
<p>Like for prolog an algorithm for type inference can be given:</p>
<ol>
<li>Any type variable unifies with any type expression, and is instantiated to that expression. A specific theory might restrict this rule with an occurs check.</li>
<li>Two type constants unify only if they are the same type.</li>
<li>Two type constructions unify only if they are applications of the same type constructor and all of their component types recursively unify.</li>
</ol>
<p>Due to its declarative nature, the order in a sequence of unifications is (usually) unimportant.</p>
<p>Note that in the terminology of first-order logic, an atom is a basic proposition and is unified similarly to a Prolog term.</p>
<h2>Order-sorted unification</h2>
<p><i>Order-sorted logic</i> allows one to assign a <i>sort</i>, or <i>type</i>, to each term, and to declare a sort <i>s</i><sub>1</sub> a <i>subsort</i> of another sort <i>s</i><sub>2</sub>, commonly written as <i>s</i><sub>1</sub> ⊆ <i>s</i><sub>2</sub>. For example, when reаsoning about biological creatures, it is useful to declare a sort <i>dog</i> to be a subsort of a sort <i>animal</i>. Wherever a term of some sort <i>s</i> is required, a term of any subsort of <i>s</i> may be supplied instead. For example, assuming a function declaration <i>mother</i>: <i>animal</i> → <i>animal</i>, and a constant declaration <i>lassie</i>: <i>dog</i>, the term <i>mother</i>(<i>lassie</i>) is perfectly valid and has the sort <i>animal</i>. In order to supply the information that the mother of a dog is a dog in turn, another declaration <i>mother</i>: <i>dog</i> → <i>dog</i> may be issued; this is called <i>function overloading</i>, similar to overloading in programming languages.</p>
<p>Walther gave a unification algorithm for terms in order-sorted logic, requiring for any two declared sorts <i>s</i><sub>1</sub>, <i>s</i><sub>2</sub> their intersection <i>s</i><sub>1</sub> ∩ <i>s</i><sub>2</sub> to be declared, too: if <i>x</i><sub>1</sub> and <i>x</i><sub>2</sub> is a variable of sort <i>s</i><sub>1</sub> and <i>s</i><sub>2</sub>, respectively, the equation <i>x</i><sub>1</sub> ≐ <i>x</i><sub>2</sub> has the solution { <i>x</i><sub>1</sub> = <i>x</i>, <i>x</i><sub>2</sub> = <i>x</i> }, where <i>x</i>: <i>s</i><sub>1</sub> ∩ <i>s</i><sub>2</sub>.  After incorporating this algorithm into a clause-based automated theorem prover, he could solve a benchmark problem by translating it into order-sorted logic, thereby boiling it down an order of magnitude, as many unary predicates turned into sorts.</p>
<p>Smolka generalized order-sorted logic to allow for parametric polymorphism.  In his framework, subsort declarations are propagated to complex type expressions. As a programming example, a parametric sort <i>list</i>(<i>X</i>) may be declared (with <i>X</i> being a type parameter as in a C++ template), and from a subsort declaration <i>int</i> ⊆ <i>float</i> the relation <i>list</i>(<i>int</i>) ⊆ <i>list</i>(<i>float</i>) is automatically inferred, meaning that each list of integers is also a list of floats.</p>
<p>Schmidt-Schauß generalized order-sorted logic to allow for term declarations.  As an example, assuming subsort declarations <i>even</i> ⊆ <i>int</i> and <i>odd</i> ⊆ <i>int</i>, a term declaration like ∀<i>i</i>:<i>int</i>. (<i>i</i>+i):<i>even</i> allows to declare a property of integer addition that could not be expressed by ordinary overloading.</p>
<h2>Unification of infinite terms</h2>
<p>Background on infinite trees:</p>
<ul>
<li>B. Courcelle (1983). "Fundamental Properties of Infinite Trees". <i>Theoret. Comput. Sci.</i> <b>25</b>: 95–169. doi:10.1016/0304-3975(83)90059-2. </li>
<li>Michael J. Maher (Jul 1988). "Complete Axiomatizations of the Algebras of Finite, Rational and Infinite Trees". <i>Proc. IEEE 3rd Annual Symp. on Logic in Computer Science, Edinburgh</i>. pp. 348–357. </li>
<li>Joxan Jaffar, Peter J. Stuckey (1986). "Semantics of Infinite Tree Logic Programming". <i>Theoretical Computer Science</i> <b>46</b>: 141–158. doi:10.1016/0304-3975(86)90027-7. </li>
</ul>
<p>Unification algorithm, Prolog II:</p>
<ul>
<li>A. Colmerauer (1982). K.L. Clark and S.-A. Tarnlund, ed. <i>Prolog and Infinite Trees</i>. Academic Press. </li>
<li>Alain Colmerauer (1984). "Equations and Inequations on Finite and Infinite Trees". In ICOT. <i>Proc. Int. Conf. on Fifth Generation Computer Systems</i>. pp. 85–99. </li>
</ul>
<p>Applications:</p>
<ul>
<li>Francis Giannesini, Jacques Cohen (1984). "Parser Generation and Grammar Manipulation using Prolog's Infinite Trees". <i>J. Logic Programming</i> <b>3</b>: 253–265. </li>
</ul>
<h2>E-unification</h2>
<p><b>E-unification</b> is the problem of finding solutions to a given set of equations, taking into account some equational background knowledge <i>E</i>. The latter is given as a set of universal equalities. For some particular sets <i>E</i>, equation solving algorithms (a.k.a. <i>E-unification algorithms</i>) have been devised; for others it has been proven that no such algorithms can exist.</p>
<p>For example, if <i>a</i> and <i>b</i> are distinct constants, the equation <i>x</i>*<i>a</i> ≐ <i>y</i>*<i>b</i> has no solution with respect to purely syntactic unification, where nothing is known about the operator *. However, if the * is known to be commutative, then the substitution { <i>x</i> ↦ <i>b</i>, <i>y</i> ↦ <i>a</i> } solves the above equation, since</p>
<p>The background knowledge <i>E</i> could state the commutativity of * by the universal equality "<i>u</i>*<i>v</i> = <i>v</i>*<i>u</i> for all <i>u</i>, <i>v</i>".</p>
<h3>Particular background knowledge sets E</h3>
<p>It is said that <i>unification is decidable</i> for a theory, if a unification algorithm has been devised for it that terminates for <i>any</i> input problem. It is said that <i>unification is semi-decidable</i> for a theory, if a unification algorithm has been devised for it that terminates for any <i>solvable</i> input problem, but may keep searching forever for solutions of an unsolvable input problem.</p>
<p><b>Unification is decidable</b> for the following theories:</p>
<ul>
<li><b>A</b></li>
<li><b>A</b>,<b>C</b></li>
<li><b>A</b>,<b>C</b>,<b>I</b></li>
<li><b>A</b>,<b>C</b>,<b>N<sub>l</sub></b></li>
<li><b>A</b>,<b>I</b></li>
<li><b>A</b>,<b>N<sub>l</sub></b>,<b>N<sub>r</sub></b> (monoid)</li>
<li><b>C</b></li>
<li>Boolean rings</li>
<li>Abelian groups, even if the signature is expanded by arbitrary additional symbols (but not axioms)</li>
<li>K4 modal algebras</li>
</ul>
<p><b>Unification is semi-decidable</b> for the following theories:</p>
<ul>
<li><b>A</b>,<b>D<sub>l</sub></b>,<b>D<sub>r</sub></b></li>
<li><b>A</b>,<b>C</b>,<b>D<sub>l</sub></b></li>
<li>Commutative rings</li>
</ul>
<h3>One-sided paramodulation</h3>
<p>If there is a convergent term rewriting system <i>R</i> available for <i>E</i>, the <b>one-sided paramodulation</b> algorithm can be used to enumerate all solutions of given equations.</p>
<p>Starting with <i>G</i> being the unification problem to be solved and <i>S</i> being the identity substitution, rules are applied nondeterministically until the empty set appears as the actual <i>G</i>, in which case the actual <i>S</i> is a unifying substitution. Depending on the order the paramodulation rules are applied, on the choice of the actual equation from <i>G</i>, and on the choice of <i>R</i>’s rules in <i>mutate</i>, different computations paths are possible. Only some lead to a solution, while others end at a <i>G</i> ≠ {} where no further rule is applicable (e.g. <i>G</i> = { <i>f</i>(...) ≐ <i>g</i>(...) }).</p>
<p>For an example, a term rewrite system <i>R</i> is used defining the <i>append</i> operator of lists built from <i>cons</i> and <i>nil</i>; where <i>cons</i>(<i>x</i>,<i>y</i>) is written in infix notation as <i>x</i>.<i>y</i> for brevity; e.g. <i>app</i>(<i>a</i>.<i>b</i>.<i>nil</i>,<i>c</i>.<i>d</i>.<i>nil</i>) → <i>a</i>.<i>app</i>(<i>b</i>.<i>nil</i>,<i>c</i>.<i>d</i>.<i>nil</i>) → <i>a</i>.<i>b</i>.<i>app</i>(<i>nil</i>,<i>c</i>.<i>d</i>.<i>nil</i>) → <i>a</i>.<i>b</i>.<i>c</i>.<i>d</i>.<i>nil</i> demonstrates the concatenation of the lists <i>a</i>.<i>b</i>.<i>nil</i> and <i>c</i>.<i>d</i>.<i>nil</i>, employing the rewrite rule 2,2, and 1. The equational theory <i>E</i> corresponding to <i>R</i> is the congruence closure of <i>R</i>, both viewed as binary relations on terms. For example, <i>app</i>(<i>a</i>.<i>b</i>.<i>nil</i>,<i>c</i>.<i>d</i>.<i>nil</i>) ≡ <i>a</i>.<i>b</i>.<i>c</i>.<i>d</i>.<i>nil</i> ≡ <i>app</i>(<i>a</i>.<i>b</i>.<i>c</i>.<i>d</i>.<i>nil</i>,<i>nil</i>). The paramodulation algorithm enumerates solutions to equations with respect to that <i>E</i> when fed with the example <i>R</i>.</p>
<p>A successful example computation path for the unification problem { <i>app</i>(<i>x</i>,<i>app</i>(<i>y</i>,<i>x</i>)) ≐ <i>a</i>.<i>a</i>.<i>nil</i> } is shown below. To avoid variable name clashes, rewrite rules are consistently renamed each time before their use by rule <i>mutate</i>; <i>v</i><sub>2</sub>, <i>v</i><sub>3</sub>, ... are computer-generated variable names for this purpose. In each line, the chosen equation from <i>G</i> is highlighted in red. Each time the <i>mutate</i> rule is applied, the chosen rewrite rule (<i>1</i> or <i>2</i>) is indicated in parentheses. From the last line, the unifying substitution <i>S</i> = { <i>y</i> ↦ <i>nil</i>, <i>x</i> ↦ <i>a</i>.<i>nil</i> } can be obtained. In fact, <i>app</i>(<i>x</i>,<i>app</i>(<i>y</i>,<i>x</i>)) {<i>y</i>↦<i>nil</i>, <i>x</i>↦ <i>a</i>.<i>nil</i> } = <i>app</i>(<i>a</i>.<i>nil</i>,<i>app</i>(<i>nil</i>,<i>a</i>.<i>nil</i>)) ≡ <i>app</i>(<i>a</i>.<i>nil</i>,<i>a</i>.<i>nil</i>) ≡ <i>a</i>.<i>app</i>(<i>nil</i>,<i>a</i>.<i>nil</i>) ≡ <i>a</i>.<i>a</i>.<i>nil</i> solves the given problem. A second successful computation path, obtainable by choosing "mutate(1), mutate(2), mutate(2), mutate(1)" leads to the substitution <i>S</i> = { <i>y</i> ↦ <i>a</i>.<i>a</i>.<i>nil</i>, <i>x</i> ↦ <i>nil</i> }; it is not shown here. No other path leads to a success.</p>
<h3>Narrowing</h3>
<p>If <i>R</i> is a convergent term rewriting system for <i>E</i>, an approach alternative to the previous section consists in successive application of "<b>narrowing steps</b>"; this will eventually enumerate all solutions of a given equation. A narrowing step (cf. picture) consists in</p>
<ul>
<li>choosing a nonvariable subterm of the current term,</li>
<li>syntactically unifying it with the left hand side of a rule from <i>R</i>, and</li>
<li>replacing the instantiated rule's right hand side into the instantiated term.</li>
</ul>
<p>Formally, if <i>l</i> → <i>r</i> is a renamed copy of a rewrite rule from <i>R</i>, having no variables in common with a term <i>s</i>, and the subterm <i>s</i>|<sub><i>p</i></sub> is not a variable and is unifiable with <i>l</i> via the mgu σ, then <i>s</i> can be <b>narrowed</b> to the term <i>t</i> = <i>s</i>σ[<i>r</i>σ]<sub><i>p</i></sub>, i.e. to the term <i>s</i>σ, with the subterm at <i>p</i> replaced by <i>r</i>σ. The situation that <i>s</i> can be narrowed to <i>t</i> is commonly denoted as <i>s</i> ~› <i>t</i>. Intuitively, a sequence of narrowing steps <i>t</i><sub>1</sub> ~› <i>t</i><sub>2</sub> ~› ... ~› <i>t</i><sub><i>n</i></sub> can be thought of as a sequence of rewrite steps <i>t</i><sub>1</sub> → <i>t</i><sub>2</sub> → ... → <i>t</i><sub><i>n</i></sub>, but with the initial term <i>t</i><sub>1</sub> being further and further instantiated, as necessary to make each of the used rules applicable.</p>
<p>The above example paramodulation computation corresponds to the following narrowing sequence ("↓" indicating instatiation here):</p>
<p>The last term, <i>v</i><sub>2</sub>.<i>v</i><sub>2</sub>.<i>nil</i> can be syntactically unified with the original right hand side term <i>a</i>.<i>a</i>.<i>nil</i>.</p>
<p>The <i>narrowing lemma</i> ensures that whenever an instance of a term <i>s</i> can be rewritten to a term <i>t</i> by a convergent term rewriting system, then <i>s</i> and <i>t</i> can be narrowed and rewritten to a term <i>s</i>’ and <i>t</i>’, respectively, such that <i>t</i>’ is an instance of <i>s</i>’. Formally: whenever <i>s</i>σ → <i>t</i> holds for some substitution σ, then there exist terms <i>s</i>’, <i>t</i>’ such that <i>s</i> ~› <i>s</i>’ and <i>t</i> → <i>t</i>’ and <i>s</i>’τ = <i>t</i>’ for some substitution τ.</p>
<h2>Higher-order unification</h2>
<p>Many applications require one to consider the unification of typed lambda-terms instead of first-order terms. Such unification is often called <i>higher-order unification</i>. A well studied branch of higher-order unification is the problem of unifying simply typed lambda terms modulo the equality determined by αβη conversions. Such unification problems do not have most general unifiers. While higher-order unification is undecidable, Gérard Huet gave a semi-decidable (pre-)unification algorithm that allows a systematic search of the space of unifiers (generalizing the unification algorithm of Martelli-Montanari with rules for terms containing higher-order variables) that seems to work sufficiently well in practice. Huet and Gilles Dowek have written articles surveying this topic.</p>
<p>Dale Miller has described what is now called higher-order pattern unification. This subset of higher-order unification is decidable and solvable unification problems have most-general unifiers. Many computer systems that contain higher-order unification, such as the higher-order logic programming languages λProlog and Twelf, often implement only the pattern fragment and not full higher-order unification.</p>
<p>In computational linguistics, one of the most influential theories of ellipsis is that ellipses are represented by free variables whose values are then determined using Higher-Order Unification (HOU). For instance, the semantic representation of "Jon likes Mary and Peter does too" is like(j; m)R(p) and the value of R (the semantic representation of the ellipsis) is determined by the equation like(j; m) = R(j). The process of solving such equations is called Higher-Order Unification.</p>
<p>For example, the unification problem { <i>f</i>(<i>a</i>, <i>b</i>, <i>a</i>) ≐ <i>d</i>(<i>b</i>, <i>a</i>, <i>c</i>) }, where the only variable is <i>f</i>, has the solutions {<i>f</i> ↦ λ<i>x</i>.λ<i>y</i>.λ<i>z</i>.<i>d</i>(<i>y</i>, <i>x</i>, <i>c</i>) }, {<i>f</i> ↦ λ<i>x</i>.λ<i>y</i>.λ<i>z</i>.<i>d</i>(<i>y</i>, <i>z</i>, <i>c</i>) }, {<i>f</i> ↦ λ<i>x</i>.λ<i>y</i>.λ<i>z</i>.<i>d</i>(<i>y</i>, <i>a</i>, <i>c</i>) }, {<i>f</i> ↦ λ<i>x</i>.λ<i>y</i>.λ<i>z</i>.<i>d</i>(<i>b</i>, <i>x</i>, <i>c</i>) }, {<i>f</i> ↦ λ<i>x</i>.λ<i>y</i>.λ<i>z</i>.<i>d</i>(<i>b</i>, <i>z</i>, <i>c</i>) } and {<i>f</i> ↦ λ<i>x</i>.λ<i>y</i>.λ<i>z</i>.<i>d</i>(<i>b</i>, <i>a</i>, <i>c</i>) }.</p>
<p>Wayne Snyder gave a generalization of both higher-order unification and E-unification, i.e. an algorithm to unify lambda-terms modulo an equational theory.</p>
<h2>See also</h2>
<ul>
<li>Admissible rule</li>
<li>Explicit substitution in lambda calculus</li>
<li>Mathematical Equation solving</li>
<li>Dis-unification: solving inequations between symbolic expression</li>
<li>Anti-unification: computing a least general generalization (lgg) of two terms, dual to computing a most general instance (mgu)</li>
</ul>
<h2>Notes</h2>
<ol>
<li><b>^</b> in this case, still a complete substitution set exists (e.g. the set of all solutions at all); however, each such set contains redundant members.</li>
<li><b>^</b> E.g. <i>a</i> ⊕ (<i>b</i> ⊕ <i>f</i>(<i>x</i>)) ≡ <i>a</i> ⊕ (<i>f</i>(<i>x</i>) ⊕ <i>b</i>) ≡ (<i>b</i> ⊕ <i>f</i>(<i>x</i>)) ⊕ <i>a</i> ≡ (<i>f</i>(<i>x</i>) ⊕ <i>b</i>) ⊕ <i>a</i></li>
<li><b>^</b> formally: each unifier τ satisfies ∀<i>x</i>: <i>x</i>τ = (<i>x</i>σ)ρ for some substitution ρ</li>
<li>^   in the presence of equality <b>C</b>, equalities <b>N<sub>l</sub></b> and <b>N<sub>r</sub></b> are equivalent, similar for <b>D<sub>l</sub></b> and <b>D<sub>r</sub></b></li>
</ol>
</body>
</html>