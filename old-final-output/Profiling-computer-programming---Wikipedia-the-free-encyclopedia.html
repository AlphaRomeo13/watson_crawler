<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Profiling-computer-programming---Wikipedia-the-free-encyclopedia.html</title></head>
<body>
<h1>Profiling (computer programming)</h1>
<p>In software engineering, <b>profiling</b> ("program profiling", "software profiling") is a form of dynamic program analysis that measures, for example, the space (memory) or time complexity of a program, the usage of particular instructions, or the frequency and duration of function calls. Most commonly, profiling information serves to aid program optimization.</p>
<p>Profiling is achieved by instrumenting either the program source code or its binary executable form using a tool called a <i>profiler</i> (or <i>code profiler</i>). Profilers may use a number of different techniques, such as event-based, statistical, instrumented, and simulation methods.</p>
<p></p>
<h2>Contents</h2>
<ul>
<li>1 Gathering program events</li>
<li>2 Use of profilers</li>
<li>3 History</li>
<li>4 Profiler types based on output
<ul>
<li>4.1 Flat profiler</li>
<li>4.2 Call-graph profiler</li>
<li>4.3 Input-sensitive profiler</li>
</ul>
</li>
<li>5 Data granularity in profiler types
<ul>
<li>5.1 Event-based profilers</li>
<li>5.2 Statistical profilers</li>
<li>5.3 Instrumentation</li>
<li>5.4 Interpreter instrumentation</li>
<li>5.5 Hypervisor/Simulator</li>
</ul>
</li>
<li>6 See also</li>
<li>7 References</li>
<li>8 External links</li>
</ul>
<ul>
<li>4.1 Flat profiler</li>
<li>4.2 Call-graph profiler</li>
<li>4.3 Input-sensitive profiler</li>
</ul>
<ul>
<li>5.1 Event-based profilers</li>
<li>5.2 Statistical profilers</li>
<li>5.3 Instrumentation</li>
<li>5.4 Interpreter instrumentation</li>
<li>5.5 Hypervisor/Simulator</li>
</ul>
<p></p>
<h2>Gathering program events</h2>
<p>Profilers use a wide variety of techniques to collect data, including hardware interrupts, code instrumentation, instruction set simulation, operating system hooks, and performance counters. Profilers are used in the performance engineering process.</p>
<h2>Use of profilers</h2>
<p>"Program analysis tools are extremely important for understanding program behavior. Computer architects need such tools to evaluate how well programs will perform on new architectures. Software writers need tools to analyze their programs and identify critical sections of code. Compiler writers often use such tools to find out how well their instruction scheduling or branch prediction algorithm is performing..." <i>-- (ATOM, PLDI, '94)</i></p>
<p>The output of a profiler may be:</p>
<ul>
<li>A statistical <i>summary</i> of the events observed (a <b>profile</b>)</li>
</ul>
<p>WHATSON? 6b372b40-c088-4d11-8b67-8ca937ca0d78</p>
<pre>
<code>/* ------------ source------------------------- count */             
0001             IF X = "A"                     0055
0002                THEN DO                       
0003                  ADD 1 to XCOUNT           0032
0004                ELSE
0005             IF X = "B"                     0055
</code>
</pre>
<ul>
<li>A stream of recorded events (a <b>trace</b>)</li>
</ul>
<ul>
<li>An ongoing interaction with the hypervisor (continuous or periodic monitoring via on-screen display for instance)</li>
</ul>
<h2>History</h2>
<p>Performance-analysis tools existed on IBM/360 and IBM/370 platforms from the early 1970s, usually based on timer interrupts which recorded the Program status word (PSW) at set timer-intervals to detect "hot spots" in executing code. This was an early example of sampling (see below). In early 1974 instruction-set simulators permitted full trace and other performance-monitoring features.</p>
<p>Profiler-driven program analysis on Unix dates back to at least 1979, when Unix systems included a basic tool, <code>prof</code>, which listed each function and how much of program execution time it used. In 1982 <code>gprof</code> extended the concept to a complete call graph analysis.</p>
<p>In 1994, Amitabh Srivastava and Alan Eustace of Digital Equipment Corporation published a paper describing ATOM (Analysis Tools with OM). The ATOM platform converts a program into its own profiler: at compile time, it inserts code into the program to be analyzed. That inserted code outputs analysis data. This technique - modifying a program to analyze itself - is known as "instrumentation".</p>
<p>In 2004 both the <code>gprof</code> and ATOM papers appeared on the list of the 50 most influential PLDI papers for the 20-year period ending in 1999.</p>
<h2>Profiler types based on output</h2>
<h3>Flat profiler</h3>
<p>Flat profilers compute the average call times, from the calls, and do not break down the call times based on the callee or the context.</p>
<h3>Call-graph profiler</h3>
<p>Call graph profilers show the call times, and frequencies of the functions, and also the call-chains involved based on the callee. In some tools full context is not preserved.</p>
<h3>Input-sensitive profiler</h3>
<p>Input-sensitive profilers add a further dimension to flat or call-graph profilers by relating performance measures to features of the input workloads, such as input size or input values. They generate charts that characterize how an application's performance scales as a function of its input.</p>
<h2>Data granularity in profiler types</h2>
<p>Profilers, which are also programs themselves, analyze target programs by collecting information on their execution. Based on their data granularity, on how profilers collect information, they are classified into event based or statistical profilers. Since profilers interrupt program execution to collect information, they have a finite resolution in the time measurements, which should be taken with a grain of salt.</p>
<h3>Event-based profilers</h3>
<p>The programming languages listed here have event-based profilers:</p>
<ul>
<li>Java: the JVMTI (JVM Tools Interface) API, formerly JVMPI (JVM Profiling Interface), provides hooks to profilers, for trapping events like calls, class-load, unload, thread enter leave.</li>
<li>.NET: Can attach a profiling agent as a <i>COM</i> server to the <i>CLR</i> using Profiling <i>API</i>. Like Java, the runtime then provides various callbacks into the agent, for trapping events like method JIT / enter / leave, object creation, etc. Particularly powerful in that the profiling agent can rewrite the target application's bytecode in arbitrary ways.</li>
<li>Python: Python profiling includes the profile module, hotshot (which is call-graph based), and using the 'sys.setprofile' function to trap events like c_{call,return,exception}, python_{call,return,exception}.</li>
<li>Ruby: Ruby also uses a similar interface to Python for profiling. Flat-profiler in profile.rb, module, and ruby-prof a C-extension are present.</li>
</ul>
<h3>Statistical profilers</h3>
<p>Some profilers operate by sampling. A sampling profiler probes the target program's program counter at regular intervals using operating system interrupts. Sampling profiles are typically less numerically accurate and specific, but allow the target program to run at near full speed.</p>
<p>The resulting data are not exact, but a statistical approximation. "The actual amount of error is usually more than one sampling period. In fact, if a value is n times the sampling period, the expected error in it is the square-root of n sampling periods." </p>
<p>In practice, sampling profilers can often provide a more accurate picture of the target program's execution than other approaches, as they are not as intrusive to the target program, and thus don't have as many side effects (such as on memory caches or instruction decoding pipelines). Also since they don't affect the execution speed as much, they can detect issues that would otherwise be hidden. They are also relatively immune to over-evaluating the cost of small, frequently called routines or 'tight' loops. They can show the relative amount of time spent in user mode versus interruptible kernel mode such as system call processing.</p>
<p>Still, kernel code to handle the interrupts entails a minor loss of CPU cycles, diverted cache usage, and is unable to distinguish the various tasks occurring in uninterruptible kernel code (microsecond-range activity).</p>
<p>Dedicated hardware can go beyond this: ARM Cortex-M3 and some recent MIPS processors JTAG interface have a PCSAMPLE register, which samples the program counter in a truly undetectable manner.</p>
<p>Some of the most commonly used statistical profilers are AMD CodeAnalyst, Apple Inc. Shark (OSX), oprofile (Linux), Intel VTune and Parallel Amplifier (part of Intel Parallel Studio).</p>
<h3>Instrumentation</h3>
<p>This technique effectively adds instructions to the target program to collect the required information. Note that instrumenting a program can cause performance changes, and may in some cases lead to inaccurate results and/or heisenbugs. The effect will depend on what information is being collected, and on the level of detail required. For example, adding code to count every procedure/routine call will probably have less effect than counting how many times each statement is obeyed. A few computers have special hardware to collecting information; in this case the impact on the program is minimal.</p>
<p>Instrumentation is key to determining the level of control and amount of time resolution available to the profilers. The following lists a few popular tools (as of 2012) representative of each category.</p>
<ul>
<li><b>Manual</b>: Performed by the programmer, e.g. by adding instructions to explicitly calculate runtimes, simply count events or calls to measurement APIs such as the Application Response Measurement standard.</li>
<li><b>Automatic source level</b>: instrumentation added to the source code by an automatic tool according to an instrumentation policy. Example: Parasoft Insure++</li>
<li><b>Intermediate language</b>: instrumentation added to assembly or decompiled bytecodes giving support for multiple higher-level source languages and avoiding (non-symbolic) binary offset re-writing issues, for example OpenPAT.</li>
<li><b>Compiler assisted</b>: <i>gprof</i>, <i>Quantify</i> use this approach. Example: <i>gcc -pg ...</i> for gprof, and <i>quantify g++ ...</i>, for Quantify</li>
<li><b>Binary translation</b>: The tool adds instrumentation to a compiled executable, for example in ATOM.</li>
<li><b>Runtime instrumentation</b>: Directly before execution the code is instrumented. The program run is fully supervised and controlled by the tool. Examples: Pin, Valgrind, DynamoRIO.</li>
<li><b>Runtime injection</b>: More lightweight than runtime instrumentation. Code is modified at runtime to have jumps to helper functions. Example: DynInst</li>
</ul>
<h3>Interpreter instrumentation</h3>
<ul>
<li><b>Interpreter debug</b> options can enable the collection of performance metrics as the interpreter encounters each target statement. A bytecode, control table or JIT interpreters are three examples that usually have complete control over execution of the target code, thus enabling extremely comprehensive data collection opportunities.</li>
</ul>
<h3>Hypervisor/Simulator</h3>
<ul>
<li><b>Hypervisor</b>: Data are collected by running the (usually) unmodified program under a hypervisor. Example: SIMMON</li>
<li><b>Simulator</b> and <b>Hypervisor</b>: Data collected interactively and selectively by running the unmodified program under an Instruction Set Simulator. Examples: SIMON and OLIVER.</li>
</ul>
<h2>See also</h2>
<ul>
<li>Algorithmic efficiency</li>
<li>Static code analysis</li>
<li>Benchmark</li>
<li>List of performance analysis tools</li>
<li>Performance engineering</li>
<li>Performance prediction</li>
<li>PAPI is a portable interface (in the form of a library) to hardware performance counters on modern microprocessors.</li>
<li>Performance tuning</li>
<li>Worst-case execution time (WCET)</li>
<li>Java performance</li>
<li>Software archaeology</li>
</ul>
</body>
</html>