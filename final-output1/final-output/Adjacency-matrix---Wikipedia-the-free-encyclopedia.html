<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Adjacency-matrix---Wikipedia-the-free-encyclopedia.html</title></head>
<body>
<h1>Adjacency matrix</h1>
<p>In mathematics and computer science, an <b>adjacency matrix</b> is a means of representing which vertices (or nodes) of a graph are adjacent to which other vertices. Another matrix representation for a graph is the incidence matrix.</p>
<p>Specifically, the adjacency matrix of a finite graph <b>G</b> on <i>n</i> vertices is the <i>n × n</i> matrix where the non-diagonal entry <i>a</i><sub><i>ij</i></sub> is the number of edges from vertex <i>i</i> to vertex <i>j</i>, and the diagonal entry <i>a</i><sub><i>ii</i></sub>, depending on the convention, is either once or twice the number of edges (loops) from vertex <i>i</i> to itself. Undirected graphs often use the latter convention of counting loops twice, whereas directed graphs typically use the former convention. There exists a unique adjacency matrix for each isomorphism class of graphs (up to permuting rows and columns), and it is not the adjacency matrix of any other isomorphism class of graphs. In the special case of a finite simple graph, the adjacency matrix is a (0,1)-matrix with zeros on its diagonal. If the graph is undirected, the adjacency matrix is symmetric.</p>
<p>The relationship between a graph and the eigenvalues and eigenvectors of its adjacency matrix is studied in spectral graph theory.</p>
<p></p>
<h2>Contents</h2>
<ul>
<li>1 Examples</li>
<li>2 Adjacency matrix of a bipartite graph</li>
<li>3 Properties</li>
<li>4 Variations</li>
<li>5 Data structures</li>
<li>6 References</li>
<li>7 Further reading</li>
<li>8 External links</li>
</ul>
<p></p>
<h2>Examples</h2>
<p>The convention followed here is that an adjacent edge counts 1 in the matrix for an undirected graph.</p>
<p>Coordinates are 1-6.</p>
<p><br>
The Nauru graph</p>
<p><br>
Coordinates are 0-23.<br>
White fields are zeros, colored fields are ones.</p>
<p><br>
Directed Cayley graph of S<sub>4</sub></p>
<p><br>
As the graph is directed,<br>
the matrix is not symmetric.</p>
<ul>
<li>The adjacency matrix of a complete graph contains all ones except along the diagonal where there are only zeros.</li>
<li>The adjacency matrix of an empty graph is a zero matrix.</li>
</ul>
<h2>Adjacency matrix of a bipartite graph</h2>
<p>The adjacency matrix <img class="mwe-math-fallback-image-inline tex" alt="A" src="//upload.wikimedia.org/math/7/f/c/7fc56270e7a70fa81a5935b72eacbe29.png"> of a bipartite graph whose parts have <img class="mwe-math-fallback-image-inline tex" alt="r" src="//upload.wikimedia.org/math/4/b/4/4b43b0aee35624cd95b910189b3dc231.png"> and <img class="mwe-math-fallback-image-inline tex" alt="s" src="//upload.wikimedia.org/math/0/3/c/03c7c0ace395d80182db07ae2c30f034.png"> vertices has the form</p>
<p>where <img class="mwe-math-fallback-image-inline tex" alt="B" src="//upload.wikimedia.org/math/9/d/5/9d5ed678fe57bcca610140957afab571.png"> is an <img class="mwe-math-fallback-image-inline tex" alt="r \times s" src="//upload.wikimedia.org/math/b/b/4/bb44623b203a1cc8458f27aae1a60329.png"> matrix, and <img class="mwe-math-fallback-image-inline tex" alt="0" src="//upload.wikimedia.org/math/c/f/c/cfcd208495d565ef66e7dff9f98764da.png"> represents the zero matrix. Clearly, the matrix <img class="mwe-math-fallback-image-inline tex" alt="B" src="//upload.wikimedia.org/math/9/d/5/9d5ed678fe57bcca610140957afab571.png"> uniquely represents the bipartite graphs. It is sometimes called the biadjacency matrix. Formally, let <img class="mwe-math-fallback-image-inline tex" alt="G = (U, V, E)" src="//upload.wikimedia.org/math/5/e/1/5e1210aab0cd47e529c75a1e23890cfb.png"> be a bipartite graph with parts <img class="mwe-math-fallback-image-inline tex" alt="U={u_1,..., u_r}" src="//upload.wikimedia.org/math/f/6/c/f6ccaf27db0a602943bc9d67fd020962.png"> and <img class="mwe-math-fallback-image-inline tex" alt="V={v_1,..., v_s}" src="//upload.wikimedia.org/math/b/3/e/b3ed7b759012dcf8c44a16618fe12d4c.png">. The <b>biadjacency matrix</b> is the <img class="mwe-math-fallback-image-inline tex" alt="r \times s" src="//upload.wikimedia.org/math/b/b/4/bb44623b203a1cc8458f27aae1a60329.png"> 0-1 matrix <img class="mwe-math-fallback-image-inline tex" alt="B" src="//upload.wikimedia.org/math/9/d/5/9d5ed678fe57bcca610140957afab571.png"> in which <img class="mwe-math-fallback-image-inline tex" alt="b_{i,j} = 1" src="//upload.wikimedia.org/math/2/6/b/26b9767da6e1fd112b6943db16a9d6b9.png"> iff <img class="mwe-math-fallback-image-inline tex" alt="(u_i, v_j) \in E" src="//upload.wikimedia.org/math/a/3/8/a3861a1ea7a19cbc10f8b800fa2fbc11.png">.</p>
<p>If <img class="mwe-math-fallback-image-inline tex" alt="G" src="//upload.wikimedia.org/math/d/f/c/dfcf28d0734569a6a693bc8194de62bf.png"> is a bipartite multigraph or weighted graph then the elements <img class="mwe-math-fallback-image-inline tex" alt="b_{i,j}" src="//upload.wikimedia.org/math/8/0/7/807e0155cb45ea6188e441234f69583d.png"> are taken to be the number of edges between the vertices or the weight of the edge <img class="mwe-math-fallback-image-inline tex" alt="(u_i, v_j)," src="//upload.wikimedia.org/math/8/c/5/8c54cee1e2efe0cb95e1ee38726f38a9.png"> respectively.</p>
<h2>Properties</h2>
<p>The adjacency matrix of an undirected simple graph is symmetric, and therefore has a complete set of real eigenvalues and an orthogonal eigenvector basis. The set of eigenvalues of a graph is the <b>spectrum</b> of the graph.</p>
<p>Suppose two directed or undirected graphs <img class="mwe-math-fallback-image-inline tex" alt="G_1" src="//upload.wikimedia.org/math/6/6/8/668ec86dfe5be1ed6e29ff4743264698.png"> and <img class="mwe-math-fallback-image-inline tex" alt="G_2" src="//upload.wikimedia.org/math/2/1/d/21deb5c93cef58f00f9ba61cc69e997f.png"> with adjacency matrices <img class="mwe-math-fallback-image-inline tex" alt="A_1" src="//upload.wikimedia.org/math/e/2/8/e283f48f6f3d4077546b2b697c3eebad.png"> and <img class="mwe-math-fallback-image-inline tex" alt="A_2" src="//upload.wikimedia.org/math/1/7/b/17b99e166258f650036939b57689bdec.png"> are given. <img class="mwe-math-fallback-image-inline tex" alt="G_1" src="//upload.wikimedia.org/math/6/6/8/668ec86dfe5be1ed6e29ff4743264698.png"> and <img class="mwe-math-fallback-image-inline tex" alt="G_2" src="//upload.wikimedia.org/math/2/1/d/21deb5c93cef58f00f9ba61cc69e997f.png"> are isomorphic if and only if there exists a permutation matrix <img class="mwe-math-fallback-image-inline tex" alt="P" src="//upload.wikimedia.org/math/4/4/c/44c29edb103a2872f519ad0c9a0fdaaa.png"> such that</p>
<p>In particular, <img class="mwe-math-fallback-image-inline tex" alt="A_1" src="//upload.wikimedia.org/math/e/2/8/e283f48f6f3d4077546b2b697c3eebad.png"> and <img class="mwe-math-fallback-image-inline tex" alt="A_2" src="//upload.wikimedia.org/math/1/7/b/17b99e166258f650036939b57689bdec.png"> are similar and therefore have the same minimal polynomial, characteristic polynomial, eigenvalues, determinant and trace. These can therefore serve as isomorphism invariants of graphs. However, two graphs may possess the same set of eigenvalues but not be isomorphic. </p>
<p>If <i>A</i> is the adjacency matrix of the directed or undirected graph <i>G</i>, then the matrix <i>A</i> (i.e., the matrix product of <i>n</i> copies of <i>A</i>) has an interesting interpretation: the entry in row <i>i</i> and column <i>j</i> gives the number of (directed or undirected) walks of length <i>n</i> from vertex <i>i</i> to vertex <i>j</i>. This implies, for example, that the number of triangles in an undirected graph <i>G</i> is exactly the trace of <i>A</i> divided by 6.</p>
<p>The main diagonal of every adjacency matrix corresponding to a graph without loops has all zero entries. Note that here 'loops' means, for example A→A, not 'cycles' such as A→B→A.</p>
<p>For <img class="mwe-math-fallback-image-inline tex" alt="\left( d \right)" src="//upload.wikimedia.org/math/9/2/a/92a03bf0785093b952461146b82fcb8f.png"> -regular graphs, d is also an eigenvalue of A for the vector <img class="mwe-math-fallback-image-inline tex" alt="v=\left( 1,\dots,1 \right)" src="//upload.wikimedia.org/math/5/1/d/51d8502fdf75b3ca0cf052f18732ec42.png">, and <img class="mwe-math-fallback-image-inline tex" alt="G" src="//upload.wikimedia.org/math/d/f/c/dfcf28d0734569a6a693bc8194de62bf.png"> is connected if and only if the multiplicity of <img class="mwe-math-fallback-image-inline tex" alt="d" src="//upload.wikimedia.org/math/8/2/7/8277e0910d750195b448797616e091ad.png"> is 1. It can be shown that <img class="mwe-math-fallback-image-inline tex" alt="-d" src="//upload.wikimedia.org/math/9/b/0/9b017020b9d48d433ec90c548e6b5c70.png"> is also an eigenvalue of A if G is a connected bipartite graph. The above are results of Perron–Frobenius theorem.</p>
<h2>Variations</h2>
<p>An <b>(<i>a</i>, <i>b</i>, <i>c</i>)-adjacency matrix</b> <i>A</i> of a simple graph has <i>A</i><sub><i>ij</i></sub> = <i>a</i> if <i>ij</i> is an edge, <i>b</i> if it is not, and <i>c</i> on the diagonal. The Seidel adjacency matrix is a <b>(−1,1,0)-adjacency matrix</b>. This matrix is used in studying strongly regular graphs and two-graphs.</p>
<p>The <b>distance matrix</b> has in position (<i>i</i>,<i>j</i>) the distance between vertices <i>v<sub>i</sub></i> and <i>v<sub>j</sub></i> . The distance is the length of a shortest path connecting the vertices. Unless lengths of edges are explicitly provided, the length of a path is the number of edges in it. The distance matrix resembles a high power of the adjacency matrix, but instead of telling only whether or not two vertices are connected (i.e., the connection matrix, which contains boolean values), it gives the exact distance between them.</p>
<h2>Data structures</h2>
<p>For use as a data structure, the main alternative to the adjacency matrix is the adjacency list. Because each entry in the adjacency matrix requires only one bit, it can be represented in a very compact way, occupying only <img class="mwe-math-fallback-image-inline tex" alt="{n^2} / 8" src="//upload.wikimedia.org/math/d/b/a/dbad9dfd87df10d0daa418ef92f4e8ae.png"> bytes of contiguous space, where <img class="mwe-math-fallback-image-inline tex" alt="n" src="//upload.wikimedia.org/math/7/b/8/7b8b965ad4bca0e41ab51de7b31363a1.png"> is the number of vertices. Besides avoiding wasted space, this compactness encourages locality of reference.</p>
<p>However, for a sparse graph, adjacency lists require less storage space, because they do not waste any space to represent edges that are <i>not</i> present. Using a naïve array implementation on a 32-bit computer, an adjacency list for an undirected graph requires about <img class="mwe-math-fallback-image-inline tex" alt="8 e" src="//upload.wikimedia.org/math/4/3/5/435a5dc21578c61ddb60dcc68da74c15.png"> bytes of storage, where <img class="mwe-math-fallback-image-inline tex" alt="e" src="//upload.wikimedia.org/math/e/1/6/e1671797c52e15f763380b45e841ec32.png"> is the number of edges.</p>
<p>Noting that a simple graph can have at most <img class="mwe-math-fallback-image-inline tex" alt="n^2" src="//upload.wikimedia.org/math/b/0/8/b08b1c6ec09f20907eb1d6f1392c01c6.png"> edges, allowing loops, we can let <img class="mwe-math-fallback-image-inline tex" alt="d = e / n^2" src="//upload.wikimedia.org/math/0/5/f/05f02c3da5e355f6657911854f8a18f0.png"> denote the <i>density</i> of the graph. Then, <img class="mwe-math-fallback-image-inline tex" alt="8 e &gt; n^2 / 8" src="//upload.wikimedia.org/math/3/4/0/34003650d5967fd078b1d04abc3c0cd7.png">, or the adjacency list representation occupies more space precisely when <img class="mwe-math-fallback-image-inline tex" alt="d &gt; 1/64" src="//upload.wikimedia.org/math/c/2/9/c293ad8fc7a36ee9ee7f7c9e6031a087.png">. Thus a graph must be sparse indeed to justify an adjacency list representation.</p>
<p>Besides the space tradeoff, the different data structures also facilitate different operations. Finding all vertices adjacent to a given vertex in an adjacency list is as simple as reading the list. With an adjacency matrix, an entire row must instead be scanned, which takes <i>O(n)</i> time. Whether there is an edge between two given vertices can be determined at once with an adjacency matrix, while requiring time proportional to the minimum degree of the two vertices with the adjacency list.</p>
</body>
</html>