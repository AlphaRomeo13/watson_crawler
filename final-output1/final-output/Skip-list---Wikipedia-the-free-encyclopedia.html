<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Skip-list---Wikipedia-the-free-encyclopedia.html</title></head>
<body>
<h1>Skip list</h1>
<ul>
<li>Bloom filter</li>
<li>Quotient filter</li>
<li><strong class="selflink">Skip list</strong></li>
</ul>
<ul>
<li>Random binary tree</li>
<li>Treap</li>
<li>Rapidly exploring random tree</li>
</ul>
<ul>
<li>Randomized algorithm</li>
</ul>
<ul>
<li>v</li>
<li>t</li>
<li>e</li>
</ul>
<p>In computer science, a <b>skip list</b> is a data structure that allows fast search within an ordered sequence of elements. Fast search is made possible by maintaining a linked hierarchy of subsequences, each skipping over fewer elements. Searching starts in the sparsest subsequence until two consecutive elements have been found, one smaller and one larger than the element searched for. Via the linked hierarchy these two elements link to elements of the next sparsest subsequence where searching is continued until finally we are searching in the full sequence. The elements that are skipped over may be chosen probabilistically.</p>
<p></p>
<h2>Contents</h2>
<ul>
<li>1 Description
<ul>
<li>1.1 Implementation details</li>
<li>1.2 Indexable skiplist</li>
</ul>
</li>
<li>2 History</li>
<li>3 Usages</li>
<li>4 See also</li>
<li>5 References</li>
<li>6 External links
<ul>
<li>6.1 Demo applets</li>
<li>6.2 Implementations</li>
</ul>
</li>
</ul>
<ul>
<li>1.1 Implementation details</li>
<li>1.2 Indexable skiplist</li>
</ul>
<ul>
<li>6.1 Demo applets</li>
<li>6.2 Implementations</li>
</ul>
<p></p>
<h2>Description</h2>
<p>A skip list is built in layers. The bottom layer is an ordinary ordered linked list. Each higher layer acts as an "express lane" for the lists below, where an element in layer <i>i</i> appears in layer <i>i</i>+1 with some fixed probability <i>p</i> (two commonly used values for <i>p</i> are 1/2 or 1/4). On average, each element appears in 1/(1-<i>p</i>) lists, and the tallest element (usually a special head element at the front of the skip list) in <img class="mwe-math-fallback-image-inline tex" alt="\log_{1/p} n\," src="//upload.wikimedia.org/math/9/0/1/9011d0f26e1fbea18a19bd0d7356d8e2.png"> lists.</p>
<h1>Skip list</h1>
<ul>
<li>Bloom filter</li>
<li>Quotient filter</li>
<li><strong class="selflink">Skip list</strong></li>
</ul>
<ul>
<li>Random binary tree</li>
<li>Treap</li>
<li>Rapidly exploring random tree</li>
</ul>
<p>A search for a target element begins at the head element in the top list, and proceeds horizontally until the current element is greater than or equal to the target. If the current element is equal to the target, it has been found. If the current element is greater than the target, or the search reaches the end of the linked list, the procedure is repeated after returning to the previous element and dropping down vertically to the next lower list. The expected number of steps in each linked list is at most 1/<i>p</i>, which can be seen by tracing the search path backwards from the target until reaching an element that appears in the next higher list or reaching the beginning of the current list. Therefore, the total <i>expected</i> cost of a search is <img class="mwe-math-fallback-image-inline tex" alt="(\log_{1/p} n)/p,\," src="//upload.wikimedia.org/math/c/2/1/c215210fdc1c5b368ddfde3fd60a1c9a.png"> which is <img class="mwe-math-fallback-image-inline tex" alt="\mathcal{O}(\log n)\," src="//upload.wikimedia.org/math/8/f/a/8fa733795c7657acf067acf4993dbf46.png"> when <i>p</i> is a constant. By choosing different values of <i>p</i>, it is possible to trade search costs against storage costs.</p>
<h3>Implementation details</h3>
<p>The elements used for a skip list can contain more than one pointer since they can participate in more than one list.</p>
<p>Insertions and deletions are implemented much like the corresponding linked-list operations, except that "tall" elements must be inserted into or deleted from more than one linked list.</p>
<ul>
<li>Randomized algorithm</li>
</ul>
<ul>
<li>v</li>
<li>t</li>
<li>e</li>
</ul>
<p>In computer science, a <b>skip list</b> is a data structure that allows fast search within an ordered sequence of elements. Fast search is made possible by maintaining a linked hierarchy of subsequences, each skipping over fewer elements. Searching starts in the sparsest subsequence until two consecutive elements have been found, one smaller and one larger than the element searched for. Via the linked hierarchy these two elements link to elements of the next sparsest subsequence where searching is continued until finally we are searching in the full sequence. The elements that are skipped over may be chosen probabilistically.</p>
<p></p>
<h2>Contents</h2>
<ul>
<li>1 Description
<ul>
<li>1.1 Implementation details</li>
<li>1.2 Indexable skiplist</li>
</ul>
</li>
<li>2 History</li>
<li>3 Usages</li>
<li>4 See also</li>
<li>5 References</li>
<li>6 External links
<ul>
<li>6.1 Demo applets</li>
<li>6.2 Implementations</li>
</ul>
</li>
</ul>
<ul>
<li>1.1 Implementation details</li>
<li>1.2 Indexable skiplist</li>
</ul>
<ul>
<li>6.1 Demo applets</li>
<li>6.2 Implementations</li>
</ul>
<p></p>
<p><img class="mwe-math-fallback-image-inline tex" alt="\mathcal{O}(n)" src="//upload.wikimedia.org/math/c/f/3/cf373ba944d0faa2f0ee7d828d18f610.png"> operations, which force us to visit every node in ascending order (such as printing the entire list), provide the opportunity to perform a behind-the-scenes derandomization of the level structure of the skip-list in an optimal way, bringing the skip list to <img class="mwe-math-fallback-image-inline tex" alt="\mathcal{O}(\log n)" src="//upload.wikimedia.org/math/6/a/2/6a2e1009f7e6194825cc7c80ed2528e4.png"> search time. (Choose the level of the i'th finite node to be 1 plus the number of times we can repeatedly divide i by 2 before it becomes odd. Also, i=0 for the negative infinity header as we have the usual special case of choosing the highest possible level for negative and/or positive infinite nodes.) However this also allows someone to know where all of the higher-than-level 1 nodes are and delete them.</p>
<p>Alternatively, we could make the level structure quasi-random in the following way:</p>
<p>WHATSON? 329600d2-e08b-48a2-9c53-d2ab03844dc2</p>
<pre>
make all nodes level 1
j ← 1
<b>while</b> the number of nodes at level j &gt; 1 <b>do</b>
  <b>for</b> each i'th node at level j <b>do</b>
    <b>if</b> i is odd 
      <b>if</b> i is not the last node at level j
        randomly choose whether to promote it to level j+1
      <b>else</b>
        do not promote
      <b>end if</b>
    <b>else if</b> i is even and node i-1 was not promoted
      promote it to level j+1
    <b>end if</b>
  <b>repeat</b>
  j ← j + 1
<b>repeat</b>
</pre>
<p>Like the derandomized version, quasi-randomization is only done when there is some other reason to be running a <img class="mwe-math-fallback-image-inline tex" alt="\mathcal{O}(n)" src="//upload.wikimedia.org/math/c/f/3/cf373ba944d0faa2f0ee7d828d18f610.png"> operation (which visits every node).</p>
<p>The advantage of this quasi-randomness is that it doesn't give away nearly as much level-structure related information to an adversarial user as the de-randomized one. This is desirable because an adversarial user who is able to tell which nodes are not at the lowest level can pessimize performance by simply deleting higher-level nodes. The search performance is still guaranteed to be logarithmic.</p>
<p>It would be tempting to make the following "optimization": In the part which says "Next, for each i'th...", forget about doing a coin-flip for each even-odd pair. Just flip a coin once to decide whether to promote only the even ones or only the odd ones. Instead of <img class="mwe-math-fallback-image-inline tex" alt="\mathcal{O}(n \log n)" src="//upload.wikimedia.org/math/b/0/9/b0962191c77ed92b45b105d6dee72dd4.png"> coin flips, there would only be <img class="mwe-math-fallback-image-inline tex" alt="\mathcal{O}(\log n)" src="//upload.wikimedia.org/math/6/a/2/6a2e1009f7e6194825cc7c80ed2528e4.png"> of them. Unfortunately, this gives the adversarial user a 50/50 chance of being correct upon guessing that all of the even numbered nodes (among the ones at level 1 or higher) are higher than level one. This is despite the property that he has a very low probability of guessing that a particular node is at level <i>N</i> for some integer <i>N</i>.</p>
<p>A skip list does not provide the same absolute worst-case performance guarantees as more traditional balanced tree data structures, because it is always possible (though with very low probability) that the coin-flips used to build the skip list will produce a badly balanced structure. However, they work well in practice, and the randomized balancing scheme has been argued to be easier to implement than the deterministic balancing schemes used in balanced binary search trees. Skip lists are also useful in parallel computing, where insertions can be done in different parts of the skip list in parallel without any global rebalancing of the data structure. Such parallelism can be especially advantageous for resource discovery in an ad-hoc wireless network because a randomized skip list can be made robust to the loss of any single node.</p>
<p>There has been some evidence that skip lists have worse real-world performance and space requirements than B trees due to memory locality and other issues.</p>
<h3>Indexable skiplist</h3>
<p>As described above, a skiplist is capable of fast <img class="mwe-math-fallback-image-inline tex" alt="\mathcal{O}(\log n)" src="//upload.wikimedia.org/math/6/a/2/6a2e1009f7e6194825cc7c80ed2528e4.png"> insertion and removal of values from a sorted sequence, but it has only slow <img class="mwe-math-fallback-image-inline tex" alt="\mathcal{O}(n)" src="//upload.wikimedia.org/math/c/f/3/cf373ba944d0faa2f0ee7d828d18f610.png"> lookups of values at a given position in the sequence (i.e. return the 500th value); however, with a minor modification the speed of random access indexed lookups can be improved to <img class="mwe-math-fallback-image-inline tex" alt="\mathcal{O}(\log n)" src="//upload.wikimedia.org/math/6/a/2/6a2e1009f7e6194825cc7c80ed2528e4.png">.</p>
<p>For every link, also store the width of the link. The width is defined as the number of bottom layer links being traversed by each of the higher layer "express lane" links.</p>
<h2>Description</h2>
<p>A skip list is built in layers. The bottom layer is an ordinary ordered linked list. Each higher layer acts as an "express lane" for the lists below, where an element in layer <i>i</i> appears in layer <i>i</i>+1 with some fixed probability <i>p</i> (two commonly used values for <i>p</i> are 1/2 or 1/4). On average, each element appears in 1/(1-<i>p</i>) lists, and the tallest element (usually a special head element at the front of the skip list) in <img class="mwe-math-fallback-image-inline tex" alt="\log_{1/p} n\," src="//upload.wikimedia.org/math/9/0/1/9011d0f26e1fbea18a19bd0d7356d8e2.png"> lists.</p>
<p>A search for a target element begins at the head element in the top list, and proceeds horizontally until the current element is greater than or equal to the target. If the current element is equal to the target, it has been found. If the current element is greater than the target, or the search reaches the end of the linked list, the procedure is repeated after returning to the previous element and dropping down vertically to the next lower list. The expected number of steps in each linked list is at most 1/<i>p</i>, which can be seen by tracing the search path backwards from the target until reaching an element that appears in the next higher list or reaching the beginning of the current list. Therefore, the total <i>expected</i> cost of a search is <img class="mwe-math-fallback-image-inline tex" alt="(\log_{1/p} n)/p,\," src="//upload.wikimedia.org/math/c/2/1/c215210fdc1c5b368ddfde3fd60a1c9a.png"> which is <img class="mwe-math-fallback-image-inline tex" alt="\mathcal{O}(\log n)\," src="//upload.wikimedia.org/math/8/f/a/8fa733795c7657acf067acf4993dbf46.png"> when <i>p</i> is a constant. By choosing different values of <i>p</i>, it is possible to trade search costs against storage costs.</p>
<h3>Implementation details</h3>
<p>The elements used for a skip list can contain more than one pointer since they can participate in more than one list.</p>
<p>Insertions and deletions are implemented much like the corresponding linked-list operations, except that "tall" elements must be inserted into or deleted from more than one linked list.</p>
<p><img class="mwe-math-fallback-image-inline tex" alt="\mathcal{O}(n)" src="//upload.wikimedia.org/math/c/f/3/cf373ba944d0faa2f0ee7d828d18f610.png"> operations, which force us to visit every node in ascending order (such as printing the entire list), provide the opportunity to perform a behind-the-scenes derandomization of the level structure of the skip-list in an optimal way, bringing the skip list to <img class="mwe-math-fallback-image-inline tex" alt="\mathcal{O}(\log n)" src="//upload.wikimedia.org/math/6/a/2/6a2e1009f7e6194825cc7c80ed2528e4.png"> search time. (Choose the level of the i'th finite node to be 1 plus the number of times we can repeatedly divide i by 2 before it becomes odd. Also, i=0 for the negative infinity header as we have the usual special case of choosing the highest possible level for negative and/or positive infinite nodes.) However this also allows someone to know where all of the higher-than-level 1 nodes are and delete them.</p>
<p>Alternatively, we could make the level structure quasi-random in the following way:</p>
<p>WHATSON? 2c4eece1-228e-4f65-aad7-595ea5fe9ea8</p>
<pre>
make all nodes level 1
j ← 1
<b>while</b> the number of nodes at level j &gt; 1 <b>do</b>
  <b>for</b> each i'th node at level j <b>do</b>
    <b>if</b> i is odd 
      <b>if</b> i is not the last node at level j
        randomly choose whether to promote it to level j+1
      <b>else</b>
        do not promote
      <b>end if</b>
    <b>else if</b> i is even and node i-1 was not promoted
      promote it to level j+1
    <b>end if</b>
  <b>repeat</b>
  j ← j + 1
<b>repeat</b>
</pre>
<p>Like the derandomized version, quasi-randomization is only done when there is some other reason to be running a <img class="mwe-math-fallback-image-inline tex" alt="\mathcal{O}(n)" src="//upload.wikimedia.org/math/c/f/3/cf373ba944d0faa2f0ee7d828d18f610.png"> operation (which visits every node).</p>
<p>The advantage of this quasi-randomness is that it doesn't give away nearly as much level-structure related information to an adversarial user as the de-randomized one. This is desirable because an adversarial user who is able to tell which nodes are not at the lowest level can pessimize performance by simply deleting higher-level nodes. The search performance is still guaranteed to be logarithmic.</p>
<p>It would be tempting to make the following "optimization": In the part which says "Next, for each i'th...", forget about doing a coin-flip for each even-odd pair. Just flip a coin once to decide whether to promote only the even ones or only the odd ones. Instead of <img class="mwe-math-fallback-image-inline tex" alt="\mathcal{O}(n \log n)" src="//upload.wikimedia.org/math/b/0/9/b0962191c77ed92b45b105d6dee72dd4.png"> coin flips, there would only be <img class="mwe-math-fallback-image-inline tex" alt="\mathcal{O}(\log n)" src="//upload.wikimedia.org/math/6/a/2/6a2e1009f7e6194825cc7c80ed2528e4.png"> of them. Unfortunately, this gives the adversarial user a 50/50 chance of being correct upon guessing that all of the even numbered nodes (among the ones at level 1 or higher) are higher than level one. This is despite the property that he has a very low probability of guessing that a particular node is at level <i>N</i> for some integer <i>N</i>.</p>
<p>A skip list does not provide the same absolute worst-case performance guarantees as more traditional balanced tree data structures, because it is always possible (though with very low probability) that the coin-flips used to build the skip list will produce a badly balanced structure. However, they work well in practice, and the randomized balancing scheme has been argued to be easier to implement than the deterministic balancing schemes used in balanced binary search trees. Skip lists are also useful in parallel computing, where insertions can be done in different parts of the skip list in parallel without any global rebalancing of the data structure. Such parallelism can be especially advantageous for resource discovery in an ad-hoc wireless network because a randomized skip list can be made robust to the loss of any single node.</p>
<p>There has been some evidence that skip lists have worse real-world performance and space requirements than B trees due to memory locality and other issues.</p>
<h3>Indexable skiplist</h3>
<p>As described above, a skiplist is capable of fast <img class="mwe-math-fallback-image-inline tex" alt="\mathcal{O}(\log n)" src="//upload.wikimedia.org/math/6/a/2/6a2e1009f7e6194825cc7c80ed2528e4.png"> insertion and removal of values from a sorted sequence, but it has only slow <img class="mwe-math-fallback-image-inline tex" alt="\mathcal{O}(n)" src="//upload.wikimedia.org/math/c/f/3/cf373ba944d0faa2f0ee7d828d18f610.png"> lookups of values at a given position in the sequence (i.e. return the 500th value); however, with a minor modification the speed of random access indexed lookups can be improved to <img class="mwe-math-fallback-image-inline tex" alt="\mathcal{O}(\log n)" src="//upload.wikimedia.org/math/6/a/2/6a2e1009f7e6194825cc7c80ed2528e4.png">.</p>
<p>For every link, also store the width of the link. The width is defined as the number of bottom layer links being traversed by each of the higher layer "express lane" links.</p>
<p>For example, here are the widths of the links in the example at the top of the page:</p>
<p>For example, here are the widths of the links in the example at the top of the page:</p>
<p>WHATSON? 25439dc5-1d44-49b4-9349-9a598375348c</p>
<pre>
   1                               10
 o---&gt; o---------------------------------------------------------&gt; o    Top level
   1           3              2                    5
 o---&gt; o---------------&gt; o---------&gt; o---------------------------&gt; o    Level 3
   1        2        1        2                    5
 o---&gt; o---------&gt; o---&gt; o---------&gt; o---------------------------&gt; o    Level 2
   1     1     1     1     1     1     1     1     1     1     1 
 o---&gt; o---&gt; o---&gt; o---&gt; o---&gt; o---&gt; o---&gt; o---&gt; o---&gt; o---&gt; o---&gt; o    Bottom level
                                        <b> </b>
Head  1st   2nd   3rd   4th   5th   6th   7th   8th   9th   10th  NIL
      Node  Node  Node  Node  Node  Node  Node  Node  Node  Node
</pre>
<p>Notice that the width of a higher level link is the sum of the component links below it (i.e. the width 10 link spans the links of widths 3, 2 and 5 immediately below it). Consequently, the sum of all widths is the same on every level (10 + 1 = 1 + 3 + 2 + 5 = 1 + 2 + 1 + 2 + 5).</p>
<p>To index the skiplist and find the i'th value, traverse the skiplist while counting down the widths of each traversed link. Descend a level whenever the upcoming width would be too large.</p>
<p>For example, to find the node in the fifth position (Node 5), traverse a link of width 1 at the top level. Now four more steps are needed but the next width on this level is ten which is too large, so drop one level. Traverse one link of width 3. Since another step of width 2 would be too far, drop down to the bottom level. Now traverse the final link of width 1 to reach the target running total of 5 (1+3+1).</p>
<p>WHATSON? 55a75015-eb91-4c2d-9cae-601fb0ac575c</p>
<pre>
 <b>function</b> lookupByPositionIndex(i)
     node ← head
     i ← i + 1                           <i># don't count the head as a step</i>
     <b>for</b> level <b>from</b> top <b>to</b> bottom <b>do</b>
          <b>while</b> i ≥ node.width[level] <b>do</b> <i># if next step is not too far</i>
              i ← i - node.width[level]  <i># subtract the current width</i>
              node ← node.next[level]    <i># traverse forward at the current level</i>
          <b>repeat</b>
     <b>repeat</b>
     <b>return</b> node.value
 <b>end function</b>
</pre>
<p>This method of implementing indexing is detailed in Section 3.4 Linear List Operations in "A skip list cookbook" by William Pugh.</p>
<h2>History</h2>
<p>Skip lists were first described in 1989 by William Pugh.</p>
<p>To quote the author:</p>
<h2>Usages</h2>
<p>List of applications and frameworks that use skip lists:</p>
<ul>
<li>Cyrus IMAP server offers a "skiplist" backend DB implementation (source file)</li>
<li>Lucene uses skip lists to search delta-encoded posting lists in logarithmic time.</li>
<li>QMap (up to Qt 4) template class of Qt that provides a dictionary.</li>
<li>Redis, an ANSI-C open-source persistent key/value store for Posix systems, uses skip lists in its implementation of ordered sets.</li>
<li>nessDB, a very fast key-value embedded Database Storage Engine (Using log-structured-merge (LSM) trees), uses skip lists for its memtable.</li>
<li>skipdb is an open-source database format using ordered key/value pairs.</li>
<li>ConcurrentSkipListSet and ConcurrentSkipListMap in the Java 1.6 API.</li>
<li>leveldb, a fast key-value storage library written at Google that provides an ordered mapping from string keys to string values</li>
<li>Skip lists are used for efficient statistical computations of running medians (also known as moving medians).</li>
</ul>
<p>Skip lists are also used in distributed applications (where the nodes represent physical computers, and pointers represent network connections) and for implementing highly scalable concurrent priority queues with less lock contention, or even without locking, as well as lockless concurrent dictionaries. There are also several US patents for using skip lists to implement (lockless) priority queues and concurrent dictionaries.[1]</p>
<h2>See also</h2>
<ul>
<li>Bloom filter</li>
<li>Skip graph</li>
</ul>
</body>
</html>