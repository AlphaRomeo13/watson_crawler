<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Gray-code---Wikipedia-the-free-encyclopedia.html</title></head>
<body>
<h1>Gray code</h1>
<p>The <b>reflected binary code</b>, also known as <b>Gray code</b> after Frank Gray, is a binary numeral system where two successive values differ in only one bit (binary digit). The reflected binary code was originally designed to prevent spurious output from electromechanical switches. Today, Gray codes are widely used to facilitate error correction in digital communications such as digital terrestrial television and some cable TV systems.</p>
<p></p>
<h2>Contents</h2>
<ul>
<li>1 Name</li>
<li>2 Motivation</li>
<li>3 History and practical application
<ul>
<li>3.1 Position encoders</li>
<li>3.2 Towers of Hanoi</li>
<li>3.3 Genetic algorithms</li>
<li>3.4 Karnaugh maps</li>
<li>3.5 Error correction</li>
<li>3.6 Communication between clock domains
<ul>
<li>3.6.1 Gray code counters and arithmetic</li>
</ul>
</li>
</ul>
</li>
<li>4 Constructing an <i>n</i>-bit Gray code</li>
<li>5 Converting to and from Gray code</li>
<li>6 Special types of Gray codes
<ul>
<li>6.1 <i>n</i>-ary Gray code</li>
<li>6.2 Balanced Gray code</li>
<li>6.3 Monotonic Gray codes</li>
<li>6.4 Beckett–Gray code</li>
<li>6.5 Snake-in-the-box codes</li>
<li>6.6 Single-track Gray code</li>
</ul>
</li>
<li>7 See also</li>
<li>8 Notes</li>
<li>9 References</li>
<li>10 External links</li>
</ul>
<ul>
<li>3.1 Position encoders</li>
<li>3.2 Towers of Hanoi</li>
<li>3.3 Genetic algorithms</li>
<li>3.4 Karnaugh maps</li>
<li>3.5 Error correction</li>
<li>3.6 Communication between clock domains
<ul>
<li>3.6.1 Gray code counters and arithmetic</li>
</ul>
</li>
</ul>
<ul>
<li>3.6.1 Gray code counters and arithmetic</li>
</ul>
<ul>
<li>6.1 <i>n</i>-ary Gray code</li>
<li>6.2 Balanced Gray code</li>
<li>6.3 Monotonic Gray codes</li>
<li>6.4 Beckett–Gray code</li>
<li>6.5 Snake-in-the-box codes</li>
<li>6.6 Single-track Gray code</li>
</ul>
<p></p>
<h2>Name</h2>
<p>Bell Labs researcher Frank Gray introduced the term <i>reflected binary code</i> in his 1947 patent application, remarking that the code had "as yet no recognized name". He derived the name from the fact that it "may be built up from the conventional binary code by a sort of reflection process".</p>
<p>The code was later named after Gray by others who used it. Two different 1953 patent applications use "Gray code" as an alternative name for the "reflected binary code"; one of those also lists "minimum error code" and "cyclic permutation code" among the names. A 1954 patent application refers to "the Bell Telephone Gray code".</p>
<h2>Motivation</h2>
<p>Many devices indicate position by closing and opening switches. If that device uses natural binary codes, these two positions would be right next to each other:</p>
<p>WHATSON? adc16588-df12-405f-9493-715b3884a7fd</p>
<pre>
...
011
100
...
</pre>
<p>The problem with natural binary codes is that, with physical, mechanical switches, it is very unlikely that switches will change states exactly in synchrony. In the transition between the two states shown above, all three switches change state. In the brief period while all are changing, the switches will read some spurious position. Even without keybounce, the transition might look like 011 — 001 — 101 — 100. When the switches appear to be in position 001, the observer cannot tell if that is the "real" position 001, or a transitional state between two other positions. If the output feeds into a sequential system, possibly via combinational logic, then the sequential system may store a false value.</p>
<p>The reflected binary code solves this problem by changing only one switch at a time, so there is never any ambiguity of position,</p>
<p>WHATSON? f0007478-8c9e-494b-b0f2-539f4c4e0aff</p>
<pre>
Dec  Gray   Binary
 0   000    000
 1   001    001
 2   011    010
 3   010    011
 4   110    100
 5   111    101
 6   101    110
 7   100    111
</pre>
<p>Notice that state 7 can roll over to state 0 with only one switch change. This is called the "cyclic" property of a Gray code. In the standard Gray coding the least significant bit follows a repetitive pattern of 2 on, 2 off ( … 11001100 … ); the next digit a pattern of 4 on, 4 off; and so forth.</p>
<p>More formally, a <b>Gray code</b> is a code assigning to each of a contiguous set of integers, or to each member of a circular list, a word of symbols such that each two adjacent code words differ by one symbol. These codes are also known as <i>single-distance codes</i>, reflecting the Hamming distance of 1 between adjacent codes. There can be more than one Gray code for a given word length, but the term was first applied to a particular binary code for the non-negative integers, the <i>binary-reflected Gray code</i>, or <b>BRGC</b>, the three-bit version of which is shown above.</p>
<h2>History and practical application</h2>
<p>Reflected binary codes were applied to mathematical puzzles before they became known to engineers. The French engineer Émile Baudot used Gray codes in telegraphy in 1878. He received the French Legion of Honor medal for his work. The Gray code is sometimes attributed, incorrectly, to Elisha Gray (in <i>Principles of Pulse Code Modulation</i>, K. W. Cattermole, for example).</p>
<p>Frank Gray, who became famous for inventing the signaling method that came to be used for compatible color television, invented a method to convert analog signals to reflected binary code groups using vacuum tube-based apparatus. The method and apparatus were patented in 1953 and the name of Gray stuck to the codes. The "PCM tube" apparatus that Gray patented was made by Raymond W. Sears of Bell Labs, working with Gray and William M. Goodall, who credited Gray for the idea of the reflected binary code.</p>
<p>The use of his eponymous codes that Gray was most interested in was to minimize the effect of error in the conversion of analog signals to digital; his codes are still used today for this purpose, and others.</p>
<h3>Position encoders</h3>
<p>Gray codes are used in position encoders (linear encoders and rotary encoders), in preference to straightforward binary encoding. This avoids the possibility that, when several bits change in the binary representation of an angle, a misread will result from some of the bits changing before others. Originally, the code pattern was electrically conductive, supported (in a rotary encoder) by an insulating disk. Each track had its own stationary metal spring contact; one more contact made the connection to the pattern. That common contact was connected by the pattern to whichever of the track contacts were resting on the conductive pattern. However, sliding contacts wear out and need maintenance, which favors optical encoders.</p>
<p>Regardless of the care in aligning the contacts, and accuracy of the pattern, a natural-binary code would have errors at specific disk positions, because it is impossible to make all bits change at exactly the same time as the disk rotates. The same is true of an optical encoder; transitions between opaque and transparent cannot be made to happen simultaneously for certain exact positions. Rotary encoders benefit from the cyclic nature of Gray codes, because consecutive positions of the sequence differ by only one bit. This means that, for a transition from state A to state B, timing mismatches can only affect when the A→B transition occurs, rather than inserting one or more (up to N-1 for an N-bit codeword) false intermediate states, as would occur if a standard binary code were used.</p>
<h3>Towers of Hanoi</h3>
<p>The binary-reflected Gray code can also be used to serve as a solution guide for the Towers of Hanoi problem, as well as the classical Chinese rings puzzle, a sequential mechanical puzzle mechanism. It also forms a Hamiltonian cycle on a hypercube, where each bit is seen as one dimension.</p>
<h3>Genetic algorithms</h3>
<p>Due to the Hamming distance properties of Gray codes, they are sometimes used in genetic algorithms. They are very useful in this field, since mutations in the code allow for mostly incremental changes, but occasionally a single bit-change can cause a big leap and lead to new properties.</p>
<h3>Karnaugh maps</h3>
<p>Gray codes are also used in labelling the axes of Karnaugh maps.</p>
<h3>Error correction</h3>
<p>In modern digital communications, Gray codes play an important role in error correction. For example, in a digital modulation scheme such as QAM where data is typically transmitted in symbols of 4 bits or more, the signal's constellation diagram is arranged so that the bit patterns conveyed by adjacent constellation points differ by only one bit. By combining this with forward error correction capable of correcting single-bit errors, it is possible for a receiver to correct any transmission errors that cause a constellation point to deviate into the area of an adjacent point. This makes the transmission system less susceptible to noise.</p>
<h3>Communication between clock domains</h3>
<p>Digital logic designers use Gray codes extensively for passing multi-bit count information between synchronous logic that operates at different clock frequencies. The logic is considered operating in different "clock domains". It is fundamental to the design of large chips that operate with many different clocking frequencies.</p>
<h4>Gray code counters and arithmetic</h4>
<p>A typical use of Gray code counters is building a FIFO (first-in, first-out) data buffer that has read and write ports that exist in different clock domains. The input and output counters inside such a dual-port FIFO are often stored using Gray code to prevent invalid transient states from being captured when the count crosses clock domains. The updated read and write pointers need to be passed between clock domains when they change, to be able to track FIFO empty and full status in each domain. Each bit of the pointers is sampled non-deterministically for this clock domain transfer. So for each bit, either the old value or the new value is propagated. Therefore, if more than one bit in the multi-bit pointer is changing at the sampling point, a "wrong" binary value (neither new nor old) can be propagated. By guaranteeing only one bit can be changing, Gray codes guarantee that the only possible sampled values are the new or old multi-bit value. Typically Gray codes of power-of-two length are used.</p>
<p>Sometimes digital buses in electronic systems are used to convey quantities that can only increase or decrease by one at a time, for example the output of an event counter which is being passed between clock domains or to a digital-to-analog converter. The advantage of Gray codes in these applications is that differences in the propagation delays of the many wires that represent the bits of the code cannot cause the received value to go through states that are out of the Gray code sequence. This is similar to the advantage of Gray codes in the construction of mechanical encoders, however the source of the Gray code is an electronic counter in this case. The counter itself must count in Gray code, or if the counter runs in binary then the output value from the counter must be reclocked after it has been converted to Gray code, because when a value is converted from binary to Gray code, it is possible that differences in the arrival times of the binary data bits into the binary-to-Gray conversion circuit will mean that the code could go briefly through states that are wildly out of sequence. Adding a clocked register after the circuit that converts the count value to Gray code may introduce a clock cycle of latency, so counting directly in Gray code may be advantageous. A Gray code counter was patented in 1962 US3020481, and there have been many others since. In recent times a Gray code counter can be implemented as a state machine in Verilog. In order to produce the next count value, it is necessary to have some combinational logic that will increment the current count value that is stored in Gray code. Probably the most obvious way to increment a Gray code number is to convert it into ordinary binary code, add one to it with a standard binary adder, and then convert the result back to Gray code. This approach was discussed in a paper in 1996  and then subsequently patented by someone else in 1998 US5754614. Other methods of counting in Gray code are discussed in a report by R. W. Doran, including taking the output from the first latches of the master-slave flip flops in a binary ripple counter.</p>
<p>Perhaps the most common electronic counter with the "only one bit changes at a time" property is the Johnson counter.</p>
<h2>Constructing an <i>n</i>-bit Gray code</h2>
<p>The binary-reflected Gray code list for <i>n</i> bits can be generated recursively from the list for <i>n−1</i> bits by reflecting the list (i.e. listing the entries in reverse order), concatenating the original list with the reversed list, prefixing the entries in the original list with a binary 0, and then prefixing the entries in the reflected list with a binary 1. For example, generating the <i>n</i> = 3 list from the <i>n</i> = 2 list:</p>
<p>The one-bit Gray code is <i>G</i><sub>1</sub> = (0, 1). This can be thought of as built recursively as above from a zero-bit Gray code <i>G</i><sub>0</sub> = { Λ } consisting of a single entry of zero length. This iterative process of generating <i>G</i><sub><i>n</i>+1</sub> from <i>G</i><sub><i>n</i></sub> makes the following properties of the standard reflecting code clear:</p>
<ul>
<li><i>G</i><sub><i>n</i></sub> is a permutation of the numbers 0, ..., 2−1. (Each number appears exactly once in the list.)</li>
<li><i>G</i><sub><i>n</i></sub> is embedded as the first half of <i>G</i><sub><i>n</i>+1</sub>.</li>
<li>Therefore the coding is <i>stable</i>, in the sense that once a binary number appears in <i>G</i><sub><i>n</i></sub> it appears in the same position in all longer lists; so it makes sense to talk about <i>the</i> reflective Gray code value of a number: <i>G</i>(<i>m</i>) = the <i>m</i>-th reflecting Gray code, counting from 0.</li>
<li>Each entry in <i>G</i><sub><i>n</i></sub> differs by only one bit from the previous entry. (The Hamming distance is 1.)</li>
<li>The last entry in <i>G</i><sub><i>n</i></sub> differs by only one bit from the first entry. (The code is cyclic.)</li>
</ul>
<p>These characteristics suggest a simple and fast method of translating a binary value into the corresponding Gray code. Each bit is inverted if the next higher bit of the input value is set to one. This can be performed in parallel by a bit-shift and exclusive-or operation if they are available: the <i>n</i>th Gray code is obtained by computing <img class="mwe-math-fallback-image-inline tex" alt="n \oplus \lfloor n/2 \rfloor" src="//upload.wikimedia.org/math/e/2/b/e2b8c02b3f5fb21e805d8bbc4345a608.png"></p>
<p>A similar method can be used to perform the reverse translation, but the computation of each bit depends on the computed value of the next higher bit so it cannot be performed in parallel. Assuming <img class="mwe-math-fallback-image-inline tex" alt="g_i" src="//upload.wikimedia.org/math/8/a/0/8a063395ded15845176d0b1e07824cbf.png"> is the <img class="mwe-math-fallback-image-inline tex" alt="i" src="//upload.wikimedia.org/math/8/6/5/865c0c0b4ab0e063e5caa3387c1a8741.png">th gray-coded bit (<img class="mwe-math-fallback-image-inline tex" alt="g_0" src="//upload.wikimedia.org/math/9/b/0/9b0d20d96b222c9a2e2215029fa6e93b.png"> being the most significant bit), and <img class="mwe-math-fallback-image-inline tex" alt="b_i" src="//upload.wikimedia.org/math/c/9/f/c9f6d8557ce40f989fa727b5c0bb1ddf.png"> is the <img class="mwe-math-fallback-image-inline tex" alt="i" src="//upload.wikimedia.org/math/8/6/5/865c0c0b4ab0e063e5caa3387c1a8741.png">th binary-coded bit (<img class="mwe-math-fallback-image-inline tex" alt="b_0" src="//upload.wikimedia.org/math/3/e/5/3e5dc8a9e58fac43ec3377c25606be6b.png"> being the most-significant bit), the reverse translation can be given recursively: <img class="mwe-math-fallback-image-inline tex" alt="b_0 = g_0" src="//upload.wikimedia.org/math/5/7/7/577c3ed0ed8d4d200c4c79d1f8ac2a17.png">, and <img class="mwe-math-fallback-image-inline tex" alt="b_i=g_i \oplus b_{i-1}" src="//upload.wikimedia.org/math/9/3/7/937366293b4d71f7965349e82ef212ec.png">. Alternatively, decoding a Gray code into a binary number can be described as a prefix sum of the bits in the Gray code, where each individual summation operation in the prefix sum is performed modulo two.</p>
<p>To construct the binary-reflected Gray code iteratively, at step 0 start with the <img class="mwe-math-fallback-image-inline tex" alt="code_0 = 0" src="//upload.wikimedia.org/math/5/4/8/548392df224146b93eb49e1471fede07.png">, and at step <img class="mwe-math-fallback-image-inline tex" alt="i &gt; 0" src="//upload.wikimedia.org/math/5/6/3/563d880e1c878d80bb57b029b4c56166.png"> find the bit position of the least significant 1 in the binary representation of <img class="mwe-math-fallback-image-inline tex" alt="i" src="//upload.wikimedia.org/math/8/6/5/865c0c0b4ab0e063e5caa3387c1a8741.png"> and flip the bit at that position in the previous code <img class="mwe-math-fallback-image-inline tex" alt="code_{i-1}" src="//upload.wikimedia.org/math/9/4/f/94f48a4de17a70318be514d3cbf003fd.png"> to get the next code <img class="mwe-math-fallback-image-inline tex" alt="code_i" src="//upload.wikimedia.org/math/b/1/0/b1085f2c198a8b46764f20449121b527.png">. The bit positions start 0, 1, 0, 2, 0, 1, 0, 3, ... (sequence A007814 in OEIS). See find first set for efficient algorithms to compute these values.</p>
<h2>Converting to and from Gray code</h2>
<p>The following functions in C convert between binary numbers and their associated Gray codes. While it may seem that gray-to-binary conversion requires each bit to be handled one at a time, faster algorithms exist.</p>
<p>WHATSON? d0e62e1b-b839-4791-b098-0e0984305662</p>
<pre>
/*
        The purpose of this function is to convert an unsigned
        binary number to reflected binary Gray code.
 
        The operator &gt;&gt; is shift right. The operator ^ is exclusive or.
*/
unsigned int binaryToGray(unsigned int num)
{
        return (num &gt;&gt; 1) ^ num;
}
 
/*
        The purpose of this function is to convert a reflected binary
        Gray code number to a binary number.
*/
unsigned int grayToBinary(unsigned int num)
{
    unsigned int mask;
    for (mask = num &gt;&gt; 1; mask != 0; mask = mask &gt;&gt; 1)
    {
        num = num ^ mask;
    }
    return num;
}
</pre>
<h2>Special types of Gray codes</h2>
<p>In practice, a "Gray code" almost always refers to a binary-reflected Gray code (BRGC). However, mathematicians have discovered other kinds of Gray codes. Like BRGCs, each consists of a lists of words, where each word differs from the next in only one digit (each word has a Hamming distance of 1 from the next word).</p>
<h3><i>n</i>-ary Gray code</h3>
<p>WHATSON? d9980541-d9d1-45d3-a517-ee0c3fcf145f</p>
<pre>
  0 → 000
  1 → 001
  2 → 002
 10 → 012
 11 → 010
 12 → 011
 20 → 021
 21 → 022
 22 → 020
100 → 120
101 → 121
102 → 122
110 → 102
111 → 100
112 → 101
120 → 111
121 → 112
122 → 110
200 → 210
201 → 211
202 → 212
210 → 222
211 → 220
212 → 221
220 → 201
221 → 202
222 → 200
</pre>
<p>There are many specialized types of Gray codes other than the binary-reflected Gray code. One such type of Gray code is the <b><i>n</i>-ary Gray code</b>, also known as a <b>non-Boolean Gray code</b>. As the name implies, this type of Gray code uses non-Boolean values in its encodings.</p>
<p>For example, a 3-ary (ternary) Gray code would use the values {0, 1, 2}. The (<i>n</i>, <i>k</i>)-<i>Gray code</i> is the <i>n</i>-ary Gray code with <i>k</i> digits. The sequence of elements in the (3, 2)-Gray code is: {00, 01, 02, 12, 10, 11, 21, 22, 20}. The (<i>n</i>, <i>k</i>)-Gray code may be constructed recursively, as the BRGC, or may be constructed iteratively. An algorithm to iteratively generate the (<i>N</i>, <i>k</i>)-Gray code is presented (in C):</p>
<p>There are other graycode algorithms for <i>(n,k)</i>-Gray codes. It is important to note that the <i>(n,k)</i>-Gray codes produced by the above algorithm is always cyclical; some algorithms, such as that by Guan, lack this property when k is odd. On the other hand, while only one digit at a time changes with this method, it can change by wrapping (looping from n-1 to 0). In Guan's algorithm, the count alternately rises and falls, so that the numeric difference between two graycode digits is always one.</p>
<p>Gray codes are not uniquely defined, because a permutation of the columns of such a code is a Gray code too. The above procedure produces a code in which the lower the significance of a digit, the more often it changes, making it similar to normal counting methods.</p>
<h3>Balanced Gray code</h3>
<p>Although the binary reflected Gray code is useful in many scenarios, it is not optimal in certain cases because of a lack of "uniformity". In <b>balanced Gray codes</b>, the number of changes in different coordinate positions are as close as possible. To make this more precise, let <i>G</i> be an <i>R</i>-ary complete Gray cycle having transition sequence <img class="mwe-math-fallback-image-inline tex" alt="(\delta_k)" src="//upload.wikimedia.org/math/6/d/0/6d02152e6c09e5c2bdcdc83382214af2.png">; the <i>transition counts (spectrum)</i> of <i>G</i> are the collection of integers defined by</p>
<p>A Gray code is <i>uniform</i> or <i>uniformly balanced</i> if its transition counts are all equal, in which case we have <img class="mwe-math-fallback-image-inline tex" alt="\lambda_k = R^n / n" src="//upload.wikimedia.org/math/0/8/d/08da2668c2282f187a3c4619f7112f72.png"> for all <i>k</i>. Clearly, when <img class="mwe-math-fallback-image-inline tex" alt="R = 2" src="//upload.wikimedia.org/math/b/0/9/b09c6f646b1383ec048b47d563da6de2.png">, such codes exist only if <i>n</i> is a power of 2. Otherwise, if <i>n</i> does not divide <img class="mwe-math-fallback-image-inline tex" alt="R^n" src="//upload.wikimedia.org/math/8/6/8/8680f722a3c5c4c68aed0843febe262d.png"> evenly, it is possible to construct <i>well-balanced</i> codes where every transition count is either <img class="mwe-math-fallback-image-inline tex" alt="\lfloor R^n / n \rfloor" src="//upload.wikimedia.org/math/8/3/6/836bddce5477e6fc954d747113e08804.png"> or <img class="mwe-math-fallback-image-inline tex" alt="\lceil R^n / n \rceil" src="//upload.wikimedia.org/math/1/5/2/1521d0fac8cdc75b74be6bec0bcc0f8a.png">. Gray codes can also be <i>exponentially balanced</i> if all of their transition counts are adjacent powers of two, and such codes exist for every power of two.</p>
<p>For example, a balanced 4-bit Gray code has 16 transitions, which can be evenly distributed among all four positions (four transitions per position), making it uniformly balanced:</p>
<p>WHATSON? 4e5154d8-1cac-4fe3-96dc-4a9a77bf1f3d</p>
<pre>
0 1 1 1 1 1 1 0 0 0 0 0 0 1 1 0 
0 0 1 1 1 1 0 0 1 1 1 1 0 0 0 0 
0 0 0 0 1 1 1 1 1 0 0 1 1 1 0 0 
0 0 0 1 1 0 0 0 0 0 1 1 1 1 1 1
</pre>
<p>whereas a balanced 5-bit Gray code has a total of 32 transitions, which cannot be evenly distributed among the positions. In this example, four positions have six transitions each, and one has eight:</p>
<p>WHATSON? d9730e57-3e30-4610-8048-3d6eb9df71c5</p>
<pre>
1 1 1 1 1 0 0 0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 
0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 0 0 
1 1 0 0 1 1 1 0 0 0 0 0 0 1 1 1 0 0 0 1 1 1 1 1 1 0 0 0 0 0 1 1 
1 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 1 
1 1 1 1 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 1 1 1 1
</pre>
<p>We will now show a construction for well-balanced binary Gray codes which allows us to generate an <i>n</i>-digit balanced Gray code for every <i>n</i>. The main principle is to inductively construct an <img class="mwe-math-fallback-image-inline tex" alt="(n+2)" src="//upload.wikimedia.org/math/1/9/9/19919aadd42912f2133ac0f3725a08ad.png">-digit Gray code <img class="mwe-math-fallback-image-inline tex" alt="G'" src="//upload.wikimedia.org/math/b/1/c/b1c5660b1392ecb094b31a0e42253ff9.png"> given an <i>n</i>-digit Gray code <i>G</i> in such a way that the balanced property is preserved. To do this, we consider partitions of <img class="mwe-math-fallback-image-inline tex" alt="G = g_0, \cdots, g_{2^n-1}" src="//upload.wikimedia.org/math/8/3/7/837fd6e93295f718685bd811b9a618de.png"> into an even number <i>L</i> of non-empty blocks of the form</p>
<p>where <img class="mwe-math-fallback-image-inline tex" alt="k_1 = 0, k_{L-1} = -2" src="//upload.wikimedia.org/math/0/8/2/082a543110bc9dce9aba1d4e8b142c30.png">, and <img class="mwe-math-fallback-image-inline tex" alt="k_{L} = -1" src="//upload.wikimedia.org/math/8/5/d/85dee814bc209b88b4e75b3a4c6151cf.png"> (mod <img class="mwe-math-fallback-image-inline tex" alt="2^n" src="//upload.wikimedia.org/math/9/a/a/9aa0ec0374c89d2f7f3d9cd2e05a4bc5.png">). This partition induces an <img class="mwe-math-fallback-image-inline tex" alt="(n+2)" src="//upload.wikimedia.org/math/1/9/9/19919aadd42912f2133ac0f3725a08ad.png">-digit Gray code given by</p>
<p>If we define the <i>transition multiplicities</i> <img class="mwe-math-fallback-image-inline tex" alt="m_i = |\{ j : \delta_{k_j} = i, 1 \leq j \leq L \}|" src="//upload.wikimedia.org/math/5/2/8/528ed7e95f40444314310b4b787ae312.png"> to be the number of times the digit in position <i>i</i> changes between consecutive blocks in a partition, then for the <img class="mwe-math-fallback-image-inline tex" alt="(n+2)" src="//upload.wikimedia.org/math/1/9/9/19919aadd42912f2133ac0f3725a08ad.png">-digit Gray code induced by this partition the transition spectrum <img class="mwe-math-fallback-image-inline tex" alt="\lambda'_k" src="//upload.wikimedia.org/math/2/3/5/2359907a599697701267afafb0ebeb55.png"> is</p>
<p>The delicate part of this construction is to find an adequate partitioning of a balanced <i>n</i>-digit Gray code such that the code induced by it remains balanced. Uniform codes can be found when <img class="mwe-math-fallback-image-inline tex" alt="R \equiv 0 \mod 4" src="//upload.wikimedia.org/math/e/c/f/ecf42e68b481ba3a1d5cdc8afb9569d2.png"> and <img class="mwe-math-fallback-image-inline tex" alt="R^n \equiv 0 \mod n" src="//upload.wikimedia.org/math/e/8/3/e831201bfb4b7f8166e5b4d37998a166.png">, and this construction can be extended to the <i>R</i>-ary case as well.</p>
<h3>Monotonic Gray codes</h3>
<p>Monotonic codes are useful in the theory of interconnection networks, especially for minimizing dilation for linear arrays of processors. If we define the <i>weight</i> of a binary string to be the number of 1's in the string, then although we clearly cannot have a Gray code with strictly increasing weight, we may want to approximate this by having the code run through two adjacent weights before reaching the next one.</p>
<p>We can formalize the concept of monotone Gray codes as follows: consider the partition of the hypercube <img class="mwe-math-fallback-image-inline tex" alt="Q_n = (V_n, E_n)" src="//upload.wikimedia.org/math/2/2/b/22b4e56b6bfa3b13fda0bdd68ee58bcd.png"> into <i>levels</i> of vertices that have equal weight, i.e.</p>
<p><img class="mwe-math-fallback-image-inline tex" alt="V_n(i) = \{ v \in V_n : v \text{ has weight } i \}" src="//upload.wikimedia.org/math/8/f/0/8f0f99bd1825063ba7e07e61ac001b54.png"></p>
<p>for <img class="mwe-math-fallback-image-inline tex" alt="0 \leq i \leq n" src="//upload.wikimedia.org/math/0/5/b/05bdb30cea2ff2f555ea8236e1845287.png">. These levels satisfy <img class="mwe-math-fallback-image-inline tex" alt="|V_n(i)| = \binom{n}{i}" src="//upload.wikimedia.org/math/8/3/6/836665f7b5166b5f9fe5bad9445a38f7.png">. Let <img class="mwe-math-fallback-image-inline tex" alt="Q_n(i)" src="//upload.wikimedia.org/math/e/d/d/edd63419a1f493a5f850d368cf2963c6.png"> be the subgraph of <img class="mwe-math-fallback-image-inline tex" alt="Q_n" src="//upload.wikimedia.org/math/c/c/2/cc2a8613d2fc6fe9c1918e15d284bb8d.png"> induced by <img class="mwe-math-fallback-image-inline tex" alt="V_n(i) \cup V_n(i+1)" src="//upload.wikimedia.org/math/4/3/0/4306b1a158ebdb2df5c3bf70ebdece35.png">, and let <img class="mwe-math-fallback-image-inline tex" alt="E_n(i)" src="//upload.wikimedia.org/math/9/9/e/99ee7eb6e7d8663055fa8e28045ac197.png"> be the edges in <img class="mwe-math-fallback-image-inline tex" alt="Q_n(i)" src="//upload.wikimedia.org/math/e/d/d/edd63419a1f493a5f850d368cf2963c6.png">. A monotonic Gray code is then a Hamiltonian path in <img class="mwe-math-fallback-image-inline tex" alt="Q_n" src="//upload.wikimedia.org/math/c/c/2/cc2a8613d2fc6fe9c1918e15d284bb8d.png"> such that whenever <img class="mwe-math-fallback-image-inline tex" alt="\delta_1 \in E_n(i)" src="//upload.wikimedia.org/math/a/9/1/a91c9b2b202a93fcd7f91dc570f56890.png"> comes before <img class="mwe-math-fallback-image-inline tex" alt="\delta_2 \in E_n(j)" src="//upload.wikimedia.org/math/5/c/a/5ca29cd5e3171c696f04624c9c9c7e93.png"> in the path, then <img class="mwe-math-fallback-image-inline tex" alt="i \leq j" src="//upload.wikimedia.org/math/f/1/f/f1f27e9c5f7572e13a24c7671e1f74be.png">.</p>
<p>An elegant construction of monotonic <i>n</i>-digit Gray codes for any <i>n</i> is based on the idea of recursively building subpaths <img class="mwe-math-fallback-image-inline tex" alt="P_{n,j}" src="//upload.wikimedia.org/math/0/c/1/0c19deb6fb5fe53d04ccd5fbed73b271.png"> of length <img class="mwe-math-fallback-image-inline tex" alt="2 \binom{n}{j}" src="//upload.wikimedia.org/math/7/e/8/7e893358cdb87e8606ef86c27a7bf5f3.png"> having edges in <img class="mwe-math-fallback-image-inline tex" alt="E_n(j)" src="//upload.wikimedia.org/math/7/b/9/7b9357471fb58161b45ac24f0696b67b.png">. We define <img class="mwe-math-fallback-image-inline tex" alt="P_{1,0} = (0, 1)" src="//upload.wikimedia.org/math/9/9/9/999f5101457f717f93ea57d4fee37fcc.png">, <img class="mwe-math-fallback-image-inline tex" alt="P_{n,j} = \emptyset" src="//upload.wikimedia.org/math/a/9/1/a91f7892eda1d938ceccf3bd8859dc99.png"> whenever <img class="mwe-math-fallback-image-inline tex" alt="j &lt; 0" src="//upload.wikimedia.org/math/9/9/1/99137da1cd089e020c79b51c284e9a04.png"> or <img class="mwe-math-fallback-image-inline tex" alt="j \geq n" src="//upload.wikimedia.org/math/d/1/4/d14114121bd2b349700d0be2d02a46b9.png">, and</p>
<p><img class="mwe-math-fallback-image-inline tex" alt="
P_{n+1,j} = 1P^{\pi_n}_{n,j-1}, 0P_{n,j}
" src="//upload.wikimedia.org/math/0/0/5/00571969f4516d4458317f837836f54f.png"></p>
<p>otherwise. Here, <img class="mwe-math-fallback-image-inline tex" alt="\pi_n" src="//upload.wikimedia.org/math/0/e/b/0eb0e15b36f3d88c83abc95d4f88f48f.png"> is a suitably defined permutation and <img class="mwe-math-fallback-image-inline tex" alt="P^{\pi}" src="//upload.wikimedia.org/math/2/9/2/29234091a227dd24e98d809dab9c96be.png"> refers to the path <i>P</i> with its coordinates permuted by <img class="mwe-math-fallback-image-inline tex" alt="\pi" src="//upload.wikimedia.org/math/5/2/2/522359592d78569a9eac16498aa7a087.png">. These paths give rise to two monotonic <i>n</i>-digit Gray codes <img class="mwe-math-fallback-image-inline tex" alt="G_n^{(1)}" src="//upload.wikimedia.org/math/d/4/0/d40135c9412b55484b0df7558533598f.png"> and <img class="mwe-math-fallback-image-inline tex" alt="G_n^{(2)}" src="//upload.wikimedia.org/math/7/a/0/7a0dae442e54d8d3203d5fbd8161e1ae.png"> given by</p>
<p><img class="mwe-math-fallback-image-inline tex" alt="
G_n^{(1)} = P_{n,0} P_{n,1}^R P_{n,2} P_{n,3}^R \cdots \text{ and } G_n^{(2)} = P_{n,0}^R P_{n,1} P_{n,2}^R P_{n,3} \cdots
" src="//upload.wikimedia.org/math/0/e/4/0e4a6f8eca11182240bf8f53bf2d623f.png"></p>
<p>The choice of <img class="mwe-math-fallback-image-inline tex" alt="\pi_n" src="//upload.wikimedia.org/math/0/e/b/0eb0e15b36f3d88c83abc95d4f88f48f.png"> which ensures that these codes are indeed Gray codes turns out to be <img class="mwe-math-fallback-image-inline tex" alt="\pi_n = E^{-1}(\pi_{n-1}^2)" src="//upload.wikimedia.org/math/1/e/3/1e3493ab5f8e303229de2dc068e06eae.png">. The first few values of <img class="mwe-math-fallback-image-inline tex" alt="P_{n,j}" src="//upload.wikimedia.org/math/0/c/1/0c19deb6fb5fe53d04ccd5fbed73b271.png"> are shown in the table below.</p>
<p>These monotonic Gray codes can be efficiently implemented in such a way that each subsequent element can be generated in <i>O</i>(<i>n</i>) time. The algorithm is most easily described using coroutines.</p>
<p>Monotonic codes have an interesting connection to the Lovász conjecture, which states that every connected vertex-transitive graph contains a Hamiltonian path. The "middle-level" subgraph <img class="mwe-math-fallback-image-inline tex" alt="Q_{2n+1}(n)" src="//upload.wikimedia.org/math/1/0/9/10935f10e38011e375f51b7ff4231d18.png"> is vertex-transitive (that is, its automorphism group is transitive, so that each vertex has the same "local environment"" and cannot be differentiated from the others, since we can relabel the coordinates as well as the binary digits to obtain an automorphism) and the problem of finding a Hamiltonian path in this subgraph is called the "middle-levels problem", which can provide insights into the more general conjecture. The question has been answered affirmatively for <img class="mwe-math-fallback-image-inline tex" alt="n \leq 15" src="//upload.wikimedia.org/math/3/d/a/3dacf4c53505dfe043e0dd3774558f14.png">, and the preceding construction for monotonic codes ensures a Hamiltonian path of length at least 0.839<i>N</i> where <i>N</i> is the number of vertices in the middle-level subgraph.</p>
<h3>Beckett–Gray code</h3>
<p>Another type of Gray code, the <b>Beckett–Gray code</b>, is named for Irish playwright Samuel Beckett, who was interested in symmetry. His play "Quad" features four actors and is divided into sixteen time periods. Each period ends with one of the four actors entering or leaving the stage. The play begins with an empty stage, and Beckett wanted each subset of actors to appear on stage exactly once. Clearly the set of actors currently on stage can be represented by a 4-bit binary Gray code. Beckett, however, placed an additional restriction on the script: he wished the actors to enter and exit so that the actor who had been on stage the longest would always be the one to exit. The actors could then be represented by a first in, first out queue, so that (of the actors onstage) the actor being dequeued is always the one who was enqueued first. Beckett was unable to find a Beckett–Gray code for his play, and indeed, an exhaustive listing of all possible sequences reveals that no such code exists for <i>n</i> = 4. It is known today that such codes do exist for <i>n</i> = 2, 5, 6, 7, and 8, and do not exist for <i>n</i> = 3 or 4. An example of an 8-bit Beckett–Gray code can be found in Knuth's <i>Art of Computer Programming</i>. According to Sawada and Wong, the search space for <i>n</i> = 6 can be explored in 15 hours, and more than 9,500 solutions for the case <i>n</i> = 7 have been found.</p>
<h3>Snake-in-the-box codes</h3>
<p>Snake-in-the-box codes, or <i>snakes</i>, are the sequences of nodes of induced paths in an <i>n</i>-dimensional hypercube graph, and coil-in-the-box codes, or <i>coils</i>, are the sequences of nodes of induced cycles in a hypercube. Viewed as Gray codes, these sequences have the property of being able to detect any single-bit coding error. Codes of this type were first described by W. H. Kautz in the late 1950s; since then, there has been much research on finding the code with the largest possible number of codewords for a given hypercube dimension.</p>
<h3>Single-track Gray code</h3>
<p>Yet another kind of Gray code is the <b>single-track Gray code</b> (STGC) developed by N. B. Spedding (NZ Patent 264738 - October 28, 1994) and refined by Hiltgen, Paterson and Brandestini in "Single-track Gray codes" (1996). The STGC is a cyclical list of <i>P</i> unique binary encodings of length n such that two consecutive words differ in exactly one position, and when the list is examined as a <i>P x n</i> matrix, each column is a cyclic shift of the first column.</p>
<p>The name comes from their use with rotary encoders, where a number of tracks are being sensed by contacts, resulting for each in an output of 0 or 1. To reduce noise due to different contacts not switching at exactly the same moment in time, one preferably sets up the tracks so that the data output by the contacts are in Gray code. To get high angular accuracy, one needs lots of contacts; in order to achieve at least 1 degree accuracy, one needs at least 360 distinct positions per revolution, which requires a minimum of 9 bits of data, and thus the same number of contacts.</p>
<p>If all contacts are placed at the same angular position, then 9 tracks are needed to get a standard BRGC with at least 1 degree accuracy. However, if the manufacturer moves a contact to a different angular position (but at the same distance from the center shaft), then the corresponding "ring pattern" needs to be rotated the same angle to give the same output. If the most significant bit (the inner ring in Figure 1) is rotated enough, it exactly matches the next ring out. Since both rings are then identical, the inner ring can be cut out, and the sensor for that ring moved to the remaining, identical ring (but offset at that angle from the other sensor on that ring). Those 2 sensors on a single ring make a quadrature encoder. That reduces the number of tracks for a "1 degree resolution" angular encoder to 8 tracks. Reducing the number of tracks still further can't be done with BRGC.</p>
<p>For many years, Torsten Sillke and other mathematicians believed that it was impossible to encode position on a single track such that consecutive positions differed at only a single sensor, except for the 2-sensor, 1-track quadrature encoder. So for applications where 8 tracks were too bulky, people used single-track incremental encoders (quadrature encoders) or 2-track "quadrature encoder + reference notch" encoders.</p>
<p>N. B. Spedding, however, registered a patent in 1994 with several examples showing that it was possible. Although it is not possible to distinguish 2 positions with <i>n</i> sensors on a single track, it <i>is</i> possible to distinguish close to that many. For example, when <i>n</i> is itself a power of 2, <i>n</i> sensors can distinguish 2−2<i>n</i> positions. Hiltgen and Paterson published a paper in 2001 exhibiting a single-track gray code with exactly 360 angular positions, constructed using 9 sensors. Since this number is larger than 2 = 256, more than 8 sensors are required by any code, although a BRGC could distinguish 512 positions with 9 sensors. An STGC for <i>P = 30</i> and <i>n = 5</i> is reproduced here:</p>
<p>WHATSON? d9d42105-3e5f-4a52-80e2-caa5408aea64</p>
<pre>
10000
10100
11100
11110
11010
11000
01000
01010
01110
01111
01101
01100
00100
00101
00111
10111
10110
00110
00010
10010
10011
11011
01011
00011
00001
01001
11001
11101
10101
10001
</pre>
<p>Note that each column is a cyclic shift of the first column, and from any row to the next row only one bit changes. The single-track nature (like a code chain) is useful in the fabrication of these wheels (compared to BRGC), as only one track is needed, thus reducing their cost and size. The Gray code nature is useful (compared to chain codes, also called De Bruijn sequences), as only one sensor will change at any one time, so the uncertainty during a transition between two discrete states will only be plus or minus one unit of angular measurement the device is capable of resolving.</p>
<h2>See also</h2>
<ul>
<li>Linear feedback shift register</li>
<li>De Bruijn sequence</li>
<li>Gillham code</li>
<li>Steinhaus–Johnson–Trotter algorithm, an algorithm that generates Gray codes for the factorial number system</li>
</ul>
<h2>Notes</h2>
<ol>
<li><b>^</b> F. Gray. <i>Pulse code communication</i>, March 17, 1953 (filed Nov. 1947). U.S. Patent 2,632,058</li>
<li><b>^</b> J. Breckman. <i>Encoding Circuit</i>, Jan 31, 1956 (filed Dec. 1953). U.S. Patent 2,733,432</li>
<li>^   E. A. Ragland et al. <i>Direction-Sensitive Binary Code Position Control System</i>, Feb. 11, 1958 (filed Oct. 1953). U.S. Patent 2,823,345</li>
<li><b>^</b> S. Reiner et al. <i>Automatic Rectification System</i>, Jun 24, 1958 (filed Jan. 1954). U.S. Patent 2,839,974</li>
<li><b>^</b> Pickover, Clifford A. (2009). <i>The Math Book: From Pythagoras to the 57th Dimension, 250 Milestones in the History of Mathematics</i>. Sterling Publishing Company. p. 392. ISBN 9781402757969. </li>
<li>^     Knuth, Donald E. "Generating all <i>n</i>-tuples." <i>The Art of Computer Programming, Volume 4A: Enumeration and Backtracking</i>, pre-fascicle 2a, October 15, 2004. [1]</li>
<li><b>^</b> Cattermole, K. W. (1969). <i>Principles of Pulse Code Modulation</i>. New York: American Elsevier. ISBN 0-444-19747-8. </li>
<li><b>^</b> Goodall, W. M. (1951). "Television by Pulse Code Modulation". <i>Bell Sys. Tech. J.</i> <b>30</b>: 33–49. </li>
<li><b>^</b> Wakerly, John F (1994). <i>Digital Design: Principles &amp; Practices</i>. New Jersey: Prentice Hall. pp. 222, 48–49. ISBN 0-13-211459-3.  Note that the two page sections taken together say that K-maps are labeled with Gray code. The first section says that they are labeled with a code that changes only one bit between entries and the second section says that such a code is called Gray code.</li>
<li><b>^</b> "Synchronization in Digital Logic Circuits by Ryan Donohue</li>
<li><b>^</b> Mehta, H.; Owens, R.M. &amp; Irwin, M.J. (1996), Some issues in gray code addressing, in the Proceedings of the 6th Great Lakes Symposium on VLSI (GLSVLSI 96), IEEE Computer Society,pp. 178</li>
<li><b>^</b> The Gray Code by R. W. Doran</li>
<li><b>^</b> Henry Gordon Dietz. "The Aggregate Magic Algorithms: Gray Code Conversion"</li>
<li>^   Guan, Dah-Jyh (1998). "Generalized Gray Codes with Applications". <i>Proc. Natl. Sci. Counc. Repub. Of China (A)</i> <b>22</b>: 841–848. CiteSeerX: 10.1.1.119.1344. </li>
<li>^    Bhat, Girish S.; Savage, Carla D. (1996). "Balanced Gray codes". <i>Electronic Journal of Combinatorics</i> <b>3</b> (1): R25. </li>
<li><b>^</b> Suparta, I. N. (2005). "A simple proof for the existence of exponentially balanced Gray codes". <i>Electronic Journal of Combinatorics</i> <b>12</b>. </li>
<li>^   M. Flahive and B. Bose (2007). "Balancing cyclic R-ary Gray codes". <i>Electronic Journal of Combinatorics</i> <b>14</b>. </li>
<li>^   C. D Savage and P. Winkler (1995). "Monotone Gray codes and the middle levels problem". <i>Journal of Combinatorial Theory, Series A</i> <b>70</b> (2): 230–248. doi:10.1016/0097-3165(95)90091-8. ISSN 0097-3165. </li>
<li><b>^</b> C. D Savage (1997). "Long cycles in the middle two levels of the Boolean lattice". </li>
<li>^   Goddyn, Luis (1999). "MATH 343 Applied Discrete Math Supplementary Materials" (PDF). Dept. of Math, Simon Fraser U. </li>
<li><b>^</b> Wong, J. (2007). "A Fast Algorithm to generate Beckett-Gray codes". <i>Electronic Notes in Discrete Mathematics</i> <b>29</b>: 571–577. doi:10.1016/j.endm.2007.07.091.  <code style="color:inherit; border:inherit; padding:inherit;">|first2=</code> missing <code style="color:inherit; border:inherit; padding:inherit;">|last2=</code> in Authors list (help)</li>
<li><b>^</b> Kautz, W. H. (1958). "Unit-distance error-checking codes". <i>IRE Trans. Elect. Comput.</i> <b>7</b>: 177–180. </li>
<li>^   ([http://www.winzurf.co.nz/Single_Track_Grey_Code_Patent/Single_track_Grey_code_encoder_patent.pdf "Single track grey code". winzurf.co.nz) NZ A method of creating a single track absolute position rotary or linear encoder of varying resolutions using equi-spaced detectors. 264738 ("Single track grey code". winzurf.co.nz)], [|Spedding, Norman Bruce], "A position encoder", published 1994 </li>
<li><b>^</b> Hiltgen, Alain P.; Kenneth G. Paterson; Marco Brandestini (1996). "Single-Track Gray Codes" (PDF). <i>IEEE Transactions on Information Theory</i> <b>42</b> (5): 1555–1561. doi:10.1109/18.532900. </li>
<li><b>^</b> Etzion, Tuvi; Moshe Schwartz (1999). "The Structure of Single-Track Gray Codes" (PDF). <i>IEEE Transactions on Information Theory</i> <b>45</b> (7): 2383–2396. doi:10.1109/18.796379. </li>
<li><b>^</b> Hiltgen, Alain P.; Kenneth G. Paterson (2001). "Single-Track Circuit Codes" (PDF). <i>IEEE Transactions on Information Theory</i> <b>47</b> (6): 2587–2595. doi:10.1109/18.945274. </li>
<li><b>^</b> "Venn Diagram Survey — Symmetric Diagrams". <i>Electronic Journal of Combinatorics</i>. 2001. </li>
<li><b>^</b> Alciatore, David G.; Michael B. Histand (1999). <i>Mechatronics</i>. McGraw-Hill Education - Europe. ISBN 978-0-07-131444-2. </li>
</ol>
</body>
</html>