<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Hungarian-algorithm---Wikipedia-the-free-encyclopedia.html</title></head>
<body>
<h1>Hungarian algorithm</h1>
<p>The <b>Hungarian method</b> is a combinatorial optimization algorithm that solves the assignment problem in polynomial time and which anticipated later primal-dual methods. It was developed and published by Harold Kuhn in 1955, who gave the name "Hungarian method" because the algorithm was largely based on the earlier works of two Hungarian mathematicians: Dénes Kőnig and Jenő Egerváry.</p>
<p>James Munkres reviewed the algorithm in 1957 and observed that it is (strongly) polynomial. Since then the algorithm has been known also as the <b>Kuhn–Munkres algorithm</b> or <b>Munkres assignment algorithm</b>. The time complexity of the original algorithm was <img class="mwe-math-fallback-image-inline tex" alt="O(n^4)" src="//upload.wikimedia.org/math/9/a/5/9a52496308b264e9678c0ea086d46130.png">, however Edmonds and Karp, and independently Tomizawa noticed that it can be modified to achieve an <img class="mwe-math-fallback-image-inline tex" alt="O(n^3)" src="//upload.wikimedia.org/math/6/8/0/6809c59370e21b3e6e8fd117442fd377.png"> running time. Ford and Fulkerson extended the method to general transportation problems. In 2006, it was discovered that Carl Gustav Jacobi had solved the assignment problem in the 19th century, and the solution had been published posthumously in 1890 in Latin.</p>
<p></p>
<h2>Contents</h2>
<ul>
<li>1 Layman’s Explanation of the Assignment Problem</li>
<li>2 Setting</li>
<li>3 The algorithm in terms of bipartite graphs</li>
<li>4 Matrix interpretation</li>
<li>5 Bibliography</li>
<li>6 References</li>
<li>7 External links
<ul>
<li>7.1 Implementations</li>
</ul>
</li>
</ul>
<ul>
<li>7.1 Implementations</li>
</ul>
<p></p>
<h2>Layman’s Explanation of the Assignment Problem</h2>
<p>Say you have three workers: <b>Jim</b>, <b>Steve</b>, and <b>Alan</b>. You need to have one of them clean the bathroom, another sweep the floors, and the third wash the windows. What’s the best (minimum-cost) way to assign the jobs? First we need a matrix of the costs of the workers doing the jobs.</p>
<p>Then the Hungarian method, when applied to the above table would give us the minimum cost it can be done with: Jim cleans the bathroom, Steve sweeps the floors, and Alan washes the windows.</p>
<h2>Setting</h2>
<p>We are given a nonnegative <i>n</i>×<i>n</i> matrix, where the element in the <i>i</i>-th row and <i>j</i>-th column represents the cost of assigning the <i>j</i>-th job to the <i>i</i>-th worker. We have to find an assignment of the jobs to the workers that has minimum cost. If the goal is to find the assignment that yields the maximum cost, the problem can be altered to fit the setting by replacing each cost with the maximum cost subtracted by the cost.</p>
<p>The algorithm is easier to describe if we formulate the problem using a bipartite graph. We have a complete bipartite graph <i>G=(S, T; E)</i> with <i>n</i> worker vertices (<i>S</i>) and <i>n</i> job vertices (<i>T</i>), and each edge has a nonnegative cost <i>c(i,j)</i>. We want to find a perfect matching with minimum cost.</p>
<p>Let us call a function <img class="mwe-math-fallback-image-inline tex" alt="y: (S \cup T) \mapsto \mathbb{R}" src="//upload.wikimedia.org/math/0/7/4/07499967d177012258f2d40bc6fcb6c6.png"> a <b>potential</b> if <img class="mwe-math-fallback-image-inline tex" alt="y(i)+y(j) \leq c(i, j)" src="//upload.wikimedia.org/math/1/8/7/187a6b85c50decd3898a8e17e71861c8.png"> for each <img class="mwe-math-fallback-image-inline tex" alt="i \in S, j \in T" src="//upload.wikimedia.org/math/c/f/4/cf468a3d037bc79c7b7b4dbccca164e6.png">. The value of potential <i>y</i> is <img class="mwe-math-fallback-image-inline tex" alt="\sum_{v\in S\cup T} y(v)" src="//upload.wikimedia.org/math/f/5/c/f5c86fbfa44aa7df54dbdeaf9cfa318f.png">. It can be seen that the cost of each perfect matching is at least the value of each potential. The Hungarian method finds a perfect matching and a potential with equal cost/value which proves the optimality of both. In fact it finds a perfect matching of <b>tight edges</b>: an edge <i>ij</i> is called tight for a potential <i>y</i> if <img class="mwe-math-fallback-image-inline tex" alt="y(i)+y(j) = c(i, j)" src="//upload.wikimedia.org/math/4/a/6/4a6e0a2ba25c38778110b039ca87ae5d.png">. Let us denote the subgraph of tight edges by <img class="mwe-math-fallback-image-inline tex" alt="G_y" src="//upload.wikimedia.org/math/2/2/c/22cb2e73509152b597f3cd24850f5ac7.png">. The cost of a perfect matching in <img class="mwe-math-fallback-image-inline tex" alt="G_y" src="//upload.wikimedia.org/math/2/2/c/22cb2e73509152b597f3cd24850f5ac7.png"> (if there is one) equals the value of <i>y</i>.</p>
<h2>The algorithm in terms of bipartite graphs</h2>
<p>During the algorithm we maintain a potential <i>y</i> and an orientation of <img class="mwe-math-fallback-image-inline tex" alt="G_y" src="//upload.wikimedia.org/math/2/2/c/22cb2e73509152b597f3cd24850f5ac7.png"> (denoted by <img class="mwe-math-fallback-image-inline tex" alt="\overrightarrow{G_y}" src="//upload.wikimedia.org/math/b/f/f/bff23e071e3dd5a3f769e04843f392b6.png">) which has the property that the edges oriented from <i>T</i> to <i>S</i> form a matching <i>M</i>. Initially, <i>y</i> is 0 everywhere, and all edges are oriented from <i>S</i> to <i>T</i> (so <i>M</i> is empty). In each step, either we modify <i>y</i> so that its value increases, or modify the orientation to obtain a matching with more edges. We maintain the invariant that all the edges of <i>M</i> are tight. We are done if <i>M</i> is a perfect matching.</p>
<p>In a general step, let <img class="mwe-math-fallback-image-inline tex" alt="R_S \subseteq S" src="//upload.wikimedia.org/math/e/7/5/e75873705a028d4401befd613e437543.png"> and <img class="mwe-math-fallback-image-inline tex" alt="R_T \subseteq T" src="//upload.wikimedia.org/math/5/2/5/52545c8b648fb945ea52e52b1cb8ac4f.png"> be the vertices not covered by <i>M</i> (so <img class="mwe-math-fallback-image-inline tex" alt="R_S" src="//upload.wikimedia.org/math/2/8/f/28fb973a0cb586fff964eae82695afdb.png"> consists of the vertices in <i>S</i> with no incoming edge and <img class="mwe-math-fallback-image-inline tex" alt="R_T" src="//upload.wikimedia.org/math/a/5/9/a59527f2dd57ac008cc0d77748fa640a.png"> consists of the vertices in <i>T</i> with no outgoing edge). Let <img class="mwe-math-fallback-image-inline tex" alt="Z" src="//upload.wikimedia.org/math/2/1/c/21c2e59531c8710156d34a3c30ac81d5.png"> be the set of vertices reachable in <img class="mwe-math-fallback-image-inline tex" alt="\overrightarrow{G_y}" src="//upload.wikimedia.org/math/b/f/f/bff23e071e3dd5a3f769e04843f392b6.png"> from <img class="mwe-math-fallback-image-inline tex" alt="R_S" src="//upload.wikimedia.org/math/2/8/f/28fb973a0cb586fff964eae82695afdb.png"> by a directed path only following edges that are tight. This can be computed by breadth-first search.</p>
<p>If <img class="mwe-math-fallback-image-inline tex" alt="R_T \cap Z" src="//upload.wikimedia.org/math/0/4/b/04ba99643122a5cc0a468f3457af3abf.png"> is nonempty, then reverse the orientation of a directed path in <img class="mwe-math-fallback-image-inline tex" alt="\overrightarrow{G_y}" src="//upload.wikimedia.org/math/b/f/f/bff23e071e3dd5a3f769e04843f392b6.png"> from <img class="mwe-math-fallback-image-inline tex" alt="R_S" src="//upload.wikimedia.org/math/2/8/f/28fb973a0cb586fff964eae82695afdb.png"> to <img class="mwe-math-fallback-image-inline tex" alt="R_T" src="//upload.wikimedia.org/math/a/5/9/a59527f2dd57ac008cc0d77748fa640a.png">. Thus the size of the corresponding matching increases by 1.</p>
<p>If <img class="mwe-math-fallback-image-inline tex" alt="R_T \cap Z" src="//upload.wikimedia.org/math/0/4/b/04ba99643122a5cc0a468f3457af3abf.png"> is empty, then let <img class="mwe-math-fallback-image-inline tex" alt="\Delta := \min \{c(i,j)-y(i)-y(j): i \in Z \cap S, j \in T \setminus Z\}" src="//upload.wikimedia.org/math/f/1/4/f14531dfb424b79a06385032a2dd2a67.png">. <img class="mwe-math-fallback-image-inline tex" alt="\Delta" src="//upload.wikimedia.org/math/6/5/9/659d23f0ed16cdb87b1d41c7b58b52f4.png"> is positive because there are no tight edges between <img class="mwe-math-fallback-image-inline tex" alt="Z \cap S" src="//upload.wikimedia.org/math/5/d/7/5d79838b74b27e5539d3501a937839be.png"> and <img class="mwe-math-fallback-image-inline tex" alt="T \setminus Z" src="//upload.wikimedia.org/math/4/d/5/4d539ca1d7cac0a776cb3a8c4ad1eecd.png">. Increase <i>y</i> by <img class="mwe-math-fallback-image-inline tex" alt="\Delta" src="//upload.wikimedia.org/math/6/5/9/659d23f0ed16cdb87b1d41c7b58b52f4.png"> on the vertices of <img class="mwe-math-fallback-image-inline tex" alt="Z \cap S" src="//upload.wikimedia.org/math/5/d/7/5d79838b74b27e5539d3501a937839be.png"> and decrease <i>y</i> by <img class="mwe-math-fallback-image-inline tex" alt="\Delta" src="//upload.wikimedia.org/math/6/5/9/659d23f0ed16cdb87b1d41c7b58b52f4.png"> on the vertices of <img class="mwe-math-fallback-image-inline tex" alt="Z \cap T" src="//upload.wikimedia.org/math/0/d/f/0df402eb4a587612003740cd0ace410d.png">. The resulting <i>y</i> is still a potential. The graph <img class="mwe-math-fallback-image-inline tex" alt="G_y" src="//upload.wikimedia.org/math/2/2/c/22cb2e73509152b597f3cd24850f5ac7.png"> changes, but it still contains <i>M</i>. We orient the new edges from <i>S</i> to <i>T</i>. By the definition of <img class="mwe-math-fallback-image-inline tex" alt="\Delta" src="//upload.wikimedia.org/math/6/5/9/659d23f0ed16cdb87b1d41c7b58b52f4.png"> the set <i>Z</i> of vertices reachable from <img class="mwe-math-fallback-image-inline tex" alt="R_S" src="//upload.wikimedia.org/math/2/8/f/28fb973a0cb586fff964eae82695afdb.png"> increases (note that the number of tight edges does not necessarily increase).</p>
<p>We repeat these steps until <i>M</i> is a perfect matching, in which case it gives a minimum cost assignment. The running time of this version of the method is <img class="mwe-math-fallback-image-inline tex" alt="O(n^4)" src="//upload.wikimedia.org/math/9/a/5/9a52496308b264e9678c0ea086d46130.png">: <i>M</i> is augmented <i>n</i> times, and in a phase where <i>M</i> is unchanged, there are at most <i>n</i> potential changes (since <i>Z</i> increases every time). The time needed for a potential change is <img class="mwe-math-fallback-image-inline tex" alt="O(n^2)" src="//upload.wikimedia.org/math/1/8/9/189317b4b935a745fcfaf95940d2b4f0.png">.</p>
<h2>Matrix interpretation</h2>
<p>Given <img class="mwe-math-fallback-image-inline tex" alt="n" src="//upload.wikimedia.org/math/7/b/8/7b8b965ad4bca0e41ab51de7b31363a1.png"> workers and tasks, and an <i>n</i>×<i>n</i> matrix containing the cost of assigning each worker to a task, find the cost minimizing assignment.</p>
<p>First the problem is written in the form of a matrix as given below</p>
<p>where a, b, c and d are the workers who have to perform tasks 1, 2, 3 and 4. a1, a2, a3, a4 denote the penalties incurred when worker "a" does task 1, 2, 3, 4 respectively. The same holds true for the other symbols as well. The matrix is square, so each worker can perform only one task.</p>
<p><b>Step 1</b></p>
<p>Then we perform row operations on the matrix. To do this, the lowest of all <i>a<sub>i</sub></i> (i belonging to 1-4) is taken and is subtracted from each element in that row. This will lead to at least one zero in that row (We get multiple zeros when there are two equal elements which also happen to be the lowest in that row). This procedure is repeated for all rows. We now have a matrix with at least one zero per row. Now we try to assign tasks to agents such that each agent is doing only one task and the penalty incurred in each case is zero. This is illustrated below.</p>
<p>The zeros that are indicated as 0' are the assigned tasks.</p>
<p><b>Step 2</b></p>
<p>Sometimes it may turn out that the matrix at this stage cannot be used for assigning, as is the case in for the matrix below.</p>
<p>In the above case, no assignment can be made. Note that task 1 is done efficiently by both agent a and c. Both can't be assigned the same task. Also note that no one does task 3 efficiently. To overcome this, we repeat the above procedure for all columns (i.e. the minimum element in each column is subtracted from all the elements in that column) and then check if an assignment is possible.</p>
<p>In most situations this will give the result, but if it is still not possible then we need to keep going..</p>
<p><b>Step 3</b></p>
<p>All zeros in the matrix must be covered by marking as few rows and/or columns as possible. The following procedure is one way to accomplish this:</p>
<p>First, assign as many tasks as possible.</p>
<ul>
<li>Row 1 has one zero, so it is assigned. The 0 in row 3 is crossed out because it is in the same column.</li>
<li>Row 2 has one zero, so it is assigned.</li>
<li>Row 3's only zero has been crossed out, so nothing is unassigned.</li>
<li>Row 4 has two uncrossed zeros. Either one can be assigned (both are optimum), and the other zero would be crossed out.</li>
</ul>
<p>Alternatively, the 0 in row 3 may be assigned, causing the 0 in row 1 to be crossed instead.</p>
<p>Now to the drawing part.</p>
<ul>
<li>Mark all rows having no assignments (row 3).</li>
<li>Mark all (unmarked) columns having zeros in newly marked row(s) (column 1).</li>
<li>Mark all rows having assignments in newly marked columns (row 1).</li>
<li>Repeat for all non-assigned rows.</li>
</ul>
<p>Now draw lines through all marked columns and <b>unmarked</b> rows.</p>
<p>The aforementioned detailed description is just one way to draw the minimum number of lines to cover all the 0s. Other methods work as well.</p>
<p><b>Step 4</b></p>
<p>From the elements that are left, find the lowest value. Subtract this from every unmarked element and add it to every element covered by two lines.</p>
<p>Repeat steps 3–4 until an assignment is possible; this is when the minimum number of lines used to cover all the 0s is equal to the max(number of people, number of assignments), assuming dummy variables (usually the max cost) are used to fill in when the number of people is greater than the number of assignments.</p>
<p>Basically you find the second minimum cost among the remaining choices. The procedure is repeated until you are able to distinguish among the workers in terms of least cost.</p>
<h2>Bibliography</h2>
<ul>
<li>R.E. Burkard, M. Dell'Amico, S. Martello: <i>Assignment Problems</i> (Revised reprint). SIAM, Philadelphia (PA.) 2012. ISBN 978-1-61197-222-1</li>
<li>M. Fischetti, "Lezioni di Ricerca Operativa", Edizioni Libreria Progetto Padova, Italia, 1995.</li>
<li>R. Ahuja, T. Magnanti, J. Orlin, "Network Flows", Prentice Hall, 1993.</li>
<li>S. Martello, "Jeno Egerváry: from the origins of the Hungarian algorithm to satellite communication". Central European Journal of Operations Research 18, 47–58, 2010</li>
</ul>
</body>
</html>