<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>List-of-algorithms---Wikipedia-the-free-encyclopedia.html</title></head>
<body>
<h1>List of algorithms</h1>
<p>The following is a <b>list of algorithms</b> along with one-line descriptions for each.</p>
<p></p>
<h2>Contents</h2>
<ul>
<li>1 Combinatorial algorithms
<ul>
<li>1.1 General combinatorial algorithms</li>
<li>1.2 Graph algorithms
<ul>
<li>1.2.1 Graph drawing</li>
<li>1.2.2 Network theory</li>
<li>1.2.3 Routing for graphs</li>
<li>1.2.4 Graph search</li>
<li>1.2.5 Subgraphs</li>
</ul>
</li>
<li>1.3 Sequence algorithms
<ul>
<li>1.3.1 Approximate sequence matching</li>
<li>1.3.2 Sequence search</li>
<li>1.3.3 Sequence merging</li>
<li>1.3.4 Sequence permutations</li>
<li>1.3.5 Sequence alignment</li>
<li>1.3.6 Sequence sorting</li>
<li>1.3.7 Subsequences</li>
<li>1.3.8 Substrings</li>
</ul>
</li>
</ul>
</li>
<li>2 Computational mathematics
<ul>
<li>2.1 Abstract algebra</li>
<li>2.2 Computer algebra</li>
<li>2.3 Geometry</li>
<li>2.4 Number theoretic algorithms</li>
<li>2.5 Numerical algorithms
<ul>
<li>2.5.1 Differential equation solving</li>
<li>2.5.2 Elementary and special functions</li>
<li>2.5.3 Geometric</li>
<li>2.5.4 Interpolation and extrapolation</li>
<li>2.5.5 Linear algebra</li>
<li>2.5.6 Monte Carlo</li>
<li>2.5.7 Numerical integration</li>
<li>2.5.8 Root finding</li>
</ul>
</li>
<li>2.6 Optimization algorithms</li>
</ul>
</li>
<li>3 Computational science
<ul>
<li>3.1 Astronomy</li>
<li>3.2 Bioinformatics</li>
<li>3.3 Geoscience</li>
<li>3.4 Linguistics</li>
<li>3.5 Medicine</li>
<li>3.6 Physics</li>
<li>3.7 Statistics</li>
</ul>
</li>
<li>4 Computer science
<ul>
<li>4.1 Computer architecture</li>
<li>4.2 Computer graphics</li>
<li>4.3 Cryptography</li>
<li>4.4 Digital logic</li>
<li>4.5 Machine learning and statistical classification</li>
<li>4.6 Programming language theory
<ul>
<li>4.6.1 Parsing</li>
</ul>
</li>
<li>4.7 Quantum algorithms</li>
<li>4.8 Theory of computation and automata</li>
</ul>
</li>
<li>5 Information theory and signal processing
<ul>
<li>5.1 Coding theory
<ul>
<li>5.1.1 Error detection and correction</li>
<li>5.1.2 Lossless compression algorithms</li>
<li>5.1.3 Lossy compression algorithms</li>
</ul>
</li>
<li>5.2 Digital signal processing
<ul>
<li>5.2.1 Image processing</li>
</ul>
</li>
</ul>
</li>
<li>6 Software engineering
<ul>
<li>6.1 Database algorithms</li>
<li>6.2 Distributed systems algorithms</li>
<li>6.3 Memory allocation and deallocation algorithms</li>
<li>6.4 Operating systems algorithms
<ul>
<li>6.4.1 Networking</li>
<li>6.4.2 Process synchronization</li>
<li>6.4.3 Scheduling</li>
<li>6.4.4 Disk scheduling</li>
</ul>
</li>
</ul>
</li>
<li>7 See also</li>
<li>8 References</li>
</ul>
<ul>
<li>1.1 General combinatorial algorithms</li>
<li>1.2 Graph algorithms
<ul>
<li>1.2.1 Graph drawing</li>
<li>1.2.2 Network theory</li>
<li>1.2.3 Routing for graphs</li>
<li>1.2.4 Graph search</li>
<li>1.2.5 Subgraphs</li>
</ul>
</li>
<li>1.3 Sequence algorithms
<ul>
<li>1.3.1 Approximate sequence matching</li>
<li>1.3.2 Sequence search</li>
<li>1.3.3 Sequence merging</li>
<li>1.3.4 Sequence permutations</li>
<li>1.3.5 Sequence alignment</li>
<li>1.3.6 Sequence sorting</li>
<li>1.3.7 Subsequences</li>
<li>1.3.8 Substrings</li>
</ul>
</li>
</ul>
<ul>
<li>1.2.1 Graph drawing</li>
<li>1.2.2 Network theory</li>
<li>1.2.3 Routing for graphs</li>
<li>1.2.4 Graph search</li>
<li>1.2.5 Subgraphs</li>
</ul>
<ul>
<li>1.3.1 Approximate sequence matching</li>
<li>1.3.2 Sequence search</li>
<li>1.3.3 Sequence merging</li>
<li>1.3.4 Sequence permutations</li>
<li>1.3.5 Sequence alignment</li>
<li>1.3.6 Sequence sorting</li>
<li>1.3.7 Subsequences</li>
<li>1.3.8 Substrings</li>
</ul>
<ul>
<li>2.1 Abstract algebra</li>
<li>2.2 Computer algebra</li>
<li>2.3 Geometry</li>
<li>2.4 Number theoretic algorithms</li>
<li>2.5 Numerical algorithms
<ul>
<li>2.5.1 Differential equation solving</li>
<li>2.5.2 Elementary and special functions</li>
<li>2.5.3 Geometric</li>
<li>2.5.4 Interpolation and extrapolation</li>
<li>2.5.5 Linear algebra</li>
<li>2.5.6 Monte Carlo</li>
<li>2.5.7 Numerical integration</li>
<li>2.5.8 Root finding</li>
</ul>
</li>
<li>2.6 Optimization algorithms</li>
</ul>
<ul>
<li>2.5.1 Differential equation solving</li>
<li>2.5.2 Elementary and special functions</li>
<li>2.5.3 Geometric</li>
<li>2.5.4 Interpolation and extrapolation</li>
<li>2.5.5 Linear algebra</li>
<li>2.5.6 Monte Carlo</li>
<li>2.5.7 Numerical integration</li>
<li>2.5.8 Root finding</li>
</ul>
<ul>
<li>3.1 Astronomy</li>
<li>3.2 Bioinformatics</li>
<li>3.3 Geoscience</li>
<li>3.4 Linguistics</li>
<li>3.5 Medicine</li>
<li>3.6 Physics</li>
<li>3.7 Statistics</li>
</ul>
<ul>
<li>4.1 Computer architecture</li>
<li>4.2 Computer graphics</li>
<li>4.3 Cryptography</li>
<li>4.4 Digital logic</li>
<li>4.5 Machine learning and statistical classification</li>
<li>4.6 Programming language theory
<ul>
<li>4.6.1 Parsing</li>
</ul>
</li>
<li>4.7 Quantum algorithms</li>
<li>4.8 Theory of computation and automata</li>
</ul>
<ul>
<li>4.6.1 Parsing</li>
</ul>
<ul>
<li>5.1 Coding theory
<ul>
<li>5.1.1 Error detection and correction</li>
<li>5.1.2 Lossless compression algorithms</li>
<li>5.1.3 Lossy compression algorithms</li>
</ul>
</li>
<li>5.2 Digital signal processing
<ul>
<li>5.2.1 Image processing</li>
</ul>
</li>
</ul>
<ul>
<li>5.1.1 Error detection and correction</li>
<li>5.1.2 Lossless compression algorithms</li>
<li>5.1.3 Lossy compression algorithms</li>
</ul>
<ul>
<li>5.2.1 Image processing</li>
</ul>
<ul>
<li>6.1 Database algorithms</li>
<li>6.2 Distributed systems algorithms</li>
<li>6.3 Memory allocation and deallocation algorithms</li>
<li>6.4 Operating systems algorithms
<ul>
<li>6.4.1 Networking</li>
<li>6.4.2 Process synchronization</li>
<li>6.4.3 Scheduling</li>
<li>6.4.4 Disk scheduling</li>
</ul>
</li>
</ul>
<ul>
<li>6.4.1 Networking</li>
<li>6.4.2 Process synchronization</li>
<li>6.4.3 Scheduling</li>
<li>6.4.4 Disk scheduling</li>
</ul>
<p></p>
<h2>Combinatorial algorithms</h2>
<h3>General combinatorial algorithms</h3>
<ul>
<li>Brent's algorithm: finds cycles in iterations using only two iterators</li>
<li>Floyd's cycle-finding algorithm: finds cycles in iterations</li>
<li>Gale–Shapley algorithm: solves the stable marriage problem</li>
<li>Pseudorandom number generators (uniformly distributed):
<ul>
<li>Blum Blum Shub</li>
<li>Lagged Fibonacci generator</li>
<li>Linear congruential generator</li>
<li>Mersenne twister</li>
</ul>
</li>
</ul>
<ul>
<li>Blum Blum Shub</li>
<li>Lagged Fibonacci generator</li>
<li>Linear congruential generator</li>
<li>Mersenne twister</li>
</ul>
<h3>Graph algorithms</h3>
<ul>
<li>Coloring algorithm: Graph coloring algorithm.</li>
<li>Hopcroft–Karp algorithm: convert a bipartite graph to a maximum cardinality matching</li>
<li>Hungarian algorithm: algorithm for finding a perfect matching</li>
<li>Prüfer coding: conversion between a labeled tree and its Prüfer sequence</li>
<li>Tarjan's off-line least common ancestors algorithm: compute lowest common ancestors for pairs of nodes in a tree</li>
<li>Topological sort: finds linear order of nodes (e.g. jobs) based on their dependencies.</li>
</ul>
<h4>Graph drawing</h4>
<ul>
<li>Force-based algorithms (also known as force-directed algorithms or spring-based algorithm)</li>
<li>Spectral layout</li>
</ul>
<h4>Network theory</h4>
<ul>
<li>Network analysis
<ul>
<li>Link analysis
<ul>
<li>Girvan–Newman algorithm: detect communities in complex systems</li>
<li>Web link analysis
<ul>
<li>Hyperlink-Induced Topic Search (HITS) (also known as Hubs and authorities)</li>
<li>PageRank</li>
<li>TrustRank</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Flow networks
<ul>
<li>Dinic's algorithm: is a strongly polynomial algorithm for computing the maximum flow in a flow network.</li>
<li>Edmonds–Karp algorithm: implementation of Ford–Fulkerson</li>
<li>Ford–Fulkerson algorithm: computes the maximum flow in a graph</li>
<li>Karger's algorithm: a Monte Carlo method to compute the minimum cut of a connected graph</li>
<li>Push–relabel algorithm: computes a maximum flow in a graph</li>
</ul>
</li>
</ul>
<ul>
<li>Link analysis
<ul>
<li>Girvan–Newman algorithm: detect communities in complex systems</li>
<li>Web link analysis
<ul>
<li>Hyperlink-Induced Topic Search (HITS) (also known as Hubs and authorities)</li>
<li>PageRank</li>
<li>TrustRank</li>
</ul>
</li>
</ul>
</li>
</ul>
<ul>
<li>Girvan–Newman algorithm: detect communities in complex systems</li>
<li>Web link analysis
<ul>
<li>Hyperlink-Induced Topic Search (HITS) (also known as Hubs and authorities)</li>
<li>PageRank</li>
<li>TrustRank</li>
</ul>
</li>
</ul>
<ul>
<li>Hyperlink-Induced Topic Search (HITS) (also known as Hubs and authorities)</li>
<li>PageRank</li>
<li>TrustRank</li>
</ul>
<ul>
<li>Dinic's algorithm: is a strongly polynomial algorithm for computing the maximum flow in a flow network.</li>
<li>Edmonds–Karp algorithm: implementation of Ford–Fulkerson</li>
<li>Ford–Fulkerson algorithm: computes the maximum flow in a graph</li>
<li>Karger's algorithm: a Monte Carlo method to compute the minimum cut of a connected graph</li>
<li>Push–relabel algorithm: computes a maximum flow in a graph</li>
</ul>
<h4>Routing for graphs</h4>
<ul>
<li>Edmonds's algorithm (also known as Chu–Liu/Edmonds's algorithm): find maximum or minimum branchings</li>
<li>Euclidean minimum spanning tree: algorithms for computing the minimum spanning tree of a set of points in the plane</li>
<li>Euclidean shortest path problem: find the shortest path between two points that does not intersect any obstacle</li>
<li>Longest path problem: find a simple path of maximum length in a given graph</li>
<li>Minimum spanning tree
<ul>
<li>Borůvka's algorithm</li>
<li>Kruskal's algorithm</li>
<li>Prim's algorithm</li>
<li>Reverse-delete algorithm</li>
</ul>
</li>
<li>Nonblocking Minimal Spanning Switch say, for a telephone exchange</li>
<li>Shortest path problem
<ul>
<li>Bellman–Ford algorithm: computes shortest paths in a weighted graph (where some of the edge weights may be negative)</li>
<li>Dijkstra's algorithm: computes shortest paths in a graph with non-negative edge weights</li>
<li>Floyd–Warshall algorithm: solves the all pairs shortest path problem in a weighted, directed graph</li>
<li>Johnson algorithm: All pairs shortest path algorithm in sparse weighted directed graph</li>
</ul>
</li>
<li>Transitive closure problem: find the transitive closure of a given binary relation</li>
<li>Traveling salesman problem
<ul>
<li>Christofides algorithm</li>
<li>Nearest neighbour algorithm</li>
</ul>
</li>
<li>Warnsdorff's algorithm: A heuristic method for solving the Knight's Tour problem.</li>
</ul>
<ul>
<li>Borůvka's algorithm</li>
<li>Kruskal's algorithm</li>
<li>Prim's algorithm</li>
<li>Reverse-delete algorithm</li>
</ul>
<ul>
<li>Bellman–Ford algorithm: computes shortest paths in a weighted graph (where some of the edge weights may be negative)</li>
<li>Dijkstra's algorithm: computes shortest paths in a graph with non-negative edge weights</li>
<li>Floyd–Warshall algorithm: solves the all pairs shortest path problem in a weighted, directed graph</li>
<li>Johnson algorithm: All pairs shortest path algorithm in sparse weighted directed graph</li>
</ul>
<ul>
<li>Christofides algorithm</li>
<li>Nearest neighbour algorithm</li>
</ul>
<h4>Graph search</h4>
<ul>
<li>A*: special case of best-first search that uses heuristics to improve speed</li>
<li>B*: a best-first graph search algorithm that finds the least-cost path from a given initial node to any goal node (out of one or more possible goals)</li>
<li>Backtracking: abandon partial solutions when they are found not to satisfy a complete solution</li>
<li>Beam search: is a heuristic search algorithm that is an optimization of best-first search that reduces its memory requirement</li>
<li>Beam stack search: integrates backtracking with beam search</li>
<li>Best-first search: traverses a graph in the order of likely importance using a priority queue</li>
<li>Bidirectional search: find the shortest path from an initial vertex to a goal vertex in a directed graph</li>
<li>Bloom filter: a constant time and memory check to see whether a given element exists in a set. May return a false positive, but never a false negative.</li>
<li>Breadth-first search: traverses a graph level by level</li>
<li>D*: an incremental heuristic search algorithm</li>
<li>Depth-first search: traverses a graph branch by branch</li>
<li>Dijkstra's algorithm: A special case of A* for which no heuristic function is used</li>
<li>General Problem Solver: a seminal theorem-proving algorithm intended to work as a universal problem solver machine.</li>
<li>Iterative deepening depth-first search (IDDFS): a state space search strategy</li>
<li>Jump point search: An optimization to A* which may reduce computation time by an order of magnitude using further heuristics.</li>
<li>Lexicographic breadth-first search (also known as Lex-BFS): a linear time algorithm for ordering the vertices of a graph</li>
<li>Uniform-cost search: a tree search that finds the lowest cost route where costs vary</li>
<li>SSS*: state space search traversing a game tree in a best-first fashion similar to that of the A* search algorithm</li>
</ul>
<h4>Subgraphs</h4>
<ul>
<li>Bron–Kerbosch algorithm: a technique for finding maximal cliques in an undirected graph</li>
<li>Strongly connected components
<ul>
<li>Path-based strong component algorithm</li>
<li>Kosaraju's algorithm</li>
<li>Tarjan's strongly connected components algorithm</li>
</ul>
</li>
</ul>
<ul>
<li>Path-based strong component algorithm</li>
<li>Kosaraju's algorithm</li>
<li>Tarjan's strongly connected components algorithm</li>
</ul>
<h3>Sequence algorithms</h3>
<h4>Approximate sequence matching</h4>
<ul>
<li>Bitap algorithm: fuzzy algorithm that determines if strings are approximately equal.</li>
<li>Phonetic algorithms
<ul>
<li>Daitch–Mokotoff Soundex: a Soundex refinement which allows matching of Slavic and Germanic surnames</li>
<li>Double Metaphone: an improvement on Metaphone</li>
<li>Match Rating Approach: a phonetic algorithm developed by Western Airlines</li>
<li>Metaphone: an algorithm for indexing words by their sound, when pronounced in English</li>
<li>NYSIIS: phonetic algorithm, improves on Soundex</li>
<li>Soundex: a phonetic algorithm for indexing names by sound, as pronounced in English</li>
</ul>
</li>
<li>String metrics: compute a similarity or dissimilarity (distance) score between two pairs of text strings
<ul>
<li>Damerau–Levenshtein distance compute a distance measure between two strings, improves on Levenshtein distance</li>
<li>Dice's coefficient (also known as the Dice coefficient): a similarity measure related to the Jaccard index</li>
<li>Hamming distance: sum number of positions which are different</li>
<li>Jaro–Winkler distance: is a measure of similarity between two strings</li>
<li>Levenshtein edit distance: compute a metric for the amount of difference between two sequences</li>
</ul>
</li>
<li>Trigram search: search for text when the exact syntax or spelling of the target object is not precisely known</li>
</ul>
<ul>
<li>Daitch–Mokotoff Soundex: a Soundex refinement which allows matching of Slavic and Germanic surnames</li>
<li>Double Metaphone: an improvement on Metaphone</li>
<li>Match Rating Approach: a phonetic algorithm developed by Western Airlines</li>
<li>Metaphone: an algorithm for indexing words by their sound, when pronounced in English</li>
<li>NYSIIS: phonetic algorithm, improves on Soundex</li>
<li>Soundex: a phonetic algorithm for indexing names by sound, as pronounced in English</li>
</ul>
<ul>
<li>Damerau–Levenshtein distance compute a distance measure between two strings, improves on Levenshtein distance</li>
<li>Dice's coefficient (also known as the Dice coefficient): a similarity measure related to the Jaccard index</li>
<li>Hamming distance: sum number of positions which are different</li>
<li>Jaro–Winkler distance: is a measure of similarity between two strings</li>
<li>Levenshtein edit distance: compute a metric for the amount of difference between two sequences</li>
</ul>
<h4>Sequence search</h4>
<ul>
<li>Linear search: finds an item in an unsorted sequence</li>
<li>Selection algorithm: finds the <i>k</i>th largest item in a sequence</li>
<li>Ternary search: a technique for finding the minimum or maximum of a function that is either strictly increasing and then strictly decreasing or vice versa</li>
<li>Sorted lists
<ul>
<li>Binary search algorithm: locates an item in a sorted sequence</li>
<li>Fibonacci search technique: search a sorted sequence using a divide and conquer algorithm that narrows down possible locations with the aid of Fibonacci numbers</li>
<li>Jump search (or block search): linear search on a smaller subset of the sequence</li>
<li>Predictive search: binary-like search which factors in magnitude of search term versus the high and low values in the search. Sometimes called dictionary search or interpolated search.</li>
<li>Uniform binary search: an optimization of the classic binary search algorithm</li>
</ul>
</li>
</ul>
<ul>
<li>Binary search algorithm: locates an item in a sorted sequence</li>
<li>Fibonacci search technique: search a sorted sequence using a divide and conquer algorithm that narrows down possible locations with the aid of Fibonacci numbers</li>
<li>Jump search (or block search): linear search on a smaller subset of the sequence</li>
<li>Predictive search: binary-like search which factors in magnitude of search term versus the high and low values in the search. Sometimes called dictionary search or interpolated search.</li>
<li>Uniform binary search: an optimization of the classic binary search algorithm</li>
</ul>
<h4>Sequence merging</h4>
<ul>
<li>Simple merge algorithm</li>
<li>k-way merge algorithm</li>
<li>Union (merge, with elements on the output not repeated)</li>
</ul>
<h4>Sequence permutations</h4>
<ul>
<li>Fisher–Yates shuffle (also known as the Knuth shuffle): randomly shuffle a finite set</li>
<li>Schensted algorithm: constructs a pair of Young tableaux from a permutation</li>
<li>Steinhaus–Johnson–Trotter algorithm (also known as the Johnson–Trotter algorithm): generate permutations by transposing elements</li>
<li>Heap's permutation generation algorithm: interchange elements to generate next permutation</li>
</ul>
<h4>Sequence alignment</h4>
<ul>
<li>Dynamic time warping: measure similarity between two sequences which may vary in time or speed</li>
<li>Hirschberg's algorithm: finds the least cost sequence alignment between two sequences, as measured by their Levenshtein distance</li>
<li>Needleman–Wunsch algorithm: find global alignment between two sequences</li>
<li>Smith–Waterman algorithm: find local sequence alignment</li>
</ul>
<h4>Sequence sorting</h4>
<ul>
<li>Exchange Sorts
<ul>
<li>Bubble sort: for each pair of indices, swap the items if out of order</li>
<li>Cocktail sort</li>
<li>Comb sort</li>
<li>Gnome sort</li>
<li>Odd-even sort</li>
<li>Quicksort: divide list into two, with all items on the first list coming before all items on the second list.; then sort the two lists. Often the method of choice</li>
</ul>
</li>
<li>Humorous or ineffective
<ul>
<li>Bogosort</li>
<li>Stooge sort</li>
</ul>
</li>
<li>Hybrid
<ul>
<li>Flashsort</li>
<li>Introsort: begin with quicksort and switch to heapsort when the recursion depth exceeds a certain level</li>
<li>Timsort: adaptative algorithm derived from merge sort and insertion sort. Used in Python 2.3 and up, and Java SE 7.</li>
</ul>
</li>
<li>Insertion sorts
<ul>
<li>Insertion sort: determine where the current item belongs in the list of sorted ones, and insert it there</li>
<li>Library sort</li>
<li>Patience sorting</li>
<li>Shell sort: an attempt to improve insertion sort</li>
<li>Tree sort (binary tree sort): build binary tree, then traverse it to create sorted list</li>
<li>Cycle sort: in-place with theoretically optimal number of writes</li>
</ul>
</li>
<li>Merge sorts
<ul>
<li>Merge sort: sort the first and second half of the list separately, then merge the sorted lists</li>
<li>Strand sort</li>
</ul>
</li>
<li>Non-comparison sorts
<ul>
<li>Bead sort</li>
<li>Bucket sort</li>
<li>Burstsort: build a compact, cache efficient burst trie and then traverse it to create sorted output</li>
<li>Counting sort</li>
<li>Pigeonhole sort</li>
<li>Postman sort: variant of Bucket sort which takes advantage of hierarchical structure</li>
<li>Radix sort: sorts strings letter by letter</li>
</ul>
</li>
<li>Selection sorts
<ul>
<li>Heapsort: convert the list into a heap, keep removing the largest element from the heap and adding it to the end of the list</li>
<li>Selection sort: pick the smallest of the remaining elements, add it to the end of the sorted list</li>
<li>Smoothsort</li>
</ul>
</li>
<li>Other
<ul>
<li>Bitonic sorter</li>
<li>Pancake sorting</li>
<li>Topological sort</li>
</ul>
</li>
<li>Unknown class
<ul>
<li>Samplesort</li>
</ul>
</li>
</ul>
<ul>
<li>Bubble sort: for each pair of indices, swap the items if out of order</li>
<li>Cocktail sort</li>
<li>Comb sort</li>
<li>Gnome sort</li>
<li>Odd-even sort</li>
<li>Quicksort: divide list into two, with all items on the first list coming before all items on the second list.; then sort the two lists. Often the method of choice</li>
</ul>
<ul>
<li>Bogosort</li>
<li>Stooge sort</li>
</ul>
<ul>
<li>Flashsort</li>
<li>Introsort: begin with quicksort and switch to heapsort when the recursion depth exceeds a certain level</li>
<li>Timsort: adaptative algorithm derived from merge sort and insertion sort. Used in Python 2.3 and up, and Java SE 7.</li>
</ul>
<ul>
<li>Insertion sort: determine where the current item belongs in the list of sorted ones, and insert it there</li>
<li>Library sort</li>
<li>Patience sorting</li>
<li>Shell sort: an attempt to improve insertion sort</li>
<li>Tree sort (binary tree sort): build binary tree, then traverse it to create sorted list</li>
<li>Cycle sort: in-place with theoretically optimal number of writes</li>
</ul>
<ul>
<li>Merge sort: sort the first and second half of the list separately, then merge the sorted lists</li>
<li>Strand sort</li>
</ul>
<ul>
<li>Bead sort</li>
<li>Bucket sort</li>
<li>Burstsort: build a compact, cache efficient burst trie and then traverse it to create sorted output</li>
<li>Counting sort</li>
<li>Pigeonhole sort</li>
<li>Postman sort: variant of Bucket sort which takes advantage of hierarchical structure</li>
<li>Radix sort: sorts strings letter by letter</li>
</ul>
<ul>
<li>Heapsort: convert the list into a heap, keep removing the largest element from the heap and adding it to the end of the list</li>
<li>Selection sort: pick the smallest of the remaining elements, add it to the end of the sorted list</li>
<li>Smoothsort</li>
</ul>
<ul>
<li>Bitonic sorter</li>
<li>Pancake sorting</li>
<li>Topological sort</li>
</ul>
<ul>
<li>Samplesort</li>
</ul>
<h4>Subsequences</h4>
<ul>
<li>Kadane's algorithm: finds maximum sub-array of any size</li>
<li>Longest common subsequence problem: Find the longest subsequence common to all sequences in a set of sequences</li>
<li>Longest increasing subsequence problem: find the longest increasing subsequence of a given sequence</li>
<li>Shortest common supersequence problem: Find the shortest supersequence that contains two or more sequences as subsequences</li>
</ul>
<h4>Substrings</h4>
<ul>
<li>Longest common substring problem: find the longest string (or strings) that is a substring (or are substrings) of two or more strings</li>
<li>Substring search
<ul>
<li>Aho–Corasick string matching algorithm: trie based algorithm for finding all substring matches to any of a finite set of strings</li>
<li>Boyer–Moore string search algorithm: amortized linear (sublinear in most times) algorithm for substring search</li>
<li>Boyer–Moore–Horspool algorithm: Simplification of Boyer–Moore</li>
<li>Knuth–Morris–Pratt algorithm: substring search which bypasses reexamination of matched characters</li>
<li>Rabin–Karp string search algorithm: searches multiple patterns efficiently</li>
<li>Zhu–Takaoka string matching algorithm: a variant of the Boyer–Moore</li>
</ul>
</li>
<li>Ukkonen's algorithm: a linear-time, online algorithm for constructing suffix trees</li>
</ul>
<ul>
<li>Aho–Corasick string matching algorithm: trie based algorithm for finding all substring matches to any of a finite set of strings</li>
<li>Boyer–Moore string search algorithm: amortized linear (sublinear in most times) algorithm for substring search</li>
<li>Boyer–Moore–Horspool algorithm: Simplification of Boyer–Moore</li>
<li>Knuth–Morris–Pratt algorithm: substring search which bypasses reexamination of matched characters</li>
<li>Rabin–Karp string search algorithm: searches multiple patterns efficiently</li>
<li>Zhu–Takaoka string matching algorithm: a variant of the Boyer–Moore</li>
</ul>
<h2>Computational mathematics</h2>
<h3>Abstract algebra</h3>
<ul>
<li>Chien search: a recursive algorithm for determining roots of polynomials defined over a finite field</li>
<li>Schreier–Sims algorithm: computing a base and strong generating set (BSGS) of a permutation group</li>
<li>Todd–Coxeter algorithm: Procedure for generating cosets.</li>
</ul>
<h3>Computer algebra</h3>
<ul>
<li>Buchberger's algorithm: finds a Gröbner basis</li>
<li>Cantor–Zassenhaus algorithm: factor polynomials over finite fields</li>
<li>Faugère F4 algorithm: finds a Gröbner basis (also mentions the F5 algorithm)</li>
<li>Gosper's algorithm: find sums of hypergeometric terms that are themselves hypergeometric terms</li>
<li>Knuth–Bendix completion algorithm: for rewriting rule systems</li>
<li>Multivariate division algorithm: for polynomials in several indeterminates</li>
<li>Pollard's kangaroo algorithm (also known as Pollard's lambda algorithm ): an algorithm for solving the discrete logarithm problem</li>
<li>Polynomial long division: an algorithm for dividing a polynomial by another polynomial of the same or lower degree</li>
<li>Risch algorithm: an algorithm for the calculus operation of indefinite integration (i.e. finding antiderivatives)</li>
</ul>
<h3>Geometry</h3>
<ul>
<li>Closest pair problem: find the pair of points (from a set of points) with the smallest distance between them</li>
<li>Collision detection algorithms: check for the collision or intersection of two given solids</li>
<li>Cone algorithm: identify surface points</li>
<li>Convex hull algorithms: determining the convex hull of a set of points
<ul>
<li>Graham scan</li>
<li>QuickHull</li>
<li>Gift wrapping algorithm or Jarvis march</li>
<li>Chan's algorithm</li>
<li>Kirkpatrick–Seidel algorithm</li>
</ul>
</li>
<li>Euclidean Distance Transform - Computes the distance between every point in a grid and a discrete collection of points.</li>
<li>Geometric hashing: a method for efficiently finding two-dimensional objects represented by discrete points that have undergone an affine transformation</li>
<li>Gilbert–Johnson–Keerthi distance algorithm: determining the smallest distance between two convex shapes.</li>
<li>Jump-and-Walk algorithm: an algorithm for point location in triangulations</li>
<li>Laplacian smoothing: an algorithm to smooth a polygonal mesh</li>
<li>Line segment intersection: finding whether lines intersect, usually with a sweep line algorithm
<ul>
<li>Bentley–Ottmann algorithm</li>
<li>Shamos–Hoey algorithm</li>
</ul>
</li>
<li>Minimum bounding box algorithms: find the oriented minimum bounding box enclosing a set of points</li>
<li>Nearest neighbor search: find the nearest point or points to a query point</li>
<li>Point in polygon algorithms: tests whether a given point lies within a given polygon</li>
<li>Point set registration algorithms: finds the transformation between two point sets to optimally align them.</li>
<li>Rotating calipers: determine all antipodal pairs of points and vertices on a convex polygon or convex hull.</li>
<li>Shoelace algorithm: determine the area of a polygon whose vertices are described by ordered pairs in the plane</li>
<li>Triangulation
<ul>
<li>Delaunay triangulation
<ul>
<li>Ruppert's algorithm (also known as Delaunay refinement): create quality Delaunay triangulations</li>
<li>Chew's second algorithm: create quality constrained Delaunay triangulations</li>
</ul>
</li>
<li>Marching triangles: reconstruct two-dimensional surface geometry from an unstructured point cloud</li>
<li>Polygon triangulation algorithms: decompose a polygon into a set of triangles</li>
<li>Voronoi diagrams, geometric dual of Delaunay triangulation
<ul>
<li>Bowyer–Watson algorithm: create voronoi diagram in any number of dimensions</li>
<li>Fortune's Algorithm: create voronoi diagram</li>
</ul>
</li>
<li>Quasitriangulation</li>
</ul>
</li>
</ul>
<ul>
<li>Graham scan</li>
<li>QuickHull</li>
<li>Gift wrapping algorithm or Jarvis march</li>
<li>Chan's algorithm</li>
<li>Kirkpatrick–Seidel algorithm</li>
</ul>
<ul>
<li>Bentley–Ottmann algorithm</li>
<li>Shamos–Hoey algorithm</li>
</ul>
<ul>
<li>Delaunay triangulation
<ul>
<li>Ruppert's algorithm (also known as Delaunay refinement): create quality Delaunay triangulations</li>
<li>Chew's second algorithm: create quality constrained Delaunay triangulations</li>
</ul>
</li>
<li>Marching triangles: reconstruct two-dimensional surface geometry from an unstructured point cloud</li>
<li>Polygon triangulation algorithms: decompose a polygon into a set of triangles</li>
<li>Voronoi diagrams, geometric dual of Delaunay triangulation
<ul>
<li>Bowyer–Watson algorithm: create voronoi diagram in any number of dimensions</li>
<li>Fortune's Algorithm: create voronoi diagram</li>
</ul>
</li>
<li>Quasitriangulation</li>
</ul>
<ul>
<li>Ruppert's algorithm (also known as Delaunay refinement): create quality Delaunay triangulations</li>
<li>Chew's second algorithm: create quality constrained Delaunay triangulations</li>
</ul>
<ul>
<li>Bowyer–Watson algorithm: create voronoi diagram in any number of dimensions</li>
<li>Fortune's Algorithm: create voronoi diagram</li>
</ul>
<h3>Number theoretic algorithms</h3>
<ul>
<li>Binary GCD algorithm: Efficient way of calculating GCD.</li>
<li>Booth's multiplication algorithm</li>
<li>Chakravala method: a cyclic algorithm to solve indeterminate quadratic equations, including Pell's equation</li>
<li>Discrete logarithm:
<ul>
<li>Baby-step giant-step</li>
<li>Index calculus algorithm</li>
<li>Pollard's rho algorithm for logarithms</li>
<li>Pohlig–Hellman algorithm</li>
</ul>
</li>
<li>Euclidean algorithm: computes the greatest common divisor</li>
<li>Extended Euclidean algorithm: Also solves the equation <i>ax</i> + <i>by</i> = <i>c</i>.</li>
<li>Integer factorization: breaking an integer into its prime factors
<ul>
<li>Congruence of squares</li>
<li>Dixon's algorithm</li>
<li>Fermat's factorization method</li>
<li>General number field sieve</li>
<li>Lenstra elliptic curve factorization</li>
<li>Pollard's <i>p</i> − 1 algorithm</li>
<li>Pollard's rho algorithm</li>
<li>prime factorization algorithm</li>
<li>Quadratic sieve</li>
<li>Shor's algorithm</li>
<li>Special number field sieve</li>
<li>Trial division</li>
</ul>
</li>
<li>Multiplication algorithms: fast multiplication of two numbers
<ul>
<li>Karatsuba algorithm</li>
<li>Schönhage–Strassen algorithm</li>
<li>Toom–Cook multiplication</li>
</ul>
</li>
<li>Odlyzko–Schönhage algorithm: calculates nontrivial zeroes of the Riemann zeta function</li>
<li>Primality tests: determining whether a given number is prime
<ul>
<li>AKS primality test</li>
<li>Baillie-PSW primality test</li>
<li>Fermat primality test</li>
<li>Lucas primality test</li>
<li>Miller–Rabin primality test</li>
<li>Sieve of Atkin</li>
<li>Sieve of Eratosthenes</li>
<li>Sieve of Sundaram</li>
</ul>
</li>
</ul>
<ul>
<li>Baby-step giant-step</li>
<li>Index calculus algorithm</li>
<li>Pollard's rho algorithm for logarithms</li>
<li>Pohlig–Hellman algorithm</li>
</ul>
<ul>
<li>Congruence of squares</li>
<li>Dixon's algorithm</li>
<li>Fermat's factorization method</li>
<li>General number field sieve</li>
<li>Lenstra elliptic curve factorization</li>
<li>Pollard's <i>p</i> − 1 algorithm</li>
<li>Pollard's rho algorithm</li>
<li>prime factorization algorithm</li>
<li>Quadratic sieve</li>
<li>Shor's algorithm</li>
<li>Special number field sieve</li>
<li>Trial division</li>
</ul>
<ul>
<li>Karatsuba algorithm</li>
<li>Schönhage–Strassen algorithm</li>
<li>Toom–Cook multiplication</li>
</ul>
<ul>
<li>AKS primality test</li>
<li>Baillie-PSW primality test</li>
<li>Fermat primality test</li>
<li>Lucas primality test</li>
<li>Miller–Rabin primality test</li>
<li>Sieve of Atkin</li>
<li>Sieve of Eratosthenes</li>
<li>Sieve of Sundaram</li>
</ul>
<h3>Numerical algorithms</h3>
<h4>Differential equation solving</h4>
<ul>
<li>Euler method</li>
<li>Backward Euler method</li>
<li>Trapezoidal rule (differential equations)</li>
</ul>
<ul>
<li>Linear multistep methods</li>
<li>Runge–Kutta methods
<ul>
<li>Euler integration</li>
</ul>
</li>
<li>Multigrid methods (MG methods), a group of algorithms for solving differential equations using a hierarchy of discretizations</li>
<li>Partial differential equation:
<ul>
<li>Finite difference method</li>
<li>Crank-Nicolson method for diffusion equations</li>
<li>Lax-Wendroff for wave equations</li>
</ul>
</li>
<li>Verlet integration (<small>French pronunciation: ​</small>[vɛʁˈlɛ]): integrate Newton's equations of motion</li>
</ul>
<ul>
<li>Euler integration</li>
</ul>
<ul>
<li>Finite difference method</li>
<li>Crank-Nicolson method for diffusion equations</li>
<li>Lax-Wendroff for wave equations</li>
</ul>
<h4>Elementary and special functions</h4>
<ul>
<li>Computation of π:
<ul>
<li>Borwein's algorithm: an algorithm to calculate the value of 1/π</li>
<li>Gauss–Legendre algorithm: computes the digits of pi</li>
<li>Bailey–Borwein–Plouffe formula: (BBP formula) a spigot algorithm for the computation of the nth binary digit of π</li>
</ul>
</li>
<li>Division algorithms: for computing quotient and/or remainder of two numbers
<ul>
<li>Long division</li>
<li>Restoring division</li>
<li>Non-restoring division</li>
<li>SRT division</li>
<li>Newton–Raphson division: uses Newton's method to find the reciprocal of D, and multiply that reciprocal by N to find the final quotient Q.</li>
<li>Goldschmidt division</li>
</ul>
</li>
<li>Hyperbolic and Trigonometric Functions:
<ul>
<li>BKM algorithm: compute elementary functions using a table of logarithms</li>
<li>CORDIC: compute hyperbolic and trigonometric functions using a table of arctangents</li>
</ul>
</li>
<li>Exponentiation:
<ul>
<li>Addition-chain exponentiation exponentiation by positive integer powers that requires a minimal number of multiplications</li>
<li>Exponentiating by squaring: an algorithm used for the fast computation of large integer powers of a number</li>
</ul>
</li>
<li>Montgomery reduction: an algorithm that allows modular arithmetic to be performed efficiently when the modulus is large</li>
<li>Multiplication algorithms: fast multiplication of two numbers
<ul>
<li>Booth's multiplication algorithm: a multiplication algorithm that multiplies two signed binary numbers in two's complement notation</li>
<li>Fürer's algorithm: an integer multiplication algorithm for very large numbers possessing a very low asymptotic complexity</li>
<li>Karatsuba algorithm: an efficient procedure for multiplying large numbers</li>
<li>Schönhage–Strassen algorithm: an asymptotically fast multiplication algorithm for large integers</li>
<li>Toom–Cook multiplication: (Toom3) a multiplication algorithm for large integers</li>
</ul>
</li>
<li>Multiplicative inverse Algorithms: for computing a number's multiplicative inverse (reciprocal).
<ul>
<li>Newton's method</li>
</ul>
</li>
<li>Rounding functions: the classic ways to round numbers</li>
<li>Spigot algorithm: A way to compute the value of a mathematical constant without knowing preceding digits</li>
<li>Square and Nth root of a number:
<ul>
<li>Alpha max plus beta min algorithm: an approximation of the square-root of the sum of two squares</li>
<li>Methods of computing square roots</li>
<li><i>n</i>th root algorithm</li>
<li>Shifting nth-root algorithm: digit by digit root extraction</li>
</ul>
</li>
<li>Summation:
<ul>
<li>Binary splitting: a divide and conquer technique which speeds up the numerical evaluation of many types of series with rational terms</li>
<li>Kahan summation algorithm: a more accurate method of summing floating-point numbers</li>
</ul>
</li>
</ul>
<ul>
<li>Borwein's algorithm: an algorithm to calculate the value of 1/π</li>
<li>Gauss–Legendre algorithm: computes the digits of pi</li>
<li>Bailey–Borwein–Plouffe formula: (BBP formula) a spigot algorithm for the computation of the nth binary digit of π</li>
</ul>
<ul>
<li>Long division</li>
<li>Restoring division</li>
<li>Non-restoring division</li>
<li>SRT division</li>
<li>Newton–Raphson division: uses Newton's method to find the reciprocal of D, and multiply that reciprocal by N to find the final quotient Q.</li>
<li>Goldschmidt division</li>
</ul>
<ul>
<li>BKM algorithm: compute elementary functions using a table of logarithms</li>
<li>CORDIC: compute hyperbolic and trigonometric functions using a table of arctangents</li>
</ul>
<ul>
<li>Addition-chain exponentiation exponentiation by positive integer powers that requires a minimal number of multiplications</li>
<li>Exponentiating by squaring: an algorithm used for the fast computation of large integer powers of a number</li>
</ul>
<ul>
<li>Booth's multiplication algorithm: a multiplication algorithm that multiplies two signed binary numbers in two's complement notation</li>
<li>Fürer's algorithm: an integer multiplication algorithm for very large numbers possessing a very low asymptotic complexity</li>
<li>Karatsuba algorithm: an efficient procedure for multiplying large numbers</li>
<li>Schönhage–Strassen algorithm: an asymptotically fast multiplication algorithm for large integers</li>
<li>Toom–Cook multiplication: (Toom3) a multiplication algorithm for large integers</li>
</ul>
<ul>
<li>Newton's method</li>
</ul>
<ul>
<li>Alpha max plus beta min algorithm: an approximation of the square-root of the sum of two squares</li>
<li>Methods of computing square roots</li>
<li><i>n</i>th root algorithm</li>
<li>Shifting nth-root algorithm: digit by digit root extraction</li>
</ul>
<ul>
<li>Binary splitting: a divide and conquer technique which speeds up the numerical evaluation of many types of series with rational terms</li>
<li>Kahan summation algorithm: a more accurate method of summing floating-point numbers</li>
</ul>
<h4>Geometric</h4>
<ul>
<li>Filtered back-projection: efficiently compute the inverse 2-dimensional Radon transform.</li>
<li>Level set method (LSM): a numerical technique for tracking interfaces and shapes</li>
</ul>
<h4>Interpolation and extrapolation</h4>
<ul>
<li>Birkhoff interpolation: an extension of polynomial interpolation</li>
<li>Cubic interpolation</li>
<li>Hermite interpolation</li>
<li>Lagrange interpolation: interpolation using Lagrange polynomials</li>
<li>Linear interpolation: a method of curve fitting using linear polynomials</li>
<li>Monotone cubic interpolation: a variant of cubic interpolation that preserves monotonicity of the data set being interpolated.</li>
<li>Multivariate interpolation
<ul>
<li>Bicubic interpolation, a generalization of cubic interpolation to two dimensions</li>
<li>Bilinear interpolation: an extension of linear interpolation for interpolating functions of two variables on a regular grid</li>
<li>Lanczos resampling ("Lanzosh"): a multivariate interpolation method used to compute new values for any digitally sampled data</li>
<li>Nearest-neighbor interpolation</li>
<li>Tricubic interpolation, a generalization of cubic interpolation to three dimensions</li>
</ul>
</li>
<li>Pareto interpolation: a method of estimating the median and other properties of a population that follows a Pareto distribution.</li>
<li>Polynomial interpolation
<ul>
<li>Neville's algorithm</li>
</ul>
</li>
<li>Spline interpolation: Reduces error with Runge's phenomenon.
<ul>
<li>De Boor algorithm: B-splines</li>
<li>De Casteljau's algorithm: Bézier curves</li>
</ul>
</li>
<li>Trigonometric interpolation</li>
</ul>
<ul>
<li>Bicubic interpolation, a generalization of cubic interpolation to two dimensions</li>
<li>Bilinear interpolation: an extension of linear interpolation for interpolating functions of two variables on a regular grid</li>
<li>Lanczos resampling ("Lanzosh"): a multivariate interpolation method used to compute new values for any digitally sampled data</li>
<li>Nearest-neighbor interpolation</li>
<li>Tricubic interpolation, a generalization of cubic interpolation to three dimensions</li>
</ul>
<ul>
<li>Neville's algorithm</li>
</ul>
<ul>
<li>De Boor algorithm: B-splines</li>
<li>De Casteljau's algorithm: Bézier curves</li>
</ul>
<h4>Linear algebra</h4>
<ul>
<li>Eigenvalue algorithms
<ul>
<li>Arnoldi iteration</li>
<li>Inverse iteration</li>
<li>Jacobi method</li>
<li>Lanczos iteration</li>
<li>Power iteration</li>
<li>QR algorithm</li>
<li>Rayleigh quotient iteration</li>
</ul>
</li>
<li>Gram–Schmidt process: orthogonalizes a set of vectors</li>
<li>Matrix multiplication
<ul>
<li>Cannon's algorithm: a distributed algorithm for matrix multiplication especially suitable for computers laid out in an N × N mesh</li>
<li>Coppersmith–Winograd algorithm: square matrix multiplication</li>
<li>Freivalds' algorithm: a randomized algorithm used to verify matrix multiplication</li>
<li>Strassen algorithm: faster matrix multiplication</li>
</ul>
</li>
<li>Solving systems of linear equations
<ul>
<li>Biconjugate gradient method: solves systems of linear equations</li>
<li>Conjugate gradient: an algorithm for the numerical solution of particular systems of linear equations</li>
<li>Gaussian elimination</li>
<li>Gauss–Jordan elimination: solves systems of linear equations</li>
<li>Gauss–Seidel method: solves systems of linear equations iteratively</li>
<li>Levinson recursion: solves equation involving a Toeplitz matrix</li>
<li>Stone's method: also known as the strongly implicit procedure or SIP, is an algorithm for solving a sparse linear system of equations</li>
<li>Successive over-relaxation (SOR): method used to speed up convergence of the Gauss–Seidel method</li>
<li>Tridiagonal matrix algorithm (Thomas algorithm): solves systems of tridiagonal equations</li>
</ul>
</li>
<li>Sparse matrix algorithms
<ul>
<li>Cuthill–McKee algorithm: reduce the bandwidth of sparse symmetric matrices</li>
<li>Minimum degree algorithm: permute the rows and columns of a symmetric sparse matrix before applying the Cholesky decomposition</li>
<li>Symbolic Cholesky decomposition: Efficient way of storing sparse matrix</li>
</ul>
</li>
</ul>
<ul>
<li>Arnoldi iteration</li>
<li>Inverse iteration</li>
<li>Jacobi method</li>
<li>Lanczos iteration</li>
<li>Power iteration</li>
<li>QR algorithm</li>
<li>Rayleigh quotient iteration</li>
</ul>
<ul>
<li>Cannon's algorithm: a distributed algorithm for matrix multiplication especially suitable for computers laid out in an N × N mesh</li>
<li>Coppersmith–Winograd algorithm: square matrix multiplication</li>
<li>Freivalds' algorithm: a randomized algorithm used to verify matrix multiplication</li>
<li>Strassen algorithm: faster matrix multiplication</li>
</ul>
<ul>
<li>Biconjugate gradient method: solves systems of linear equations</li>
<li>Conjugate gradient: an algorithm for the numerical solution of particular systems of linear equations</li>
<li>Gaussian elimination</li>
<li>Gauss–Jordan elimination: solves systems of linear equations</li>
<li>Gauss–Seidel method: solves systems of linear equations iteratively</li>
<li>Levinson recursion: solves equation involving a Toeplitz matrix</li>
<li>Stone's method: also known as the strongly implicit procedure or SIP, is an algorithm for solving a sparse linear system of equations</li>
<li>Successive over-relaxation (SOR): method used to speed up convergence of the Gauss–Seidel method</li>
<li>Tridiagonal matrix algorithm (Thomas algorithm): solves systems of tridiagonal equations</li>
</ul>
<ul>
<li>Cuthill–McKee algorithm: reduce the bandwidth of sparse symmetric matrices</li>
<li>Minimum degree algorithm: permute the rows and columns of a symmetric sparse matrix before applying the Cholesky decomposition</li>
<li>Symbolic Cholesky decomposition: Efficient way of storing sparse matrix</li>
</ul>
<h4>Monte Carlo</h4>
<ul>
<li>Gibbs sampling: generate a sequence of samples from the joint probability distribution of two or more random variables</li>
<li>Metropolis–Hastings algorithm: used to generate a sequence of samples from the probability distribution of one or more variables</li>
<li>Wang and Landau algorithm: an extension of Metropolis–Hastings algorithm sampling</li>
</ul>
<h4>Numerical integration</h4>
<ul>
<li>MISER algorithm: Monte Carlo simulation, numerical integration</li>
</ul>
<h4>Root finding</h4>
<ul>
<li>Bisection method</li>
<li>False position method: approximates roots of a function</li>
<li>Newton's method: finds zeros of functions with calculus</li>
<li>Halley's method: uses first and second derivatives</li>
<li>Secant method: 2-point, 1-sided</li>
<li>False position method and Illinois method: 2-point, bracketing</li>
<li>Ridder's method: 3-point, exponential scaling</li>
<li>Muller's method: 3-point, quadratic intepolation</li>
</ul>
<h3>Optimization algorithms</h3>
<ul>
<li>Alpha-beta pruning: search to reduce number of nodes in minimax algorithm</li>
<li>Branch and bound</li>
<li>Bruss algorithm: see odds algorithm</li>
<li>Chain matrix multiplication</li>
<li>Combinatorial optimization: optimization problems where the set of feasible solutions is discrete
<ul>
<li>Greedy randomized adaptive search procedure (GRASP): successive constructions of a greedy randomized solution and subsequent iterative improvements of it through a local search</li>
<li>Hungarian method: a combinatorial optimization algorithm which solves the assignment problem in polynomial time</li>
</ul>
</li>
<li>Constraint satisfaction
<ul>
<li>General algorithms for the constraint satisfaction
<ul>
<li>AC-3 algorithm</li>
<li>Difference map algorithm</li>
<li>Min conflicts algorithm</li>
</ul>
</li>
<li>Chaff algorithm: an algorithm for solving instances of the boolean satisfiability problem</li>
<li>Davis–Putnam algorithm: check the validity of a first-order logic formula</li>
<li>Davis–Putnam–Logemann–Loveland algorithm (DPLL): an algorithm for deciding the satisfiability of propositional logic formula in conjunctive normal form, i.e. for solving the CNF-SAT problem</li>
<li>Exact cover problem
<ul>
<li>Algorithm X: a nondeterministic algorithm</li>
<li>Dancing Links: an efficient implementation of Algorithm X</li>
</ul>
</li>
</ul>
</li>
<li>Cross-entropy method: a general Monte Carlo approach to combinatorial and continuous multi-extremal optimization and importance sampling</li>
<li>Differential evolution</li>
<li>Dynamic Programming: problems exhibiting the properties of overlapping subproblems and optimal substructure</li>
<li>Ellipsoid method: is an algorithm for solving convex optimization problems</li>
<li>Evolutionary computation: optimization inspired by biological mechanisms of evolution
<ul>
<li>Evolution strategy</li>
<li>Gene expression programming</li>
<li>Genetic algorithms
<ul>
<li>Fitness proportionate selection - also known as roulette-wheel selection</li>
<li>Stochastic universal sampling</li>
<li>Truncation selection</li>
<li>Tournament selection</li>
</ul>
</li>
<li>Memetic algorithm</li>
<li>Swarm intelligence
<ul>
<li>Ant colony optimization</li>
<li>Bees algorithm: a search algorithm which mimics the food foraging behavior of swarms of honey bees</li>
<li>Particle swarm</li>
</ul>
</li>
</ul>
</li>
<li>Gradient descent</li>
<li>Harmony search (HS): a metaheuristic algorithm mimicking the improvisation process of musicians</li>
<li>Interior point method</li>
<li>Linear programming
<ul>
<li>Benson's algorithm: an algorithm for solving linear vector optimization problems</li>
<li>Dantzig–Wolfe decomposition: an algorithm for solving linear programming problems with special structure</li>
<li>Delayed column generation</li>
<li>Integer linear programming: solve linear programming problems where some or all the unknowns are restricted to integer values
<ul>
<li>Branch and cut</li>
<li>Cutting-plane method</li>
</ul>
</li>
<li>Karmarkar's algorithm: The first reasonably efficient algorithm that solves the linear programming problem in polynomial time.</li>
<li>Simplex algorithm: An algorithm for solving linear programming problems</li>
</ul>
</li>
<li>Line search</li>
<li>Local search: a metaheuristic for solving computationally hard optimization problems
<ul>
<li>Random-restart hill climbing</li>
<li>Tabu search</li>
</ul>
</li>
<li>Minimax used in game programming</li>
<li>Nearest neighbor search (NNS): find closest points in a metric space
<ul>
<li>Best Bin First: find an approximate solution to the Nearest neighbor search problem in very-high-dimensional spaces</li>
</ul>
</li>
<li>Newton's method in optimization</li>
<li>Nonlinear optimization
<ul>
<li>BFGS method: A nonlinear optimization algorithm</li>
<li>Gauss–Newton algorithm: An algorithm for solving nonlinear least squares problems.</li>
<li>Levenberg–Marquardt algorithm: An algorithm for solving nonlinear least squares problems.</li>
<li>Nelder–Mead method (downhill simplex method): A nonlinear optimization algorithm</li>
</ul>
</li>
<li>Odds algorithm (Bruss algorithm) : Finds the optimal strategy to predict a last specific event in a random sequence event</li>
<li>Simulated annealing</li>
<li>Stochastic tunneling</li>
<li>Subset sum algorithm</li>
</ul>
<ul>
<li>Greedy randomized adaptive search procedure (GRASP): successive constructions of a greedy randomized solution and subsequent iterative improvements of it through a local search</li>
<li>Hungarian method: a combinatorial optimization algorithm which solves the assignment problem in polynomial time</li>
</ul>
<ul>
<li>General algorithms for the constraint satisfaction
<ul>
<li>AC-3 algorithm</li>
<li>Difference map algorithm</li>
<li>Min conflicts algorithm</li>
</ul>
</li>
<li>Chaff algorithm: an algorithm for solving instances of the boolean satisfiability problem</li>
<li>Davis–Putnam algorithm: check the validity of a first-order logic formula</li>
<li>Davis–Putnam–Logemann–Loveland algorithm (DPLL): an algorithm for deciding the satisfiability of propositional logic formula in conjunctive normal form, i.e. for solving the CNF-SAT problem</li>
<li>Exact cover problem
<ul>
<li>Algorithm X: a nondeterministic algorithm</li>
<li>Dancing Links: an efficient implementation of Algorithm X</li>
</ul>
</li>
</ul>
<ul>
<li>AC-3 algorithm</li>
<li>Difference map algorithm</li>
<li>Min conflicts algorithm</li>
</ul>
<ul>
<li>Algorithm X: a nondeterministic algorithm</li>
<li>Dancing Links: an efficient implementation of Algorithm X</li>
</ul>
<ul>
<li>Evolution strategy</li>
<li>Gene expression programming</li>
<li>Genetic algorithms
<ul>
<li>Fitness proportionate selection - also known as roulette-wheel selection</li>
<li>Stochastic universal sampling</li>
<li>Truncation selection</li>
<li>Tournament selection</li>
</ul>
</li>
<li>Memetic algorithm</li>
<li>Swarm intelligence
<ul>
<li>Ant colony optimization</li>
<li>Bees algorithm: a search algorithm which mimics the food foraging behavior of swarms of honey bees</li>
<li>Particle swarm</li>
</ul>
</li>
</ul>
<ul>
<li>Fitness proportionate selection - also known as roulette-wheel selection</li>
<li>Stochastic universal sampling</li>
<li>Truncation selection</li>
<li>Tournament selection</li>
</ul>
<ul>
<li>Ant colony optimization</li>
<li>Bees algorithm: a search algorithm which mimics the food foraging behavior of swarms of honey bees</li>
<li>Particle swarm</li>
</ul>
<ul>
<li>Benson's algorithm: an algorithm for solving linear vector optimization problems</li>
<li>Dantzig–Wolfe decomposition: an algorithm for solving linear programming problems with special structure</li>
<li>Delayed column generation</li>
<li>Integer linear programming: solve linear programming problems where some or all the unknowns are restricted to integer values
<ul>
<li>Branch and cut</li>
<li>Cutting-plane method</li>
</ul>
</li>
<li>Karmarkar's algorithm: The first reasonably efficient algorithm that solves the linear programming problem in polynomial time.</li>
<li>Simplex algorithm: An algorithm for solving linear programming problems</li>
</ul>
<ul>
<li>Branch and cut</li>
<li>Cutting-plane method</li>
</ul>
<ul>
<li>Random-restart hill climbing</li>
<li>Tabu search</li>
</ul>
<ul>
<li>Best Bin First: find an approximate solution to the Nearest neighbor search problem in very-high-dimensional spaces</li>
</ul>
<ul>
<li>BFGS method: A nonlinear optimization algorithm</li>
<li>Gauss–Newton algorithm: An algorithm for solving nonlinear least squares problems.</li>
<li>Levenberg–Marquardt algorithm: An algorithm for solving nonlinear least squares problems.</li>
<li>Nelder–Mead method (downhill simplex method): A nonlinear optimization algorithm</li>
</ul>
<h2>Computational science</h2>
<h3>Astronomy</h3>
<ul>
<li>Doomsday algorithm: day of the week</li>
<li>Zeller's congruence is an algorithm to calculate the day of the week for any Julian or Gregorian calendar date</li>
<li>various Easter algorithms are used to calculate the day of Easter</li>
</ul>
<h3>Bioinformatics</h3>
<ul>
<li>Basic Local Alignment Search Tool also known as BLAST: an algorithm for comparing primary biological sequence information</li>
<li>Kabsch algorithm: calculate the optimal alignment of two sets of points in order to compute the root mean squared deviation between two protein structures.</li>
<li>Velvet: a set of algorithms manipulating de Bruijn graphs for genomic sequence assembly</li>
<li>Sorting by signed reversals: an algorithm for understanding genomic evolution.</li>
<li>Maximum parsimony (phylogenetics): an algorithm for finding the simplest phylogenetic tree to explain a given character matrix.</li>
<li>UPGMA: a distance-based phylogentic tree construction algorithm.</li>
</ul>
<h3>Geoscience</h3>
<ul>
<li>Vincenty's formulae: a fast algorithm to calculate the distance between two latitude/longitude points on an ellipsoid</li>
</ul>
<h3>Linguistics</h3>
<ul>
<li>Lesk algorithm: word sense disambiguation</li>
<li>Stemming algorithm: a method of reducing words to their stem, base, or root form</li>
<li>Sukhotin's algorithm: a statistical classification algorithm for classifying characters in a text as vowels or consonants</li>
</ul>
<h3>Medicine</h3>
<ul>
<li>ESC algorithm for the diagnosis of heart failure</li>
<li>Manning Criteria for irritable bowel syndrome</li>
<li>Pulmonary embolism diagnostic algorithms</li>
<li>Texas Medication Algorithm Project</li>
</ul>
<h3>Physics</h3>
<ul>
<li>Constraint algorithm: a class of algorithms for satisfying constraints for bodies that obey Newton's equations of motion</li>
<li>Demon algorithm: a Monte Carlo method for efficiently sampling members of a microcanonical ensemble with a given energy</li>
<li>Featherstone's algorithm: compute the effects of forces applied to a structure of joints and links</li>
<li>Ground state approximation
<ul>
<li>Variational method
<ul>
<li>Ritz method</li>
</ul>
</li>
</ul>
</li>
<li>N-body problems
<ul>
<li>Barnes–Hut simulation: Solves the n-body problem in an approximate way that has the order O(<var>n</var> log <var>n</var>) instead of O(<var>n</var>) as in a direct-sum simulation.</li>
<li>Fast multipole method (FMM): speeds up the calculation of long-ranged forces</li>
</ul>
</li>
<li>Rainflow-counting algorithm: Reduces a complex stress history to a count of elementary stress-reversals for use in fatigue analysis</li>
<li>Sweep and prune: a broad phase algorithm used during collision detection to limit the number of pairs of solids that need to be checked for collision</li>
<li>VEGAS algorithm: a method for reducing error in Monte Carlo simulations</li>
</ul>
<ul>
<li>Variational method
<ul>
<li>Ritz method</li>
</ul>
</li>
</ul>
<ul>
<li>Ritz method</li>
</ul>
<ul>
<li>Barnes–Hut simulation: Solves the n-body problem in an approximate way that has the order O(<var>n</var> log <var>n</var>) instead of O(<var>n</var>) as in a direct-sum simulation.</li>
<li>Fast multipole method (FMM): speeds up the calculation of long-ranged forces</li>
</ul>
<h3>Statistics</h3>
<ul>
<li>Algorithms for calculating variance: avoiding instability and numerical overflow</li>
<li>Approximate counting algorithm: Allows counting large number of events in a small register</li>
<li>Bayesian statistics
<ul>
<li>Nested sampling algorithm: a computational approach to the problem of comparing models in Bayesian statistics</li>
</ul>
</li>
<li>Clustering Algorithms
<ul>
<li>Average-linkage clustering: a simple agglomerative clustering algorithm</li>
<li>Canopy clustering algorithm: an unsupervised pre-clustering algorithm related to the K-means algorithm</li>
<li>Complete-linkage clustering: a simple agglomerative clustering algorithm</li>
<li>DBSCAN: a density based clustering algorithm</li>
<li>Expectation-maximization algorithm</li>
<li>Fuzzy clustering: a class of clustering algorithms where each point has a degree of belonging to clusters
<ul>
<li>Fuzzy c-means</li>
<li>FLAME clustering (Fuzzy clustering by Local Approximation of MEmberships): define clusters in the dense parts of a dataset and perform cluster assignment solely based on the neighborhood relationships among objects</li>
</ul>
</li>
<li>k-means clustering: cluster objects based on attributes into partitions</li>
<li>k-means++: a variation of this, using modified random seeds</li>
<li>k-medoids: similar to k-means, but chooses datapoints or medoids as centers</li>
<li>Linde–Buzo–Gray algorithm: a vector quantization algorithm to derive a good codebook</li>
<li>Lloyd's algorithm (Voronoi iteration or relaxation): group data points into a given number of categories, a popular algorithm for k-means clustering</li>
<li>OPTICS: a density based clustering algorithm with a visual evaluation method</li>
<li>Single-linkage clustering: a simple agglomerative clustering algorithm</li>
<li>SUBCLU: a subspace clustering algorithm</li>
<li>Ward's method : an agglomerative clustering algorithm, extended to more general Lance–Williams algorithms</li>
</ul>
</li>
<li>Estimation Theory
<ul>
<li>Expectation-maximization algorithm A class of related algorithms for finding maximum likelihood estimates of parameters in probabilistic models
<ul>
<li>Ordered subset expectation maximization (OSEM): used in medical imaging for positron emission tomography, single photon emission computed tomography and X-ray computed tomography.</li>
</ul>
</li>
<li>Odds algorithm (Bruss algorithm) Optimal online search for distinguished value in sequential random input</li>
<li>Kalman filter: estimate the state of a linear dynamic system from a series of noisy measurements</li>
</ul>
</li>
<li>False nearest neighbor algorithm (FNN) estimates fractal dimension</li>
<li>Hidden Markov model
<ul>
<li>Baum–Welch algorithm: compute maximum likelihood estimates and posterior mode estimates for the parameters of a hidden markov model</li>
<li>Forward-backward algorithm a dynamic programming algorithm for computing the probability of a particular observation sequence</li>
<li>Viterbi algorithm: find the most likely sequence of hidden states in a hidden markov model</li>
</ul>
</li>
<li>Partial least squares regression: finds a linear model describing some predicted variables in terms of other observable variables</li>
<li>Queuing theory
<ul>
<li>Buzen's algorithm: an algorithm for calculating the normalization constant G(K) in the Gordon–Newell theorem</li>
</ul>
</li>
<li>RANSAC (an abbreviation for "RANdom SAmple Consensus"): an iterative method to estimate parameters of a mathematical model from a set of observed data which contains outliers</li>
<li>Scoring algorithm: is a form of Newton's method used to solve maximum likelihood equations numerically</li>
<li>Yamartino method: calculate an approximation to the standard deviation σθ of wind direction θ during a single pass through the incoming data</li>
<li>Ziggurat algorithm: generate random numbers from a non-uniform distribution</li>
</ul>
<ul>
<li>Nested sampling algorithm: a computational approach to the problem of comparing models in Bayesian statistics</li>
</ul>
<ul>
<li>Average-linkage clustering: a simple agglomerative clustering algorithm</li>
<li>Canopy clustering algorithm: an unsupervised pre-clustering algorithm related to the K-means algorithm</li>
<li>Complete-linkage clustering: a simple agglomerative clustering algorithm</li>
<li>DBSCAN: a density based clustering algorithm</li>
<li>Expectation-maximization algorithm</li>
<li>Fuzzy clustering: a class of clustering algorithms where each point has a degree of belonging to clusters
<ul>
<li>Fuzzy c-means</li>
<li>FLAME clustering (Fuzzy clustering by Local Approximation of MEmberships): define clusters in the dense parts of a dataset and perform cluster assignment solely based on the neighborhood relationships among objects</li>
</ul>
</li>
<li>k-means clustering: cluster objects based on attributes into partitions</li>
<li>k-means++: a variation of this, using modified random seeds</li>
<li>k-medoids: similar to k-means, but chooses datapoints or medoids as centers</li>
<li>Linde–Buzo–Gray algorithm: a vector quantization algorithm to derive a good codebook</li>
<li>Lloyd's algorithm (Voronoi iteration or relaxation): group data points into a given number of categories, a popular algorithm for k-means clustering</li>
<li>OPTICS: a density based clustering algorithm with a visual evaluation method</li>
<li>Single-linkage clustering: a simple agglomerative clustering algorithm</li>
<li>SUBCLU: a subspace clustering algorithm</li>
<li>Ward's method : an agglomerative clustering algorithm, extended to more general Lance–Williams algorithms</li>
</ul>
<ul>
<li>Fuzzy c-means</li>
<li>FLAME clustering (Fuzzy clustering by Local Approximation of MEmberships): define clusters in the dense parts of a dataset and perform cluster assignment solely based on the neighborhood relationships among objects</li>
</ul>
<ul>
<li>Expectation-maximization algorithm A class of related algorithms for finding maximum likelihood estimates of parameters in probabilistic models
<ul>
<li>Ordered subset expectation maximization (OSEM): used in medical imaging for positron emission tomography, single photon emission computed tomography and X-ray computed tomography.</li>
</ul>
</li>
<li>Odds algorithm (Bruss algorithm) Optimal online search for distinguished value in sequential random input</li>
<li>Kalman filter: estimate the state of a linear dynamic system from a series of noisy measurements</li>
</ul>
<ul>
<li>Ordered subset expectation maximization (OSEM): used in medical imaging for positron emission tomography, single photon emission computed tomography and X-ray computed tomography.</li>
</ul>
<ul>
<li>Baum–Welch algorithm: compute maximum likelihood estimates and posterior mode estimates for the parameters of a hidden markov model</li>
<li>Forward-backward algorithm a dynamic programming algorithm for computing the probability of a particular observation sequence</li>
<li>Viterbi algorithm: find the most likely sequence of hidden states in a hidden markov model</li>
</ul>
<ul>
<li>Buzen's algorithm: an algorithm for calculating the normalization constant G(K) in the Gordon–Newell theorem</li>
</ul>
<h2>Computer science</h2>
<h3>Computer architecture</h3>
<ul>
<li>Tomasulo algorithm: allows sequential instructions that would normally be stalled due to certain dependencies to execute non-sequentially</li>
</ul>
<h3>Computer graphics</h3>
<ul>
<li>Clipping
<ul>
<li>Line clipping
<ul>
<li>Cohen–Sutherland</li>
<li>Cyrus–Beck</li>
<li>Fast-clipping</li>
<li>Liang–Barsky</li>
<li>Nicholl–Lee–Nicholl</li>
</ul>
</li>
<li>Polygon clipping
<ul>
<li>Sutherland–Hodgman</li>
<li>Vatti</li>
<li>Weiler–Atherton</li>
</ul>
</li>
</ul>
</li>
<li>Contour lines and Isosurfaces
<ul>
<li>Marching cubes: extract a polygonal mesh of an isosurface from a three-dimensional scalar field (sometimes called voxels)</li>
<li>Marching squares: generate contour lines for a two-dimensional scalar field</li>
<li>Marching tetrahedrons: an alternative to Marching cubes</li>
</ul>
</li>
<li>Discrete Green's Theorem: is an algorithm for computing double integral over a generalized rectangular domain in constant time. It is a natural extension to the summed area table algorithm</li>
<li>Flood fill: fills a connected region of a multi-dimensional array with a specified symbol</li>
<li>Global illumination algorithms: Considers direct illumination and reflection from other objects.
<ul>
<li>Ambient occlusion</li>
<li>Beam tracing</li>
<li>Cone tracing</li>
<li>Image-based lighting</li>
<li>Metropolis light transport</li>
<li>Path tracing</li>
<li>Photon mapping</li>
<li>Radiosity</li>
<li>Ray tracing</li>
</ul>
</li>
<li>Hidden surface removal or Visual surface determination
<ul>
<li>Newell's algorithm: eliminate polygon cycles in the depth sorting required in hidden surface removal</li>
<li>Painter's algorithm: detects visible parts of a 3-dimensional scenery</li>
<li>Scanline rendering: constructs an image by moving an imaginary line over the image</li>
<li>Warnock algorithm</li>
</ul>
</li>
<li>Line Drawing: graphical algorithm for approximating a line segment on discrete graphical media.
<ul>
<li>Bresenham's line algorithm: plots points of a 2-dimensional array to form a straight line between 2 specified points (uses decision variables)</li>
<li>DDA line algorithm: plots points of a 2-dimensional array to form a straight line between 2 specified points (uses floating-point math)</li>
<li>Xiaolin Wu's line algorithm: algorithm for line antialiasing.</li>
</ul>
</li>
<li>Midpoint circle algorithm: an algorithm used to determine the points needed for drawing a circle</li>
<li>Ramer–Douglas–Peucker algorithm: Given a 'curve' composed of line segments to find a curve not too dissimilar but that has fewer points</li>
<li>Shading
<ul>
<li>Gouraud shading: an algorithm to simulate the differing effects of light and colour across the surface of an object in 3D computer graphics</li>
<li>Phong shading: an algorithm to interpolate surface normal-vectors for surface shading in 3D computer graphics</li>
</ul>
</li>
<li>Slerp (spherical linear interpolation): quaternion interpolation for the purpose of animating 3D rotation</li>
<li>Summed area table (also known as an integral image): an algorithm for computing the sum of values in a rectangular subset of a grid in constant time</li>
</ul>
<ul>
<li>Line clipping
<ul>
<li>Cohen–Sutherland</li>
<li>Cyrus–Beck</li>
<li>Fast-clipping</li>
<li>Liang–Barsky</li>
<li>Nicholl–Lee–Nicholl</li>
</ul>
</li>
<li>Polygon clipping
<ul>
<li>Sutherland–Hodgman</li>
<li>Vatti</li>
<li>Weiler–Atherton</li>
</ul>
</li>
</ul>
<ul>
<li>Cohen–Sutherland</li>
<li>Cyrus–Beck</li>
<li>Fast-clipping</li>
<li>Liang–Barsky</li>
<li>Nicholl–Lee–Nicholl</li>
</ul>
<ul>
<li>Sutherland–Hodgman</li>
<li>Vatti</li>
<li>Weiler–Atherton</li>
</ul>
<ul>
<li>Marching cubes: extract a polygonal mesh of an isosurface from a three-dimensional scalar field (sometimes called voxels)</li>
<li>Marching squares: generate contour lines for a two-dimensional scalar field</li>
<li>Marching tetrahedrons: an alternative to Marching cubes</li>
</ul>
<ul>
<li>Ambient occlusion</li>
<li>Beam tracing</li>
<li>Cone tracing</li>
<li>Image-based lighting</li>
<li>Metropolis light transport</li>
<li>Path tracing</li>
<li>Photon mapping</li>
<li>Radiosity</li>
<li>Ray tracing</li>
</ul>
<ul>
<li>Newell's algorithm: eliminate polygon cycles in the depth sorting required in hidden surface removal</li>
<li>Painter's algorithm: detects visible parts of a 3-dimensional scenery</li>
<li>Scanline rendering: constructs an image by moving an imaginary line over the image</li>
<li>Warnock algorithm</li>
</ul>
<ul>
<li>Bresenham's line algorithm: plots points of a 2-dimensional array to form a straight line between 2 specified points (uses decision variables)</li>
<li>DDA line algorithm: plots points of a 2-dimensional array to form a straight line between 2 specified points (uses floating-point math)</li>
<li>Xiaolin Wu's line algorithm: algorithm for line antialiasing.</li>
</ul>
<ul>
<li>Gouraud shading: an algorithm to simulate the differing effects of light and colour across the surface of an object in 3D computer graphics</li>
<li>Phong shading: an algorithm to interpolate surface normal-vectors for surface shading in 3D computer graphics</li>
</ul>
<h3>Cryptography</h3>
<ul>
<li>Asymmetric (public key) encryption:
<ul>
<li>DSA</li>
<li>ElGamal</li>
<li>Elliptic curve cryptography</li>
<li>NTRUEncrypt</li>
<li>RSA</li>
</ul>
</li>
<li>Cryptographic hash functions:
<ul>
<li>HMAC: keyed-hash message authentication</li>
<li>MD5 – Note that there is now a method of generating collisions for MD5</li>
<li>RIPEMD-160</li>
<li>RTR0</li>
<li>SHA-1</li>
<li>SHA-2 (SHA-224, SHA-256, SHA-384, SHA-512)</li>
<li>Tiger (TTH), usually used in Tiger tree hashes</li>
<li>WHIRLPOOL</li>
</ul>
</li>
<li>Cryptographically secure pseudo-random number generators
<ul>
<li>Blum Blum Shub - based on the hardness of factorization</li>
<li>Fortuna, intended as an improvement on Yarrow algorithm</li>
<li>Linear feedback shift register</li>
<li>Yarrow algorithm</li>
</ul>
</li>
<li>Key exchange
<ul>
<li>Diffie–Hellman key exchange</li>
</ul>
</li>
<li>Secret sharing, Secret Splitting, Key Splitting, M of N algorithms
<ul>
<li>Blakey's Scheme</li>
<li>Shamir's Scheme</li>
</ul>
</li>
<li>Symmetric (secret key) encryption:
<ul>
<li>Advanced Encryption Standard (AES), winner of NIST competition, also known as Rijndael</li>
<li>Blowfish</li>
<li>Data Encryption Standard (DES), sometimes DE Algorithm, winner of NBS selection competition, replaced by AES for most purposes</li>
<li>IDEA</li>
<li>RC4 (cipher)</li>
<li>Tiny Encryption Algorithm</li>
</ul>
</li>
</ul>
<ul>
<li>DSA</li>
<li>ElGamal</li>
<li>Elliptic curve cryptography</li>
<li>NTRUEncrypt</li>
<li>RSA</li>
</ul>
<ul>
<li>HMAC: keyed-hash message authentication</li>
<li>MD5 – Note that there is now a method of generating collisions for MD5</li>
<li>RIPEMD-160</li>
<li>RTR0</li>
<li>SHA-1</li>
<li>SHA-2 (SHA-224, SHA-256, SHA-384, SHA-512)</li>
<li>Tiger (TTH), usually used in Tiger tree hashes</li>
<li>WHIRLPOOL</li>
</ul>
<ul>
<li>Blum Blum Shub - based on the hardness of factorization</li>
<li>Fortuna, intended as an improvement on Yarrow algorithm</li>
<li>Linear feedback shift register</li>
<li>Yarrow algorithm</li>
</ul>
<ul>
<li>Diffie–Hellman key exchange</li>
</ul>
<ul>
<li>Blakey's Scheme</li>
<li>Shamir's Scheme</li>
</ul>
<ul>
<li>Advanced Encryption Standard (AES), winner of NIST competition, also known as Rijndael</li>
<li>Blowfish</li>
<li>Data Encryption Standard (DES), sometimes DE Algorithm, winner of NBS selection competition, replaced by AES for most purposes</li>
<li>IDEA</li>
<li>RC4 (cipher)</li>
<li>Tiny Encryption Algorithm</li>
</ul>
<h3>Digital logic</h3>
<ul>
<li>Boolean minimization
<ul>
<li>Quine–McCluskey algorithm: Also called as Q-M algorithm, programmable method for simplifying the boolean equations.</li>
<li>Petrick's method: Another algorithm for boolean simplification.</li>
<li>Espresso heuristic logic minimizer: Fast algorithm for boolean function minimization.</li>
</ul>
</li>
</ul>
<ul>
<li>Quine–McCluskey algorithm: Also called as Q-M algorithm, programmable method for simplifying the boolean equations.</li>
<li>Petrick's method: Another algorithm for boolean simplification.</li>
<li>Espresso heuristic logic minimizer: Fast algorithm for boolean function minimization.</li>
</ul>
<h3>Machine learning and statistical classification</h3>
<ul>
<li>ALOPEX: a correlation-based machine-learning algorithm</li>
<li>Association rule learning: discover interesting relations between variables, used in data mining
<ul>
<li>Apriori algorithm</li>
<li>Eclat algorithm</li>
<li>FP-growth algorithm</li>
<li>One-attribute rule</li>
<li>Zero-attribute rule</li>
</ul>
</li>
<li>Boosting (meta-algorithm): Use many weak learners to boost effectiveness
<ul>
<li>AdaBoost: adaptive boosting</li>
<li>BrownBoost:a boosting algorithm that may be robust to noisy datasets</li>
<li>LogitBoost: logistic regression boosting</li>
<li>LPBoost: linear programming boosting</li>
</ul>
</li>
<li>Bootstrap aggregating (bagging): technique to improve stability and classification accuracy</li>
<li>Decision Trees
<ul>
<li>C4.5 algorithm: an extension to ID3</li>
<li>ID3 algorithm (Iterative Dichotomiser 3): Use heuristic to generate small decision trees</li>
</ul>
</li>
<li>k-nearest neighbors (k-NN): a method for classifying objects based on closest training examples in the feature space</li>
<li>Linde–Buzo–Gray algorithm: a vector quantization algorithm used to derive a good codebook</li>
<li>Locality-sensitive hashing (LSH): a method of performing probabilistic dimension reduction of high-dimensional data</li>
<li>Neural Network
<ul>
<li>Backpropagation: A supervised learning method which requires a teacher that knows, or can calculate, the desired output for any given input</li>
<li>Hopfield net: a Recurrent neural network in which all connections are symmetric</li>
<li>Perceptron: the simplest kind of feedforward neural network: a linear classifier.</li>
<li>Pulse-coupled neural networks (PCNN): neural models proposed by modeling a cat's visual cortex and developed for high-performance biomimetic image processing.</li>
<li>Radial basis function network: an artificial neural network that uses radial basis functions as activation functions</li>
<li>Self-organizing map: an unsupervised network that produces a low-dimensional representation of the input space of the training samples</li>
</ul>
</li>
<li>Random forest: classify using many decision trees</li>
<li>Reinforcement Learning:
<ul>
<li>Q-learning: learn an action-value function that gives the expected utility of taking a given action in a given state and following a fixed policy thereafter</li>
<li>SARSA (State-Action-Reward-State-Action): learn a Markov decision process policy</li>
<li>Temporal difference learning</li>
</ul>
</li>
<li>Relevance Vector Machine (RVM): similar to SVM, but provides probabilistic classification</li>
<li>Support Vector Machines (SVM): a set of methods which divide multidimensional data by finding a dividing hyperplane with the maximum margin between the two sets
<ul>
<li>Structured SVM: allows training of a classifier for general structured output labels.</li>
</ul>
</li>
<li>Winnow algorithm: related to the perceptron, but uses a multiplicative weight-update scheme</li>
</ul>
<ul>
<li>Apriori algorithm</li>
<li>Eclat algorithm</li>
<li>FP-growth algorithm</li>
<li>One-attribute rule</li>
<li>Zero-attribute rule</li>
</ul>
<ul>
<li>AdaBoost: adaptive boosting</li>
<li>BrownBoost:a boosting algorithm that may be robust to noisy datasets</li>
<li>LogitBoost: logistic regression boosting</li>
<li>LPBoost: linear programming boosting</li>
</ul>
<ul>
<li>C4.5 algorithm: an extension to ID3</li>
<li>ID3 algorithm (Iterative Dichotomiser 3): Use heuristic to generate small decision trees</li>
</ul>
<ul>
<li>Backpropagation: A supervised learning method which requires a teacher that knows, or can calculate, the desired output for any given input</li>
<li>Hopfield net: a Recurrent neural network in which all connections are symmetric</li>
<li>Perceptron: the simplest kind of feedforward neural network: a linear classifier.</li>
<li>Pulse-coupled neural networks (PCNN): neural models proposed by modeling a cat's visual cortex and developed for high-performance biomimetic image processing.</li>
<li>Radial basis function network: an artificial neural network that uses radial basis functions as activation functions</li>
<li>Self-organizing map: an unsupervised network that produces a low-dimensional representation of the input space of the training samples</li>
</ul>
<ul>
<li>Q-learning: learn an action-value function that gives the expected utility of taking a given action in a given state and following a fixed policy thereafter</li>
<li>SARSA (State-Action-Reward-State-Action): learn a Markov decision process policy</li>
<li>Temporal difference learning</li>
</ul>
<ul>
<li>Structured SVM: allows training of a classifier for general structured output labels.</li>
</ul>
<h3>Programming language theory</h3>
<ul>
<li>C3 linearization: an algorithm used primarily to obtain a consistent linearization of a multiple inheritance hierarchy in object-oriented programming</li>
<li>Chaitin's algorithm: a bottom-up, graph coloring register allocation algorithm that uses cost/degree as its spill metric</li>
<li>Hindley–Milner type inference algorithm</li>
<li>Rete algorithm: an efficient pattern matching algorithm for implementing production rule systems</li>
<li>Sethi-Ullman algorithm: generate optimal code for arithmetic expressions</li>
</ul>
<h4>Parsing</h4>
<ul>
<li>CYK algorithm: An O(n) algorithm for parsing context-free grammars in Chomsky normal form</li>
<li>Earley parser: Another O(n) algorithm for parsing any context-free grammar</li>
<li>GLR parser:An algorithm for parsing any context-free grammar by Masaru Tomita. It is tuned for deterministic grammars, on which it performs almost linear time and O(n) in worst case.</li>
<li>Inside-outside algorithm: An O(n) algorithm for re-estimating production probabilities in probabilistic context-free grammars</li>
<li>LL parser: A relatively simple linear time parsing algorithm for a limited class of context-free grammars</li>
<li>LR parser: A more complex linear time parsing algorithm for a larger class of context-free grammars. Variants:
<ul>
<li>Canonical LR parser</li>
<li>LALR (Look-ahead LR) parser</li>
<li>Operator-precedence parser</li>
<li>SLR (Simple LR) parser</li>
<li>Simple precedence parser</li>
</ul>
</li>
<li>Packrat parser: A linear time parsing algorithm supporting some context-free grammars and parsing expression grammars</li>
<li>Recursive descent parser: A top-down parser suitable for LL(<i>k</i>) grammars</li>
<li>Shunting yard algorithm: convert an infix-notation math expression to postfix</li>
<li>Pratt parser</li>
<li>Lexical analysis</li>
</ul>
<ul>
<li>Canonical LR parser</li>
<li>LALR (Look-ahead LR) parser</li>
<li>Operator-precedence parser</li>
<li>SLR (Simple LR) parser</li>
<li>Simple precedence parser</li>
</ul>
<h3>Quantum algorithms</h3>
<ul>
<li>Deutsch-Jozsa algorithm: criterion of balance for Boolean function</li>
<li>Grover's algorithm: provides quadratic speedup for many search problems</li>
<li>Shor's algorithm: provides exponential speedup (relative to currently known non-quantum algorithms) for factoring a number</li>
<li>Simon's algorithm: provides a provably exponential speedup (relative to any non-quantum algorithm) for a black-box problem</li>
</ul>
<h3>Theory of computation and automata</h3>
<ul>
<li>Powerset construction: Algorithm to convert nondeterministic automaton to deterministic automaton.</li>
<li>Tarski–Kuratowski algorithm: a non-deterministic algorithm which provides an upper bound for the complexity of formulas in the arithmetical hierarchy and analytical hierarchy</li>
</ul>
<h2>Information theory and signal processing</h2>
<h3>Coding theory</h3>
<h4>Error detection and correction</h4>
<ul>
<li>BCH Codes
<ul>
<li>Berlekamp–Massey algorithm</li>
<li>Peterson–Gorenstein–Zierler algorithm</li>
<li>Reed–Solomon error correction</li>
</ul>
</li>
<li>BCJR algorithm: decoding of error correcting codes defined on trellises (principally convolutional codes)</li>
<li>Forward error correction</li>
<li>Gray code</li>
<li>Hamming codes
<ul>
<li>Hamming(7,4): a Hamming code that encodes 4 bits of data into 7 bits by adding 3 parity bits</li>
<li>Hamming distance: sum number of positions which are different</li>
<li>Hamming weight (population count): find the number of 1 bits in a binary word</li>
</ul>
</li>
<li>Redundancy checks
<ul>
<li>Adler-32</li>
<li>Cyclic redundancy check</li>
<li>Damm algorithm</li>
<li>Fletcher's checksum</li>
<li>Longitudinal redundancy check (LRC)</li>
<li>Luhn algorithm: a method of validating identification numbers</li>
<li>Luhn mod N algorithm: extension of Luhn to non-numeric characters</li>
<li>Parity: simple/fast error detection technique</li>
<li>Verhoeff algorithm</li>
</ul>
</li>
</ul>
<ul>
<li>Berlekamp–Massey algorithm</li>
<li>Peterson–Gorenstein–Zierler algorithm</li>
<li>Reed–Solomon error correction</li>
</ul>
<ul>
<li>Hamming(7,4): a Hamming code that encodes 4 bits of data into 7 bits by adding 3 parity bits</li>
<li>Hamming distance: sum number of positions which are different</li>
<li>Hamming weight (population count): find the number of 1 bits in a binary word</li>
</ul>
<ul>
<li>Adler-32</li>
<li>Cyclic redundancy check</li>
<li>Damm algorithm</li>
<li>Fletcher's checksum</li>
<li>Longitudinal redundancy check (LRC)</li>
<li>Luhn algorithm: a method of validating identification numbers</li>
<li>Luhn mod N algorithm: extension of Luhn to non-numeric characters</li>
<li>Parity: simple/fast error detection technique</li>
<li>Verhoeff algorithm</li>
</ul>
<h4>Lossless compression algorithms</h4>
<ul>
<li>Burrows–Wheeler transform: preprocessing useful for improving lossless compression</li>
<li>Context tree weighting</li>
<li>Delta encoding: aid to compression of data in which sequential data occurs frequently</li>
<li>Dynamic Markov compression: Compression using predictive arithmetic coding</li>
<li>Dictionary coders
<ul>
<li>Byte pair encoding (BPE)</li>
<li>DEFLATE</li>
<li>Lempel–Ziv
<ul>
<li>LZ77 and LZ78</li>
<li>Lempel–Ziv Jeff Bonwick (LZJB)</li>
<li>Lempel–Ziv–Markov chain algorithm (LZMA)</li>
<li>Lempel–Ziv–Oberhumer (LZO): speed oriented</li>
<li>Lempel–Ziv–Stac (LZS)</li>
<li>Lempel–Ziv–Storer–Szymanski (LZSS)</li>
<li>Lempel–Ziv–Welch (LZW)</li>
<li>LZWL: syllable-based variant</li>
<li>LZX</li>
<li>Lempel–Ziv Ross Williams (LZRW)</li>
</ul>
</li>
</ul>
</li>
<li>Entropy encoding: coding scheme that assigns codes to symbols so as to match code lengths with the probabilities of the symbols
<ul>
<li>Arithmetic coding: advanced entropy coding
<ul>
<li>Range encoding: same as arithmetic coding, but looked at in a slightly different way</li>
</ul>
</li>
<li>Huffman coding: simple lossless compression taking advantage of relative character frequencies
<ul>
<li>Adaptive Huffman coding: adaptive coding technique based on Huffman coding</li>
<li>Package-merge algorithm: Optimizes Huffman coding subject to a length restriction on code strings</li>
</ul>
</li>
<li>Shannon–Fano coding</li>
<li>Shannon–Fano–Elias coding: precursor to arithmetic encoding</li>
</ul>
</li>
<li>Entropy coding with known entropy characteristics
<ul>
<li>Golomb coding: form of entropy coding that is optimal for alphabets following geometric distributions</li>
<li>Rice coding: form of entropy coding that is optimal for alphabets following geometric distributions</li>
<li>Truncated binary encoding</li>
<li>Unary coding: code that represents a number n with n ones followed by a zero</li>
<li>Universal codes: encodes positive integers into binary code words
<ul>
<li>Elias delta, gamma, and omega coding</li>
<li>Exponential-Golomb coding</li>
<li>Fibonacci coding</li>
<li>Levenshtein coding</li>
</ul>
</li>
</ul>
</li>
<li>Fast Efficient &amp; Lossless Image Compression System (FELICS): a lossless image compression algorithm</li>
<li>Incremental encoding: delta encoding applied to sequences of strings</li>
<li>Prediction by partial matching (PPM): an adaptive statistical data compression technique based on context modeling and prediction</li>
<li>Run-length encoding: lossless data compression taking advantage of strings of repeated characters</li>
<li>SEQUITUR algorithm: lossless compression by incremental grammar inference on a string</li>
</ul>
<ul>
<li>Byte pair encoding (BPE)</li>
<li>DEFLATE</li>
<li>Lempel–Ziv
<ul>
<li>LZ77 and LZ78</li>
<li>Lempel–Ziv Jeff Bonwick (LZJB)</li>
<li>Lempel–Ziv–Markov chain algorithm (LZMA)</li>
<li>Lempel–Ziv–Oberhumer (LZO): speed oriented</li>
<li>Lempel–Ziv–Stac (LZS)</li>
<li>Lempel–Ziv–Storer–Szymanski (LZSS)</li>
<li>Lempel–Ziv–Welch (LZW)</li>
<li>LZWL: syllable-based variant</li>
<li>LZX</li>
<li>Lempel–Ziv Ross Williams (LZRW)</li>
</ul>
</li>
</ul>
<ul>
<li>LZ77 and LZ78</li>
<li>Lempel–Ziv Jeff Bonwick (LZJB)</li>
<li>Lempel–Ziv–Markov chain algorithm (LZMA)</li>
<li>Lempel–Ziv–Oberhumer (LZO): speed oriented</li>
<li>Lempel–Ziv–Stac (LZS)</li>
<li>Lempel–Ziv–Storer–Szymanski (LZSS)</li>
<li>Lempel–Ziv–Welch (LZW)</li>
<li>LZWL: syllable-based variant</li>
<li>LZX</li>
<li>Lempel–Ziv Ross Williams (LZRW)</li>
</ul>
<ul>
<li>Arithmetic coding: advanced entropy coding
<ul>
<li>Range encoding: same as arithmetic coding, but looked at in a slightly different way</li>
</ul>
</li>
<li>Huffman coding: simple lossless compression taking advantage of relative character frequencies
<ul>
<li>Adaptive Huffman coding: adaptive coding technique based on Huffman coding</li>
<li>Package-merge algorithm: Optimizes Huffman coding subject to a length restriction on code strings</li>
</ul>
</li>
<li>Shannon–Fano coding</li>
<li>Shannon–Fano–Elias coding: precursor to arithmetic encoding</li>
</ul>
<ul>
<li>Range encoding: same as arithmetic coding, but looked at in a slightly different way</li>
</ul>
<ul>
<li>Adaptive Huffman coding: adaptive coding technique based on Huffman coding</li>
<li>Package-merge algorithm: Optimizes Huffman coding subject to a length restriction on code strings</li>
</ul>
<ul>
<li>Golomb coding: form of entropy coding that is optimal for alphabets following geometric distributions</li>
<li>Rice coding: form of entropy coding that is optimal for alphabets following geometric distributions</li>
<li>Truncated binary encoding</li>
<li>Unary coding: code that represents a number n with n ones followed by a zero</li>
<li>Universal codes: encodes positive integers into binary code words
<ul>
<li>Elias delta, gamma, and omega coding</li>
<li>Exponential-Golomb coding</li>
<li>Fibonacci coding</li>
<li>Levenshtein coding</li>
</ul>
</li>
</ul>
<ul>
<li>Elias delta, gamma, and omega coding</li>
<li>Exponential-Golomb coding</li>
<li>Fibonacci coding</li>
<li>Levenshtein coding</li>
</ul>
<h4>Lossy compression algorithms</h4>
<ul>
<li>3Dc: a lossy data compression algorithm for normal maps</li>
<li>Audio and Speech compression
<ul>
<li>A-law algorithm: standard companding algorithm</li>
<li>Code-excited linear prediction (CELP): low bit-rate speech compression</li>
<li>Linear predictive coding (LPC): lossy compression by representing the spectral envelope of a digital signal of speech in compressed form</li>
<li>Mu-law algorithm: standard analog signal compression or companding algorithm</li>
<li>Warped Linear Predictive Coding (WLPC)</li>
</ul>
</li>
<li>Image Compression
<ul>
<li>Block Truncation Coding (BTC): a type of lossy image compression technique for greyscale images</li>
<li>Embedded Zerotree Wavelet (EZW)</li>
<li>Fast Cosine Transform algorithms (FCT algorithms): compute Discrete Cosine Transform (DCT) efficiently</li>
<li>Fractal compression: method used to compress images using fractals</li>
<li>Set Partitioning in Hierarchical Trees (SPIHT)</li>
<li>Wavelet compression: form of data compression well suited for image compression (sometimes also video compression and audio compression)</li>
</ul>
</li>
<li>Transform coding: type of data compression for "natural" data like audio signals or photographic images</li>
<li>Video compression</li>
<li>Vector quantization: technique often used in lossy data compression</li>
</ul>
<ul>
<li>A-law algorithm: standard companding algorithm</li>
<li>Code-excited linear prediction (CELP): low bit-rate speech compression</li>
<li>Linear predictive coding (LPC): lossy compression by representing the spectral envelope of a digital signal of speech in compressed form</li>
<li>Mu-law algorithm: standard analog signal compression or companding algorithm</li>
<li>Warped Linear Predictive Coding (WLPC)</li>
</ul>
<ul>
<li>Block Truncation Coding (BTC): a type of lossy image compression technique for greyscale images</li>
<li>Embedded Zerotree Wavelet (EZW)</li>
<li>Fast Cosine Transform algorithms (FCT algorithms): compute Discrete Cosine Transform (DCT) efficiently</li>
<li>Fractal compression: method used to compress images using fractals</li>
<li>Set Partitioning in Hierarchical Trees (SPIHT)</li>
<li>Wavelet compression: form of data compression well suited for image compression (sometimes also video compression and audio compression)</li>
</ul>
<h3>Digital signal processing</h3>
<ul>
<li>Adaptive-additive algorithm (AA algorithm): find the spatial frequency phase of an observed wave source</li>
<li>Discrete Fourier transform: determines the frequencies contained in a (segment of a) signal
<ul>
<li>Bluestein's FFT algorithm</li>
<li>Bruun's FFT algorithm</li>
<li>Cooley–Tukey FFT algorithm</li>
<li>Fast Fourier transform</li>
<li>Prime-factor FFT algorithm</li>
<li>Rader's FFT algorithm</li>
</ul>
</li>
<li>Fast folding algorithm: an efficient algorithm for the detection of approximately periodic events within time series data</li>
<li>Gerchberg–Saxton algorithm: Phase retrieval algorithm for optical planes</li>
<li>Goertzel algorithm: identify a particular frequency component in a signal. Can be used for DTMF digit decoding.</li>
<li>Karplus-Strong string synthesis: physical modelling synthesis to simulate the sound of a hammered or plucked string or some types of percussion</li>
</ul>
<ul>
<li>Bluestein's FFT algorithm</li>
<li>Bruun's FFT algorithm</li>
<li>Cooley–Tukey FFT algorithm</li>
<li>Fast Fourier transform</li>
<li>Prime-factor FFT algorithm</li>
<li>Rader's FFT algorithm</li>
</ul>
<h4>Image processing</h4>
<ul>
<li>Contrast Enhancement
<ul>
<li>Histogram equalization: use histogram to improve image contrast</li>
<li>Adaptive histogram equalization: histogram equalization which adapts to local changes in contrast</li>
</ul>
</li>
<li>Connected-component labeling: find and label disjoint regions</li>
<li>Dithering and half-toning
<ul>
<li>Error diffusion</li>
<li>Floyd–Steinberg dithering</li>
<li>Ordered dithering</li>
<li>Riemersma dithering</li>
</ul>
</li>
<li>Elser difference-map algorithm: a search algorithm for general constraint satisfaction problems. Originally used for X-Ray diffraction microscopy</li>
<li>Feature detection
<ul>
<li>Canny edge detector: detect a wide range of edges in images</li>
<li>Generalised Hough transform</li>
<li>Hough transform</li>
<li>Marr–Hildreth algorithm: an early edge detection algorithm</li>
<li>SIFT (Scale-invariant feature transform): is an algorithm to detect and describe local features in images.</li>
<li>SURF (Speeded Up Robust Features): is a robust local feature detector, first presented by Herbert Bay et al. in 2006, that can be used in computer vision tasks like object recognition or 3D reconstruction. It is partly inspired by the SIFT descriptor. The standard version of SURF is several times faster than SIFT and claimed by its authors to be more robust against different image transformations than SIFT.</li>
</ul>
</li>
<li>Richardson–Lucy deconvolution: image de-blurring algorithm</li>
<li>Seam carving: content-aware image resizing algorithm</li>
<li>Segmentation: partition a digital image into two or more regions
<ul>
<li>GrowCut algorithm: an interactive segmentation algorithm</li>
<li>Random walker algorithm</li>
<li>Region growing</li>
<li>Watershed transformation: a class of algorithms based on the watershed analogy</li>
</ul>
</li>
</ul>
<ul>
<li>Histogram equalization: use histogram to improve image contrast</li>
<li>Adaptive histogram equalization: histogram equalization which adapts to local changes in contrast</li>
</ul>
<ul>
<li>Error diffusion</li>
<li>Floyd–Steinberg dithering</li>
<li>Ordered dithering</li>
<li>Riemersma dithering</li>
</ul>
<ul>
<li>Canny edge detector: detect a wide range of edges in images</li>
<li>Generalised Hough transform</li>
<li>Hough transform</li>
<li>Marr–Hildreth algorithm: an early edge detection algorithm</li>
<li>SIFT (Scale-invariant feature transform): is an algorithm to detect and describe local features in images.</li>
<li>SURF (Speeded Up Robust Features): is a robust local feature detector, first presented by Herbert Bay et al. in 2006, that can be used in computer vision tasks like object recognition or 3D reconstruction. It is partly inspired by the SIFT descriptor. The standard version of SURF is several times faster than SIFT and claimed by its authors to be more robust against different image transformations than SIFT.</li>
</ul>
<ul>
<li>GrowCut algorithm: an interactive segmentation algorithm</li>
<li>Random walker algorithm</li>
<li>Region growing</li>
<li>Watershed transformation: a class of algorithms based on the watershed analogy</li>
</ul>
<h2>Software engineering</h2>
<ul>
<li>Cache algorithms</li>
<li>CHS conversion: converting between disk addressing systems</li>
<li>Double dabble: Convert binary numbers to BCD</li>
<li>Hash Function: convert a large, possibly variable-sized amount of data into a small datum, usually a single integer that may serve as an index into an array
<ul>
<li>Fowler–Noll–Vo hash function: fast with low collision rate</li>
<li>Pearson hashing: computes 8 bit value only, optimized for 8 bit computers</li>
<li>Zobrist hashing: used in the implementation of transposition tables</li>
</ul>
</li>
<li>Unicode Collation Algorithm</li>
<li>Xor swap algorithm: swaps the values of two variables without using a buffer</li>
</ul>
<ul>
<li>Fowler–Noll–Vo hash function: fast with low collision rate</li>
<li>Pearson hashing: computes 8 bit value only, optimized for 8 bit computers</li>
<li>Zobrist hashing: used in the implementation of transposition tables</li>
</ul>
<h3>Database algorithms</h3>
<ul>
<li>Algorithms for Recovery and Isolation Exploiting Semantics (ARIES): transaction recovery</li>
<li>Join algorithms
<ul>
<li>Block nested loop</li>
<li>Hash join</li>
<li>Nested loop join</li>
<li>Sort-Merge Join</li>
</ul>
</li>
</ul>
<ul>
<li>Block nested loop</li>
<li>Hash join</li>
<li>Nested loop join</li>
<li>Sort-Merge Join</li>
</ul>
<h3>Distributed systems algorithms</h3>
<ul>
<li>Bully algorithm: a method for dynamically selecting a coordinator</li>
<li>Byzantine fault tolerance: good fault tolerance.</li>
<li>Clock synchronization
<ul>
<li>Berkeley algorithm</li>
<li>Cristian's algorithm</li>
<li>Intersection algorithm</li>
<li>Marzullo's algorithm</li>
</ul>
</li>
<li>Detection of Process Termination
<ul>
<li>Dijkstra-Scholten algorithm</li>
<li>Huang's algorithm</li>
</ul>
</li>
<li>Lamport ordering: a partial ordering of events based on the <i>happened-before</i> relation</li>
<li>Mutual exclusion
<ul>
<li>Lamport's Distributed Mutual Exclusion Algorithm</li>
<li>Naimi-Trehel's log(n) Algorithm</li>
<li>Maekawa's Algorithm</li>
<li>Raymond's Algorithm</li>
<li>Ricart-Agrawala Algorithm</li>
</ul>
</li>
<li>Paxos algorithm: a family of protocols for solving consensus in a network of unreliable processors</li>
<li>Snapshot algorithm: record a consistent global state for an asynchronous system</li>
<li>Vector clocks: generate a partial ordering of events in a distributed system and detect causality violations</li>
</ul>
<ul>
<li>Berkeley algorithm</li>
<li>Cristian's algorithm</li>
<li>Intersection algorithm</li>
<li>Marzullo's algorithm</li>
</ul>
<ul>
<li>Dijkstra-Scholten algorithm</li>
<li>Huang's algorithm</li>
</ul>
<ul>
<li>Lamport's Distributed Mutual Exclusion Algorithm</li>
<li>Naimi-Trehel's log(n) Algorithm</li>
<li>Maekawa's Algorithm</li>
<li>Raymond's Algorithm</li>
<li>Ricart-Agrawala Algorithm</li>
</ul>
<h3>Memory allocation and deallocation algorithms</h3>
<ul>
<li>Buddy memory allocation: Algorithm to allocate memory such that fragmentation is less.</li>
<li>Garbage collectors
<ul>
<li>Boehm garbage collector: Conservative garbage collector</li>
<li>Cheney's algorithm: An improvement on the Semi-space collector</li>
<li>Generational garbage collector: Fast garbage collectors that segregate memory by age</li>
<li>Mark-compact algorithm: a combination of the mark-sweep algorithm and Cheney's copying algorithm</li>
<li>Mark and sweep</li>
<li>Semi-space collector: An early copying collector</li>
</ul>
</li>
<li>Reference counting</li>
</ul>
<ul>
<li>Boehm garbage collector: Conservative garbage collector</li>
<li>Cheney's algorithm: An improvement on the Semi-space collector</li>
<li>Generational garbage collector: Fast garbage collectors that segregate memory by age</li>
<li>Mark-compact algorithm: a combination of the mark-sweep algorithm and Cheney's copying algorithm</li>
<li>Mark and sweep</li>
<li>Semi-space collector: An early copying collector</li>
</ul>
<h3>Operating systems algorithms</h3>
<ul>
<li>Banker's algorithm: Algorithm used for deadlock avoidance.</li>
<li>Page replacement algorithms: Selecting the victim page under low memory conditions.
<ul>
<li>Adaptive replacement cache: better performance than LRU</li>
<li>Clock with Adaptive Replacement (CAR): is a page replacement algorithm that has performance comparable to Adaptive replacement cache</li>
</ul>
</li>
</ul>
<ul>
<li>Adaptive replacement cache: better performance than LRU</li>
<li>Clock with Adaptive Replacement (CAR): is a page replacement algorithm that has performance comparable to Adaptive replacement cache</li>
</ul>
<h4>Networking</h4>
<ul>
<li>Karn's Algorithm: addresses the problem of getting accurate estimates of the round-trip time for messages when using TCP</li>
<li>Luleå algorithm: a technique for storing and searching internet routing tables efficiently</li>
<li>Network congestion
<ul>
<li>Exponential backoff</li>
<li>Nagle's algorithm: improve the efficiency of TCP/IP networks by coalescing packets</li>
<li>Truncated binary exponential backoff</li>
</ul>
</li>
</ul>
<ul>
<li>Exponential backoff</li>
<li>Nagle's algorithm: improve the efficiency of TCP/IP networks by coalescing packets</li>
<li>Truncated binary exponential backoff</li>
</ul>
<h4>Process synchronization</h4>
<ul>
<li>Dekker's algorithm</li>
<li>Lamport's Bakery algorithm</li>
<li>Peterson's algorithm</li>
</ul>
<h4>Scheduling</h4>
<ul>
<li>Earliest deadline first scheduling</li>
<li>Fair-share scheduling</li>
<li>Least slack time scheduling</li>
<li>List scheduling</li>
<li>Multi level feedback queue</li>
<li>Rate-monotonic scheduling</li>
<li>Round-robin scheduling</li>
<li>Shortest job next</li>
<li>Shortest remaining time</li>
<li>Top-nodes algorithm: resource calendar management</li>
</ul>
<h4>Disk scheduling</h4>
<ul>
<li>Elevator algorithm: Disk scheduling algorithm that works like an elevator.</li>
<li>Shortest seek first: Disk scheduling algorithm to reduce seek time.</li>
</ul>
<h2>See also</h2>
<ul>
<li>List of data structures</li>
<li>List of machine learning algorithms</li>
<li>List of algorithm general topics</li>
<li>List of terms relating to algorithms and data structures</li>
<li>Heuristic</li>
</ul>
</body>
</html>