<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Horners-method---Wikipedia-the-free-encyclopedia.html</title></head>
<body>
<h1>Horner's method</h1>
<p>In mathematics, <b>Horner's method</b> (also known as <b>Horner scheme</b> in the UK or <b>Horner's rule</b> in the U.S.) is either of two things: (i) an algorithm for calculating polynomials, which consists of transforming the monomial form into a computationally efficient form; or (ii) a method for approximating the roots of a polynomial. The latter is also known as <b>Ruffini–Horner's method</b>.</p>
<p>These methods are named after the British mathematician William George Horner, although they were known before him by Paolo Ruffini and, six hundred years earlier, by the Chinese mathematician Qin Jiushao.</p>
<p></p>
<h2>Contents</h2>
<ul>
<li>1 Description of the algorithm</li>
<li>2 Examples
<ul>
<li>2.1 Floating point multiplication and division
<ul>
<li>2.1.1 Example</li>
<li>2.1.2 Method</li>
<li>2.1.3 Derivation</li>
</ul>
</li>
<li>2.2 Polynomial root finding
<ul>
<li>2.2.1 Example</li>
<li>2.2.2 Octave implementation</li>
<li>2.2.3 Python implementation</li>
</ul>
</li>
</ul>
</li>
<li>3 Application</li>
<li>4 Efficiency</li>
<li>5 History</li>
<li>6 See also</li>
<li>7 References
<ul>
<li>7.1 Citations</li>
<li>7.2 Bibliography</li>
</ul>
</li>
<li>8 External links</li>
</ul>
<ul>
<li>2.1 Floating point multiplication and division
<ul>
<li>2.1.1 Example</li>
<li>2.1.2 Method</li>
<li>2.1.3 Derivation</li>
</ul>
</li>
<li>2.2 Polynomial root finding
<ul>
<li>2.2.1 Example</li>
<li>2.2.2 Octave implementation</li>
<li>2.2.3 Python implementation</li>
</ul>
</li>
</ul>
<ul>
<li>2.1.1 Example</li>
<li>2.1.2 Method</li>
<li>2.1.3 Derivation</li>
</ul>
<ul>
<li>2.2.1 Example</li>
<li>2.2.2 Octave implementation</li>
<li>2.2.3 Python implementation</li>
</ul>
<ul>
<li>7.1 Citations</li>
<li>7.2 Bibliography</li>
</ul>
<p></p>
<h2>Description of the algorithm</h2>
<p>Given the polynomial</p>
<p>where <img class="mwe-math-fallback-image-inline tex" alt="a_0, \ldots, a_n" src="//upload.wikimedia.org/math/2/2/0/220cb03f9aa9cad8e8558109cb82663d.png"> are real numbers, we wish to evaluate the polynomial at a specific value of <img class="mwe-math-fallback-image-inline tex" alt="x" src="//upload.wikimedia.org/math/9/d/d/9dd4e461268c8034f5c8564e155c67a6.png">, say <img class="mwe-math-fallback-image-inline tex" alt="x_0" src="//upload.wikimedia.org/math/0/b/2/0b21a666a81629962ade8afd967826ed.png">.</p>
<p>To accomplish this, we define a new sequence of constants as follows:</p>
<p>Then <img class="mwe-math-fallback-image-inline tex" alt="b_0" src="//upload.wikimedia.org/math/3/e/5/3e5dc8a9e58fac43ec3377c25606be6b.png"> is the value of <img class="mwe-math-fallback-image-inline tex" alt="p(x_0)" src="//upload.wikimedia.org/math/2/a/d/2ade10a73a94e085bdac2d1bfb3c9559.png">.</p>
<p>To see why this works, note that the polynomial can be written in the form</p>
<p>Thus, by iteratively substituting the <img class="mwe-math-fallback-image-inline tex" alt="b_i" src="//upload.wikimedia.org/math/c/9/f/c9f6d8557ce40f989fa727b5c0bb1ddf.png"> into the expression,</p>
<h2>Examples</h2>
<p>Evaluate</p>
<p>We use synthetic division as follows:</p>
<p>WHATSON? 51919ffb-d639-4119-8371-1cd09a7c614e</p>
<pre>
 x₀│   x³    x²    x¹    x⁰
 3 │   2    −6     2    −1
   │         6     0     6    
   └────────────────────────
       2     0     2     5
</pre>
<p>The entries in the third row are the sum of those in the first two. Each entry in the second row is the product of the <i>x</i>-value (3 in this example) with the third-row entry immediately to the left. The entries in the first row are the coefficients of the polynomial to be evaluated. Then the remainder of <img class="mwe-math-fallback-image-inline tex" alt="f(x)" src="//upload.wikimedia.org/math/5/0/b/50bbd36e1fd2333108437a2ca378be62.png"> on division by <img class="mwe-math-fallback-image-inline tex" alt="x-3" src="//upload.wikimedia.org/math/7/8/8/7882d4fcae2b358f63b24def6f56e7d4.png"> is 5.</p>
<p>But by the polynomial remainder theorem, we know that the remainder is <img class="mwe-math-fallback-image-inline tex" alt="f(3) " src="//upload.wikimedia.org/math/d/1/0/d10299b8ce8e24128b8cdd510c51da75.png">. Thus <img class="mwe-math-fallback-image-inline tex" alt="f(3) = 5" src="//upload.wikimedia.org/math/7/a/8/7a893721863065c37900f2a534728af8.png"></p>
<p>In this example, if <img class="mwe-math-fallback-image-inline tex" alt="a_3 = 2, a_2 = -6, a_1 = 2, a_0 = -1" src="//upload.wikimedia.org/math/5/5/1/55195e43c812cc1175a6d98945b4f361.png"> we can see that <img class="mwe-math-fallback-image-inline tex" alt="b_3 = 2, b_2 = 0, b_1 = 2, b_0 = 5 " src="//upload.wikimedia.org/math/9/b/d/9bd8b0b920b2a98bcb0950198cddc4ae.png">, the entries in the third row. So, synthetic division is based on Horner's method.</p>
<p>As a consequence of the polynomial remainder theorem, the entries in the third row are the coefficients of the second-degree polynomial, the quotient of <img class="mwe-math-fallback-image-inline tex" alt="f(x)" src="//upload.wikimedia.org/math/5/0/b/50bbd36e1fd2333108437a2ca378be62.png"> on division by <img class="mwe-math-fallback-image-inline tex" alt=" x-3 " src="//upload.wikimedia.org/math/7/8/8/7882d4fcae2b358f63b24def6f56e7d4.png">. The remainder is 5. This makes Horner's method useful for polynomial long division.</p>
<p>Divide <img class="mwe-math-fallback-image-inline tex" alt="x^3-6x^2+11x-6\," src="//upload.wikimedia.org/math/e/4/f/e4f6905ec7824e9735551ab65a5b914e.png"> by <img class="mwe-math-fallback-image-inline tex" alt="x-2\," src="//upload.wikimedia.org/math/7/7/7/777f30c76dc03cac9f568c563850fda6.png">:</p>
<p>WHATSON? 36f51115-370c-4d3e-9d95-c5eafdc5ab8e</p>
<pre>
 2 │   1    -6    11    -6
   │         2    -8     6    
   └────────────────────────
       1    -4     3     0
</pre>
<p>The quotient is <img class="mwe-math-fallback-image-inline tex" alt="x^2-4x+3\," src="//upload.wikimedia.org/math/b/4/8/b48226f4b97a8a5f2080561f96536105.png">.</p>
<p>Let <img class="mwe-math-fallback-image-inline tex" alt="f_1(x)=4x^4-6x^3+3x-5\," src="//upload.wikimedia.org/math/d/8/d/d8dd7e08b4d210f89562fbaa58710eff.png"> and <img class="mwe-math-fallback-image-inline tex" alt="f_2(x)=2x-1\," src="//upload.wikimedia.org/math/d/3/1/d31f67ba462294886bbb07c8e701100c.png">. Divide <img class="mwe-math-fallback-image-inline tex" alt="f_1(x)\," src="//upload.wikimedia.org/math/2/c/5/2c5dfb789f47dbc2a50e4922a1942a9f.png"> by <img class="mwe-math-fallback-image-inline tex" alt="f_2\,(x)" src="//upload.wikimedia.org/math/8/b/0/8b071f710fec48c2ee797361ca034e70.png"> using Horner's method.</p>
<p>WHATSON? eb784a6e-b78f-4ec0-930b-0b924785a73c</p>
<pre>
  2 │  4    -6    0    3   │   -5
────┼──────────────────────┼───────
  1 │        2   -2   -1   │    1
    │                      │  
    └──────────────────────┼───────
       2    -2    -1   1   │   -4
</pre>
<p>The third row is the sum of the first two rows, divided by 2. Each entry in the second row is the product of 1 with the third-row entry to the left. The answer is</p>
<h3>Floating point multiplication and division</h3>
<p>Horner's method is a fast, code-efficient method for multiplication and division of binary numbers on a microcontroller with no hardware multiplier. One of the binary numbers to be multiplied is represented as a trivial polynomial, where, (using the above notation): a<sub>i</sub> = 1, and x = 2. Then, x (or x to some power) is repeatedly factored out. In this binary numeral system (base 2), x = 2, so powers of 2 are repeatedly factored out.</p>
<h4>Example</h4>
<p>For example, to find the product of two numbers, (0.15625) and <i>m</i>:</p>
<h4>Method</h4>
<p>To find the product of two binary numbers, d and m:</p>
<ul>
<li>1. A register holding the intermediate result is initialized to d.</li>
<li>2. Begin with the least significant (rightmost) non-zero bit in m.
<ul>
<li>2b. Count (to the left) the number of bit positions to the next most significant non-zero bit. If there are no more-significant bits, then take the value of the current bit position.</li>
<li>2c. Using that value, perform a right-shift operation by that number of bits on the register holding the intermediate result</li>
</ul>
</li>
<li>3. If all the non-zero bits were counted, then the intermediate result register now holds the final result. Otherwise, add d to the intermediate result, and continue in step #2 with the next most significant bit in m.</li>
</ul>
<ul>
<li>2b. Count (to the left) the number of bit positions to the next most significant non-zero bit. If there are no more-significant bits, then take the value of the current bit position.</li>
<li>2c. Using that value, perform a right-shift operation by that number of bits on the register holding the intermediate result</li>
</ul>
<h4>Derivation</h4>
<p>In general, for a binary number with bit values: (<img class="mwe-math-fallback-image-inline tex" alt=" d_3 d_2 d_1 d_0 " src="//upload.wikimedia.org/math/e/7/f/e7f0b0a1a68b8f5d9462634bd1b7cbeb.png">) the product is:</p>
<p>At this stage in the algorithm, it is required that terms with zero-valued coefficients are dropped, so that only binary coefficients equal to one are counted, thus the problem of multiplication or division by zero is not an issue, despite this implication in the factored equation:</p>
<p>The denominators all equal one (or the term is absent), so this reduces to:</p>
<p>or equivalently (as consistent with the "method" described above):</p>
<p>In binary (base 2) math, multiplication by a power of 2 is merely a register shift operation. Thus, multiplying by 2 is calculated in base-2 by an arithmetic shift. The factor (2) is a right arithmetic shift, a (0) results in no operation (since 2 = 1, is the multiplicative identity element), and a (2) results in a left arithmetic shift. The multiplication product can now be quickly calculated using only arithmetic shift operations, addition and subtraction.</p>
<p>The method is particularly fast on processors supporting a single-instruction shift-and-addition-accumulate. Compared to a C floating-point library, Horner's method sacrifices some accuracy, however it is nominally 13 times faster (16 times faster when the "canonical signed digit" (CSD) form is used), and uses only 20% of the code space.</p>
<h3>Polynomial root finding</h3>
<p>Using Horner's method in combination with Newton's method, it is possible to approximate the real roots of a polynomial. The algorithm works as follows. Given a polynomial <img class="mwe-math-fallback-image-inline tex" alt="p_n(x)" src="//upload.wikimedia.org/math/6/6/1/661876bde94f4fa48421a032066c6465.png"> of degree <img class="mwe-math-fallback-image-inline tex" alt="n" src="//upload.wikimedia.org/math/7/b/8/7b8b965ad4bca0e41ab51de7b31363a1.png"> with zeros <img class="mwe-math-fallback-image-inline tex" alt=" z_n &lt; z_{n-1} &lt; \cdots &lt; z_1 " src="//upload.wikimedia.org/math/1/2/4/1242a5615da6c5ec60c46697b093c08e.png">, make some initial guess <img class="mwe-math-fallback-image-inline tex" alt=" x_0 " src="//upload.wikimedia.org/math/0/b/2/0b21a666a81629962ade8afd967826ed.png"> such that <img class="mwe-math-fallback-image-inline tex" alt=" x_0 &gt; z_1 " src="//upload.wikimedia.org/math/8/0/6/806b44476338bd3b90c546dd0da201e7.png">. Now iterate the following two steps:</p>
<p>1. Using Newton's method, find the largest zero <img class="mwe-math-fallback-image-inline tex" alt="z_1" src="//upload.wikimedia.org/math/7/b/1/7b130c2e8f1d1584f9440cbfd6883b1a.png"> of <img class="mwe-math-fallback-image-inline tex" alt="p_n(x)" src="//upload.wikimedia.org/math/6/6/1/661876bde94f4fa48421a032066c6465.png"> using the guess <img class="mwe-math-fallback-image-inline tex" alt="x_0" src="//upload.wikimedia.org/math/0/b/2/0b21a666a81629962ade8afd967826ed.png">.</p>
<p>2. Using Horner's method, divide out <img class="mwe-math-fallback-image-inline tex" alt="(x-z_1)" src="//upload.wikimedia.org/math/a/5/c/a5cec429175226c1d6171c4e8e299501.png"> to obtain <img class="mwe-math-fallback-image-inline tex" alt="p_{n-1}" src="//upload.wikimedia.org/math/6/6/3/663e987c849632162d53a944ca61829b.png">. Return to step 1 but use the polynomial <img class="mwe-math-fallback-image-inline tex" alt="p_{n-1}" src="//upload.wikimedia.org/math/6/6/3/663e987c849632162d53a944ca61829b.png"> and the initial guess <img class="mwe-math-fallback-image-inline tex" alt="z_1" src="//upload.wikimedia.org/math/7/b/1/7b130c2e8f1d1584f9440cbfd6883b1a.png">.</p>
<p>These two steps are repeated until all real zeros are found for the polynomial. If the approximated zeros are not precise enough, the obtained values can be used as initial guesses for Newton's method but using the full polynomial rather than the reduced polynomials.</p>
<h4>Example</h4>
<p>Consider the polynomial,</p>
<p>which can be expanded to</p>
<p>From the above we know that the largest root of this polynomial is 7 so we are able to make an initial guess of 8. Using Newton's method the first zero of 7 is found as shown in black in the figure to the right. Next <img class="mwe-math-fallback-image-inline tex" alt="p(x)" src="//upload.wikimedia.org/math/4/1/3/4130c89f2d12c3ac81aba3adbff28685.png"> is divided by <img class="mwe-math-fallback-image-inline tex" alt="(x-7)" src="//upload.wikimedia.org/math/5/d/b/5dbc51af19e5296a02d9ba147cd72070.png"> to obtain</p>
<p>which is drawn in red in the figure to the right. Newton's method is used to find the largest zero of this polynomial with an initial guess of 7. The largest zero of this polynomial which corresponds to the second largest zero of the original polynomial is found at 3 and is circled in red. The degree 5 polynomial is now divided by <img class="mwe-math-fallback-image-inline tex" alt="(x-3)" src="//upload.wikimedia.org/math/a/7/1/a71862c3832d2ca6d0d94e476406dcdc.png"> to obtain</p>
<p>which is shown in yellow. The zero for this polynomial is found at 2 again using Newton's method and is circled in yellow. Horner's method is now used to obtain</p>
<p>which is shown in green and found to have a zero at −3. This polynomial is further reduced to</p>
<p>which is shown in blue and yields a zero of −5. The final root of the original polynomial may be found by either using the final zero as an initial guess for Newton's method, or by reducing <img class="mwe-math-fallback-image-inline tex" alt="p_2(x)" src="//upload.wikimedia.org/math/9/4/e/94ef6bd1d5bfa024344223cadc99bb0c.png"> and solving the linear equation. As can be seen, the expected roots of −8, −5, −3, 2, 3, and 7 were found.</p>
<h4>Octave implementation</h4>
<p>The following Octave code was used in the example above to implement Horner's method.</p>
<p>WHATSON? f6c9c9cd-2079-4746-ba7a-66bd93cae1b8</p>
<pre>
function [y b] = horner(a,x)
  % Input a is the polynomial coefficient vector, x the value to be evaluated at.
  % The output y is the evaluated polynomial and b the divided coefficient vector.
  b(1) = a(1);
  for i = 2:length(a)
    b(i) = a(i)+x*b(i-1);
  end
  y = b(length(a));
  b = b(1:length(b)-1);
end
</pre>
<h4>Python implementation</h4>
<p>The following Python code implements Horner's method.</p>
<p>WHATSON? 5bd8f9f6-ba6b-403d-8621-421643dac222</p>
<pre>
def horner(x, *polynomial):
    """A function that implements the Horner Scheme for evaluating a
    polynomial of coefficients *polynomial in x."""
    result = 0
    for coefficient in polynomial:
        result = result * x + coefficient
    return result
</pre>
<h2>Application</h2>
<p>Horner's method can be used to convert between different positional numeral systems – in which case <i>x</i> is the base of the number system, and the <i>a</i><sub><i>i</i></sub> coefficients are the digits of the base-<i>x</i> representation of a given number – and can also be used if <i>x</i> is a matrix, in which case the gain in computational efficiency is even greater. In fact, when <i>x</i> is a matrix, further acceleration is possible which exploits the structure of matrix multiplication, and only <img class="mwe-math-fallback-image-inline tex" alt="\sqrt{n}" src="//upload.wikimedia.org/math/d/4/3/d435c6dd92f3b3430d735f360cba0ec9.png"> instead of <i>n</i> multiplies are needed (at the expense of requiring more storage) using the 1973 method of Paterson and Stockmeyer.</p>
<h2>Efficiency</h2>
<p>Evaluation using the monomial form of a degree-<i>n</i> polynomial requires at most <i>n</i> additions and (<i>n</i> + <i>n</i>)/2 multiplications, if powers are calculated by repeated multiplication and each monomial is evaluated individually. (This can be reduced to <i>n</i> additions and 2<i>n</i> − 1 multiplications by evaluating the powers of <i>x</i> iteratively.) If numerical data are represented in terms of digits (or bits), then the naive algorithm also entails storing approximately 2<i>n</i> times the number of bits of <i>x</i> (the evaluated polynomial has approximate magnitude <i>x</i>, and one must also store <i>x</i> itself). By contrast, Horner's method requires only <i>n</i> additions and <i>n</i> multiplications, and its storage requirements are only <i>n</i> times the number of bits of <i>x</i>. Alternatively, Horner's method can be computed with <i>n</i> fused multiply–adds. Horner's method can also be extended to evaluate the first <i>k</i> derivatives of the polynomial with <i>kn</i> additions and multiplications.</p>
<p>Horner's method is optimal, in the sense that any algorithm to evaluate an arbitrary polynomial must use at least as many operations. Alexander Ostrowski proved in 1954 that the number of additions required is minimal. Victor Pan proved in 1966 that the number of multiplications is minimal. However, when <i>x</i> is a matrix, Horner's method is not optimal.</p>
<p>This assumes that the polynomial is evaluated in monomial form and no preconditioning of the representation is allowed, which makes sense if the polynomial is evaluated only once. However, if preconditioning is allowed and the polynomial is to be evaluated many times, then faster algorithms are possible. They involve a transformation of the representation of the polynomial. In general, a degree-<i>n</i> polynomial can be evaluated using only <img class="mwe-math-fallback-image-inline tex" alt="{\scriptstyle{\left\lfloor n/2 \right\rfloor + 2}}" src="//upload.wikimedia.org/math/c/9/7/c979d366921b31e77b6c72a7b83ce9b8.png"> multiplications and <i>n</i> additions (see Knuth: <i>The Art of Computer Programming</i>, Vol.2).</p>
<h2>History</h2>
<p>Horner's paper entitled "A new method of solving numerical equations of all orders, by continuous approximation", was read before the Royal Society of London, at its meeting on July 1, 1819, with Davies Gilbert, Vice-President and Treasurer, in the chair; this was the final meeting of the session before the Society adjorned for its Summer recess. When a sequel was read before the Society in 1823, it was again at the final meeting of the session. On both occasions, papers by James Ivory, FRS, were also read. In 1819, it was Horner's paper that got through to publication in the "Philosophical Transactions". later in the year, Ivory's paper falling by the way, despite Ivory being a Fellow; in 1823, when a total of ten papers were read, fortunes as regards publication, were reversed. But Gilbert, who had strong connections with the West of England and may have had social contact with Horner, resident as Horner was in Bristol and Bath, published his own survey of Horner-type methods earlier in 1823.</p>
<p>Horner's paper in Part II of <i>Philosophical Transactions of the Royal Society of London</i> for 1819 was warmly and expansively welcomed by a reviewer in the issue of <i>The Monthly Review: or, Literary Journal</i> for April, 1820; in comparison, a technical paper by Charles Babbage is dismissed curtly in this review. However, the reviewer noted that another, similar method had also recently been published by the architect and mathematical expositor, Peter Nicholson. This theme is developed in a further review of some of Nicholson's books in the issue of <i>The Monthly Review</i> for December, 1820, which in turn ends with notice of the appearance of a booklet by Theophilus Holdred, from whom Nicholson acknowledges he obtained the gist of his approach in the first place, although claiming to have improved upon it. The sequence of reviews is concluded in the issue of <i>The Monthly Review</i> for September, 1821, with the reviewer concluding that whereas Holdred was the first person to discover a direct and general practical solution of numerical equations, he had not reduced it to its simplest form by the time of Horner's publication, and saying that had Holdred published forty years earlier when he first discovered his method, his contribution could be more easily recognized. The reviewer is exceptionally well-informed, even having sighted Horner's preparatory correspondence with Peter Barlow in 1818, seeking work of Budan. The Bodlean Library, Oxford has the Editor's annotated copy of <i>The Monthly Review</i> from which it is clear that the most active reviewer in mathematics in 1814 and 1815 (the last years for which this information has been published) was none other than Peter Barlow,one of the foremost specialists on approximation theory of the period, suggesting that it was Barlow, who wrote this sequence of reviews. As it also happened, Henry Atkinson, of Newcastle, devised a similar approximation scheme in 1809; he had consulted his fellow Geordie, Charles Hutton, another specialist and a senior colleague of Barlow at the Royal Military Academy, Woolwich, only to be advised that, while his work was publishable, it was unlikely to have much impact. J. R. Young, writing in the mid-1830s, concluded that Holdred's first method replicated Atkinson's while his improved method was only added to Holdred's booklet some months after its first appearance in 1820, when Horner's paper was already in circulation.</p>
<p>The feature of Horner's writing that most distinguishes it from his English contemporaries is the way he draws on the Continental literature, notably the work of Arbogast. The advocacy, as well as the detraction, of Horner's Method has this as an unspoken subtext. Quite how he gained that familiarity has not been determined. Horner is known to have made a close reading of John Bonneycastle's book on algebra. Bonneycastle recognizes that Arbogast has the general, combinatorial expression for the reversion of series, a project going back at least to Newton. But Bonneycastle's main purpose in mentioning Arbogast is not to praise him, but to observe that Arbogast's notation is incompatible with the approach he adopts. The gap in Horner's reading was the work of Paolo Ruffini, except that, as far as awareness of Ruffini goes, citations of Ruffini's work by authors, including medical authors, in <i>Philosophical Transactions</i> speak volumes: there are none - Ruffini's name only appears in 1814, recording a work he donated to the Royal Society. Ruffini might have done better if his work had appeared in French, as had Malfatti's Problem in the reformulation of Joseph Diaz Gergonne, or had he written in French, as had Antonio Cagnoli, a source quoted by Bonneycastle on series reversion (today, Cagnoli is in the Italian Wikipedia, as shown, but has yet to make it into either French or English).</p>
<p>Fuller showed that the method in Horner's 1819 paper differs from what afterwards became known as 'Horner's method' and that in consequence the priority for this method should go to Holdred (1920). This view may be compared with the remarks concerning the works of Horner and Holdred in the previous paragraph. Fuller also takes aim at Augustus De Morgan. Precocious though Augustus de Morgan was, he was not the reviewer for <i>The Monthly Review</i>, while several others - Thomas Stephens Davies, J. R. Young, Stephen Fenwick, T. T. Wilkinson - wrote Horner firmly into their records, not least Horner himself, as he published extensively up until the year of his death in 1837. His paper in 1819 was one that would have been difficult to miss. In contrast, the only other mathematical sighting of Holdred is a single named contribution to <i>The Gentleman's Mathematical Companion</i>, an answer to a problem.</p>
<p>It is questionable to what extent it was De Morgan's advocacy of Horner's priority in discovery that led to "Horner's method" being so called in textbooks, but it is true that those suggesting this tend themselves to know of Horner largely through intermediaries, of whom De Morgan made himself a prime example. However, this method <i>qua</i> method was known long before Horner. In reverse chronological order, Horner's method was already known to:</p>
<ul>
<li>Paolo Ruffini in 1809 (see Ruffini's rule)</li>
<li>Isaac Newton in 1669 (but precise reference needed)</li>
<li>the Chinese mathematician Zhu Shijie in the 14th century</li>
<li>the Chinese mathematician Qin Jiushao in his <i>Mathematical Treatise in Nine Sections</i> in the 13th century</li>
<li>the Persian mathematician Sharaf al-Dīn al-Tūsī in the 12th century</li>
<li>the Chinese mathematician Jia Xian in the 11th century (Song Dynasty)</li>
<li><i>The Nine Chapters on the Mathematical Art</i>, a Chinese work of the Han Dynasty (202 BC – 220 AD) edited by Liu Hui (fl. 3rd century).</li>
</ul>
<p>However, this observation on its own masks significant differences in conception and also, as noted with Ruffini's work, issues of accessibility.</p>
<p>Qin Jiushao, in his <i>Shu Shu Jiu Zhang</i> (<i>Mathematical Treatise in Nine Sections</i>; 1247), presents a portfolio of methods of Horner-type for solving polynomial equations, which was based on earlier works of the 11th century Song dynasty mathematician Jia Xian; for example, one method is specifically suited to bi-qintics, of which Qin gives an instance, in keeping with the then Chinese custom of case studies. The first person writing in English to note the connection with Horner's method was Alexander Wylie, writing in <i>The North China Herald</i> in 1852; perhaps conflating and misconstruing different Chinese phrases, Wylie calls the method <i>Harmoniously Alternating Evolution</i> (which does not agree with his Chinese, <i>linglong kaifang</i>, not that at that date he uses pinyin), working the case of one of Qin's quartics and giving, for comparison, the working with Horner's method. Yoshio Mikami in <i>Development of Mathematics in China and Japan</i> published in Leipzig in 1913, gave a detailed description of Qin's method, using the quartic illustrated to the above right in a worked example; he wrote: "who can deny the fact of Horner's illustrious process being used in China at least nearly six long centuries earlier than in Europe ... We of course don't intend in any way to ascribe Horner's invention to a Chinese origin, but the lapse of time sufficiently makes it not altogether impossible that the Europeans could have known of the Chinese method in a direct or indirect way.". However, as Mikami is also aware, it was <i>not altogether impossible</i> that a related work, <i>Si Yuan Yu Jian</i> (<i>Jade Mirror of the Four Unknowns; 1303)</i> by Zhu Shijie might make the shorter journey across to Japan, but seemingly it never did, although another work of Zhu, <i>Suan Xue Qi Meng</i>, had a seminal influence on the development of traditional mathematics in the Edo period, starting in the mid-1600s. Ulrich Libbrecht (at the time teaching in school, but subsequently a professor of comparative philosophy) gave a detailed description in his doctoral thesis of Qin's method, he concluded: <i>It is obvious that this procedure is a Chinese invention....the method was not known in India</i>. He said, Fibonacci probably learned of it from Arabs, who perhaps borrowed from the Chinese. Here, the problems is that there is no more evidence for this speculation than there is of the method being known in India. Of course, the extraction of square and cube roots along similar lines is already discussed by Liu Hui in connection with Problems IV.16 and 22 in <i>Jiu Zhang Suan Shu</i>, while Wang Xiaotong in the 7th century supposes his readers can solve cubics by an approximation method he does not specify.</p>
<h2>See also</h2>
<ul>
<li>Clenshaw algorithm to evaluate polynomials in Chebyshev form</li>
<li>De Boor's algorithm to evaluate splines in B-spline form</li>
<li>De Casteljau's algorithm to evaluate polynomials in Bézier form</li>
<li>Estrin's scheme to facilitate parallelization on modern computer architectures</li>
<li>Lill's method to approximate roots graphically</li>
<li>Ruffini's rule to divide a polynomial by a binomial of the form x − r</li>
</ul>
</body>
</html>