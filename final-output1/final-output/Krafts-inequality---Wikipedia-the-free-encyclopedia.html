<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Krafts-inequality---Wikipedia-the-free-encyclopedia.html</title></head>
<body>
<h1>Kraft's inequality</h1>
<p>In coding theory, <b>Kraft's inequality</b>, named after Leon Kraft, gives a sufficient condition for the existence of a prefix code and necessary condition for the existence of a uniquely decodable code for a given set of codeword lengths. Its applications to prefix codes and trees often find use in computer science and information theory.</p>
<p>More specifically, Kraft's inequality limits the lengths of codewords in a prefix code: if one takes an exponential of the length of each valid codeword, the resulting set of values must look like a probability mass function, that is, it must have total measure less than or equal to one. Kraft's inequality can be thought of in terms of a constrained budget to be spent on codewords, with shorter codewords being more expensive.</p>
<ul>
<li>If Kraft's inequality holds with strict inequality, the code has some redundancy.</li>
<li>If Kraft's inequality holds with equality, the code in question is a complete code.</li>
<li>If Kraft's inequality does not hold, the code is not uniquely decodable.</li>
</ul>
<p>Kraft's inequality was published by Kraft (1949). However, Kraft's paper discusses only prefix codes, and attributes the analysis leading to the inequality to Raymond Redheffer. The inequality is sometimes also called the <b>Kraftâ€“McMillan theorem</b> after the independent discovery of the result by McMillan (1956); McMillan proves the result for the general case of uniquely decodable codes, and attributes the version for prefix codes to a spoken observation in 1955 by Joseph Leo Doob.</p>
<p></p>
<h2>Contents</h2>
<ul>
<li>1 Examples
<ul>
<li>1.1 Binary trees</li>
<li>1.2 Chaitin's constant</li>
</ul>
</li>
<li>2 Formal statement</li>
<li>3 Proof
<ul>
<li>3.1 Proof for prefix codes</li>
<li>3.2 Probabilistic Proof for prefix codes</li>
<li>3.3 Proof of the general case</li>
<li>3.4 Alternative construction for the converse</li>
</ul>
</li>
<li>4 Notes</li>
<li>5 References</li>
<li>6 External links</li>
</ul>
<ul>
<li>1.1 Binary trees</li>
<li>1.2 Chaitin's constant</li>
</ul>
<ul>
<li>3.1 Proof for prefix codes</li>
<li>3.2 Probabilistic Proof for prefix codes</li>
<li>3.3 Proof of the general case</li>
<li>3.4 Alternative construction for the converse</li>
</ul>
<p></p>
<h2>Examples</h2>
<h3>Binary trees</h3>
<p>Any binary tree can be viewed as defining a prefix code for the leaves of the tree. Kraft's inequality states that</p>
<p>Here the sum is taken over the leaves of the tree, i.e. the nodes without any children. The depth is the distance to the root node. In the tree to the right, this sum is</p>
<h3>Chaitin's constant</h3>
<p>In algorithmic information theory, Chaitin's constant is defined as</p>
<p>This is an infinite sum, which has one summand for every syntactically correct program that halts. |<i>p</i>| stands for the length of the bit string of <i>p</i>. The programs are required to be prefix-free in the sense that no summand has a prefix representing a syntactically valid program that halts. Hence the bit strings are prefix codes, and Kraft's inequality gives that <img class="mwe-math-fallback-image-inline tex" alt="\Omega \leq 1" src="//upload.wikimedia.org/math/b/0/5/b05446bf671593ba04da22c1c8037d52.png">.</p>
<h2>Formal statement</h2>
<p>Let each source symbol from the alphabet</p>
<p>be encoded into a uniquely decodable code over an alphabet of size <img class="mwe-math-fallback-image-inline tex" alt="r" src="//upload.wikimedia.org/math/4/b/4/4b43b0aee35624cd95b910189b3dc231.png"> with codeword lengths</p>
<p>Then</p>
<p>Conversely, for a given set of natural numbers <img class="mwe-math-fallback-image-inline tex" alt="\ell_1,\ell_2,\ldots,\ell_n\," src="//upload.wikimedia.org/math/6/8/0/680e26f63ebd8201e4fe94978fe64081.png"> satisfying the above inequality, there exists a uniquely decodable code over an alphabet of size <img class="mwe-math-fallback-image-inline tex" alt="r" src="//upload.wikimedia.org/math/4/b/4/4b43b0aee35624cd95b910189b3dc231.png"> with those codeword lengths.</p>
<p>A commonly occurring special case of a uniquely decodable code is a prefix code. Kraft's inequality therefore also holds for any prefix code.</p>
<h2>Proof</h2>
<h3>Proof for prefix codes</h3>
<p>Suppose that <img class="mwe-math-fallback-image-inline tex" alt="\ell_1 \leq \ell_2 \leq ... \leq \ell_n " src="//upload.wikimedia.org/math/0/c/1/0c102c34152638caea71d8798728dbe6.png">. Let <img class="mwe-math-fallback-image-inline tex" alt="A" src="//upload.wikimedia.org/math/7/f/c/7fc56270e7a70fa81a5935b72eacbe29.png"> be the full <img class="mwe-math-fallback-image-inline tex" alt="r" src="//upload.wikimedia.org/math/4/b/4/4b43b0aee35624cd95b910189b3dc231.png">-ary tree of depth <img class="mwe-math-fallback-image-inline tex" alt="\ell_n" src="//upload.wikimedia.org/math/1/c/2/1c242081df280bddf733e2a7ef8db76c.png">. Every word of length <img class="mwe-math-fallback-image-inline tex" alt="\ell \leq \ell_n" src="//upload.wikimedia.org/math/a/9/0/a903b407247e6c9642ce8d1c93d5cd4d.png"> over an <img class="mwe-math-fallback-image-inline tex" alt="r" src="//upload.wikimedia.org/math/4/b/4/4b43b0aee35624cd95b910189b3dc231.png">-ary alphabet corresponds to a node in this tree at depth <img class="mwe-math-fallback-image-inline tex" alt="\ell" src="//upload.wikimedia.org/math/3/3/4/334ce9eb79df1178b0380461c9eaa09e.png">. The <img class="mwe-math-fallback-image-inline tex" alt="i" src="//upload.wikimedia.org/math/8/6/5/865c0c0b4ab0e063e5caa3387c1a8741.png">th word in the prefix code corresponds to a node <img class="mwe-math-fallback-image-inline tex" alt="v_i" src="//upload.wikimedia.org/math/f/0/e/f0e66f55342ef85ba8be3415dd92d8e2.png">; let <img class="mwe-math-fallback-image-inline tex" alt="A_i" src="//upload.wikimedia.org/math/e/8/a/e8aaf87d9a5c35b14cfbc370d3fd7b21.png"> be the set of all leaf nodes in the subtree of <img class="mwe-math-fallback-image-inline tex" alt="A" src="//upload.wikimedia.org/math/7/f/c/7fc56270e7a70fa81a5935b72eacbe29.png"> rooted at <img class="mwe-math-fallback-image-inline tex" alt="v_i" src="//upload.wikimedia.org/math/f/0/e/f0e66f55342ef85ba8be3415dd92d8e2.png">. Clearly</p>
<p>Since the code is a prefix code,</p>
<p>Thus, given that the total number of nodes at depth <img class="mwe-math-fallback-image-inline tex" alt="\ell_n" src="//upload.wikimedia.org/math/1/c/2/1c242081df280bddf733e2a7ef8db76c.png"> is <img class="mwe-math-fallback-image-inline tex" alt="r^{\ell_n}" src="//upload.wikimedia.org/math/9/5/5/9551eff38eee9d9cb244583163febd14.png">,</p>
<p>from which the result follows.</p>
<p>Conversely, given any ordered sequence of <img class="mwe-math-fallback-image-inline tex" alt="n" src="//upload.wikimedia.org/math/7/b/8/7b8b965ad4bca0e41ab51de7b31363a1.png"> natural numbers,</p>
<p>satisfying the Kraft inequality, one can construct a prefix code with codeword lengths equal to <img class="mwe-math-fallback-image-inline tex" alt="\ell_i" src="//upload.wikimedia.org/math/e/d/2/ed283b1f5f9da881e8b8fc044d5341ee.png"> by pruning subtrees from a full <img class="mwe-math-fallback-image-inline tex" alt="r" src="//upload.wikimedia.org/math/4/b/4/4b43b0aee35624cd95b910189b3dc231.png">-ary tree of depth <img class="mwe-math-fallback-image-inline tex" alt="\ell_n" src="//upload.wikimedia.org/math/1/c/2/1c242081df280bddf733e2a7ef8db76c.png">. First choose any node from the full tree at depth <img class="mwe-math-fallback-image-inline tex" alt="\ell_1" src="//upload.wikimedia.org/math/6/c/7/6c72c4de2714433908be059a006a95d9.png"> and remove all of its descendants. This removes <img class="mwe-math-fallback-image-inline tex" alt="r^{-\ell_1}" src="//upload.wikimedia.org/math/c/0/c/c0cc7017df6765c1e5e4c0e4339abd4c.png"> fraction of the nodes from the full tree from being considered for the rest of the remaining codewords. The next iteration removes <img class="mwe-math-fallback-image-inline tex" alt="r^{-\ell_2}" src="//upload.wikimedia.org/math/d/b/4/db4de224f26a8dd9cc9f2d8823889d65.png"> fraction of the full tree for total of <img class="mwe-math-fallback-image-inline tex" alt="r^{-\ell_1}+r^{-\ell_2}" src="//upload.wikimedia.org/math/7/a/a/7aae7e9c2b71de4d44e17b9dcc666b41.png">. After <img class="mwe-math-fallback-image-inline tex" alt="m" src="//upload.wikimedia.org/math/6/f/8/6f8f57715090da2632453988d9a1501b.png"> iterations,</p>
<p>fraction of the full tree nodes are removed from consideration for any remaining codewords. But, by the assumption, this sum is less than 1 for all <img class="mwe-math-fallback-image-inline tex" alt="m&lt;n" src="//upload.wikimedia.org/math/4/8/5/48574888561da3083126521f8d1b6682.png">. Thus prefix code with lengths <img class="mwe-math-fallback-image-inline tex" alt="\ell_i" src="//upload.wikimedia.org/math/e/d/2/ed283b1f5f9da881e8b8fc044d5341ee.png"> can be constructed for all <img class="mwe-math-fallback-image-inline tex" alt="n" src="//upload.wikimedia.org/math/7/b/8/7b8b965ad4bca0e41ab51de7b31363a1.png"> source symbols.</p>
<h3>Probabilistic Proof for prefix codes</h3>
<p>Generate a sequence of symbols from the <i>r</i> character alphabet, independently and uniformly at random. Define <i>E</i><sub>i</sub> to be the event that codeword <i>i</i> is a prefix of this sequence. Because we have a prefix code, these events are mutually exclusive. Therefore,</p>
<p><img class="mwe-math-fallback-image-inline tex" alt="\sum r^{-li} = \sum P(E_i) = P(\cup E_i) \leq 1." src="//upload.wikimedia.org/math/1/3/d/13d4c2a404ced95621f4c256e8b9da32.png"></p>
<p>The proof of the converse half of the result is given above.</p>
<h3>Proof of the general case</h3>
<p>Consider the generating function in inverse of <i>x</i> for the code <i>S</i></p>
<p>in which <img class="mwe-math-fallback-image-inline tex" alt="p_\ell" src="//upload.wikimedia.org/math/d/3/c/d3c556ab5170c36dc85d1e91e61ae01b.png">â€”the coefficient in front of <img class="mwe-math-fallback-image-inline tex" alt="x^{-\ell}" src="//upload.wikimedia.org/math/0/1/f/01fe1e70470bd2a15deebff200d5b7a8.png">â€”is the number of distinct codewords of length <img class="mwe-math-fallback-image-inline tex" alt="\ell" src="//upload.wikimedia.org/math/3/3/4/334ce9eb79df1178b0380461c9eaa09e.png">. Here min is the length of the shortest codeword in <i>S</i>, and max is the length of the longest codeword in <i>S</i>.</p>
<p>Consider all <i>m</i>-powers <i>S</i>, in the form of words <img class="mwe-math-fallback-image-inline tex" alt="s_{i_1}s_{i_2}\dots s_{i_m}" src="//upload.wikimedia.org/math/a/5/1/a51ca342d8f562df8b4079644c7f1820.png">, where <img class="mwe-math-fallback-image-inline tex" alt="i_1, i_2, \dots, i_m" src="//upload.wikimedia.org/math/6/6/1/661d31a0b67d099964c3e3068dfcb0b1.png"> are indices between 1 and <i>n</i>. Note that, since <i>S</i> was assumed to uniquely decodable, <img class="mwe-math-fallback-image-inline tex" alt="s_{i_1}s_{i_2}\dots s_{i_m}=s_{j_1}s_{j_2}\dots s_{j_m}" src="//upload.wikimedia.org/math/7/0/1/70198006a177b3294af0149714c0fdb7.png"> implies <img class="mwe-math-fallback-image-inline tex" alt="i_1=j_1, i_2=j_2, \dots, i_m=j_m" src="//upload.wikimedia.org/math/6/9/e/69e2f13d8ed85fe9d9c71e2515ede9ab.png">. Because of this property, one can compute the generating function <img class="mwe-math-fallback-image-inline tex" alt="G(x)" src="//upload.wikimedia.org/math/5/d/0/5d09697085e8b2d48446837da84789a3.png"> for <img class="mwe-math-fallback-image-inline tex" alt="S^m" src="//upload.wikimedia.org/math/2/8/8/288eaa3b24cf5344d6937ff599a39492.png"> from the generating function <img class="mwe-math-fallback-image-inline tex" alt="F(x)" src="//upload.wikimedia.org/math/d/7/6/d76f2c4d6bdf142af5106c3f36e9e970.png"> as</p>
<p>Here, similarly as before, <img class="mwe-math-fallback-image-inline tex" alt="q_\ell" src="//upload.wikimedia.org/math/9/b/9/9b903bea05eaee8ec1d083dff50c0b4f.png">â€”the coefficient in front of <img class="mwe-math-fallback-image-inline tex" alt="x^{-\ell}" src="//upload.wikimedia.org/math/0/1/f/01fe1e70470bd2a15deebff200d5b7a8.png"> in <img class="mwe-math-fallback-image-inline tex" alt="G(x)" src="//upload.wikimedia.org/math/5/d/0/5d09697085e8b2d48446837da84789a3.png">â€”is the number of words of length <img class="mwe-math-fallback-image-inline tex" alt="\ell" src="//upload.wikimedia.org/math/3/3/4/334ce9eb79df1178b0380461c9eaa09e.png"> in <img class="mwe-math-fallback-image-inline tex" alt="S^m" src="//upload.wikimedia.org/math/2/8/8/288eaa3b24cf5344d6937ff599a39492.png">. Clearly, <img class="mwe-math-fallback-image-inline tex" alt="q_\ell" src="//upload.wikimedia.org/math/9/b/9/9b903bea05eaee8ec1d083dff50c0b4f.png"> cannot exceed <img class="mwe-math-fallback-image-inline tex" alt="r^\ell" src="//upload.wikimedia.org/math/8/d/8/8d8e92480f46e0415a1c8fec39d9598f.png">. Hence for any positive <i>x</i></p>
<p>Substituting the value <i>x</i>Â =Â <i>r</i> we have</p>
<p>for any positive integer <img class="mwe-math-fallback-image-inline tex" alt="m" src="//upload.wikimedia.org/math/6/f/8/6f8f57715090da2632453988d9a1501b.png">. The left side of the inequality grows exponentially in <img class="mwe-math-fallback-image-inline tex" alt="m" src="//upload.wikimedia.org/math/6/f/8/6f8f57715090da2632453988d9a1501b.png"> and the right side only linearly. The only possibility for the inequality to be valid for all <img class="mwe-math-fallback-image-inline tex" alt="m" src="//upload.wikimedia.org/math/6/f/8/6f8f57715090da2632453988d9a1501b.png"> is that <img class="mwe-math-fallback-image-inline tex" alt=" F(r) \le 1 " src="//upload.wikimedia.org/math/0/6/4/064a236a736f5320f5c815d0c22792cc.png">. Looking back on the definition of <img class="mwe-math-fallback-image-inline tex" alt="F(x)" src="//upload.wikimedia.org/math/d/7/6/d76f2c4d6bdf142af5106c3f36e9e970.png"> we finally get the inequality.</p>
<h3>Alternative construction for the converse</h3>
<p>Given a sequence of <img class="mwe-math-fallback-image-inline tex" alt="n" src="//upload.wikimedia.org/math/7/b/8/7b8b965ad4bca0e41ab51de7b31363a1.png"> natural numbers,</p>
<p>satisfying the Kraft inequality, we can construct a prefix code as follows. Define the <i>i</i> codeword, <i>C</i><sub>i</sub>, to be the first <i>l</i><sub>i</sub> digits after the radix point (e.g. decimal point) in the base <i>r</i> representation of</p>
<p><img class="mwe-math-fallback-image-inline tex" alt="\sum_{j = 1}^{i - 1} r^{-l_j}." src="//upload.wikimedia.org/math/3/2/a/32a72d4b96dcbaa0991653b4573f19dc.png"></p>
<p>Note that by Kraft's inequality, this sum is never more than 1. Hence the codewords capture the entire value of the sum. Therefore, for <i>j</i> &gt; <i>i</i>, the first <i>l</i><sub><i>i</i></sub> digits of <i>C</i><sub><i>j</i></sub> form a larger number than <i>C</i><sub>i</sub>, so the code is prefix free.</p>
<p>See also Canonical Huffman code.</p>
<h2>Notes</h2>
<ol>
<li><b>^</b> Cover, Thomas M.; Thomas, Joy A. (2006), <i>Elements of Information Theory</i> (pdf) (2nd ed.), John Wiley &amp; Sons, Inc, pp.Â 108â€“109, doi:10.1002/047174882X.ch5, ISBNÂ 0-471-24195-4Â </li>
</ol>
</body>
</html>