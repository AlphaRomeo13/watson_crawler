<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Cobhams-thesis---Wikipedia-the-free-encyclopedia.html</title></head>
<body>
<h1>Cobham's thesis</h1>
<p><b>Cobham's thesis</b>, also known as <b>Cobham–Edmonds thesis</b> (named after Alan Cobham and Jack Edmonds), asserts that computational problems can be feasibly computed on some computational device only if they can be computed in polynomial time; that is, if they lie in the complexity class <b>P</b>.</p>
<p>Formally, to say that a problem can be solved in polynomial time is to say that there exists an algorithm that, given an <i>n</i>-bit instance of the problem as input, can produce a solution in time O(n), where <i>c</i> is a constant that depends on the problem but not the particular instance of the problem.</p>
<p>Alan Cobham's 1965 paper entitled "The intrinsic computational difficulty of functions" is one of the earliest mentions of the concept of the complexity class P, consisting of problems decidable in polynomial time. Cobham theorized that this complexity class was a good way to describe the set of feasibly computable problems. Any problem that cannot be contained in P is not feasible, but if a real-world problem can be solved by an algorithm existing in P, generally such an algorithm will eventually be discovered.</p>
<p>The class P is a useful object of study because it is not sensitive to the details of the model of computation: for example, a change from a single-tape Turing machine to a multi-tape machine can lead to a quadratic speedup, but any algorithm that runs in polynomial time under one model also does so on the other.</p>
<p>In similar spirit, NC complexity class can be thought to capture problems "effectively solvable" on a parallel computer.</p>
<h2>Reasoning</h2>
<p>The thesis is widely considered to be a good rule of thumb for real-life problems. Typical input lengths that users and programmers are interested in are approximately between 100 and 1,000,000. Consider an input length of n=100 and a polynomial algorithm whose running time is n. This is a typical running time for a polynomial algorithm. (See the "Objections" section for a discussion of atypical running times.) The number of steps that it will require, for n=100, is 100=10000. A typical CPU will be able to do approximately 10 operations per second (this is extremely simplified). So this algorithm will finish on the order of (10000 ÷10) = .00001 seconds. A running time of .00001 seconds is reasonable, and that's why this is called a practical algorithm. The same algorithm with an input length of 1,000,000 will take on the order of 17 minutes, which is also a reasonable time for most (non-real-time) applications.</p>
<p>Meanwhile, an algorithm that runs in exponential time might have a running time of 2. The number of operations that it will require, for n=100, is 2. It will take (2 ÷ 10) ≈ 1.3×10 seconds, which is (1.3×10 ÷ 31556926) ≈ 4.1×10 years, longer than the age of the universe. The largest problem this algorithm could solve in a day would have n=46, which seems very small.</p>
<p>Mathematically speaking, for big enough inputs, <i>any</i> polynomial time algorithm will beat <i>any</i> exponential time algorithm, and by arbitrarily large amounts. The only question is how big the input must be for this crossover to occur.</p>
<h2>Objections</h2>
<p>There are many lines of objection to Cobham's thesis. The thesis essentially states that "<b>P</b>" means "easy, fast, and practical," while "not in <b>P</b>" means "hard, slow, and impractical." But this is not always true. To begin with, it abstracts away some important variables that influence the runtime in practice:</p>
<ul>
<li>It ignores constant factors and lower-order terms.</li>
<li>It ignores the size of the exponent. The time hierarchy theorem proves the existence of problems in <b>P</b> requiring arbitrarily large exponents.</li>
<li>It ignores the typical size of the input.</li>
</ul>
<p>All three are related, and are general complaints about analysis of algorithms, but they particularly apply to Cobham's thesis since it makes an explicit claim about practicality. Under Cobham's thesis, we are to call a problem for which the best algorithm takes 10n instructions feasible, and a problem with an algorithm that takes 2 infeasible—even though we could never solve an instance of size n=1 with the former algorithm, whereas we could solve an instance of the latter problem of size n=10 without difficulty. As we saw, it takes a day on a typical modern machine to process 2 operations when n=46; this may be the size of inputs we have, and the amount of time we have to solve a typical problem, making the 2-time algorithm feasible in practice on the inputs we have. Conversely, in fields where practical problems have millions of variables (such as Operations Research or Electronic Design Automation), even O(<i>n</i>) algorithms are often impractical.</p>
</body>
</html>