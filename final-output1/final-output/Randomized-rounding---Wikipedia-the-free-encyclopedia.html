<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Randomized-rounding---Wikipedia-the-free-encyclopedia.html</title></head>
<body>
<h1>Randomized rounding</h1>
<p>Within computer science and operations research, many combinatorial optimization problems are computationally intractable to solve exactly (to optimality). Many such problems do admit fast (polynomial time) approximation algorithms—that is, algorithms that are guaranteed to return an approximately optimal solution given any input.</p>
<p><b>Randomized rounding</b> (Raghavan &amp; Tompson 1987) is a widely used approach for designing and analyzing such approximation algorithms. The basic idea is to use the probabilistic method to convert an optimal solution of a relaxation of the problem into an approximately optimal solution to the original problem.</p>
<p></p>
<h2>Contents</h2>
<ul>
<li>1 Overview</li>
<li>2 Comparison to other applications of the probabilistic method</li>
<li>3 Set Cover example
<ul>
<li>3.1 Step 3: The randomized rounding step
<ul>
<li>3.1.1 lemma (approximation guarantee for rounding scheme)</li>
<li>3.1.2 proof</li>
</ul>
</li>
<li>3.2 Derandomization using the method of conditional probabilities
<ul>
<li>3.2.1 Bounding the conditional probability of failure</li>
<li>3.2.2 Keeping the conditional probability of failure below 1</li>
</ul>
</li>
<li>3.3 Randomized-rounding algorithm for Set Cover
<ul>
<li>3.3.1 lemma (approximation guarantee for algorithm)</li>
<li>3.3.2 proof</li>
</ul>
</li>
<li>3.4 Remarks</li>
</ul>
</li>
<li>4 See also</li>
<li>5 References</li>
<li>6 Further reading</li>
</ul>
<ul>
<li>3.1 Step 3: The randomized rounding step
<ul>
<li>3.1.1 lemma (approximation guarantee for rounding scheme)</li>
<li>3.1.2 proof</li>
</ul>
</li>
<li>3.2 Derandomization using the method of conditional probabilities
<ul>
<li>3.2.1 Bounding the conditional probability of failure</li>
<li>3.2.2 Keeping the conditional probability of failure below 1</li>
</ul>
</li>
<li>3.3 Randomized-rounding algorithm for Set Cover
<ul>
<li>3.3.1 lemma (approximation guarantee for algorithm)</li>
<li>3.3.2 proof</li>
</ul>
</li>
<li>3.4 Remarks</li>
</ul>
<ul>
<li>3.1.1 lemma (approximation guarantee for rounding scheme)</li>
<li>3.1.2 proof</li>
</ul>
<ul>
<li>3.2.1 Bounding the conditional probability of failure</li>
<li>3.2.2 Keeping the conditional probability of failure below 1</li>
</ul>
<ul>
<li>3.3.1 lemma (approximation guarantee for algorithm)</li>
<li>3.3.2 proof</li>
</ul>
<p></p>
<h2>Overview</h2>
<p>The basic approach has three steps:</p>
<ol>
<li>Formulate the problem to be solved as an integer linear program (ILP).</li>
<li>Compute an optimal fractional solution <img class="mwe-math-fallback-image-inline tex" alt="x" src="//upload.wikimedia.org/math/9/d/d/9dd4e461268c8034f5c8564e155c67a6.png"> to the linear programming relaxation (LP) of the ILP.</li>
<li>Round the fractional solution <img class="mwe-math-fallback-image-inline tex" alt="x" src="//upload.wikimedia.org/math/9/d/d/9dd4e461268c8034f5c8564e155c67a6.png"> of the LP to an integer solution <img class="mwe-math-fallback-image-inline tex" alt="x'" src="//upload.wikimedia.org/math/3/0/b/30b94bbbad526eeb6dd345afdaeaccf8.png"> of the ILP.</li>
</ol>
<p>(Although the approach is most commonly applied with linear programs, other kinds of relaxations are sometimes used. For example, see Goeman's and Williamson's semi-definite programming-based Max-Cut approximation algorithm.)</p>
<p>The challenge in the first step is to choose a suitable integer linear program. Familiarity with linear programming is required, in particular, familiarity with how to model problems using linear programs and integer linear programs. But, for many problems, there is a natural integer linear program that works well, such as in the Set Cover example below. (The integer linear program should have a small integrality gap; indeed randomized rounding is often used to prove bounds on integrality gaps.)</p>
<p>In the second step, the optimal fractional solution can typically be computed in polynomial time using any standard linear programming algorithm.</p>
<p>In the third step, the fractional solution must be converted into an integer solution (and thus a solution to the original problem). This is called <i>rounding</i> the fractional solution. The resulting integer solution should (provably) have cost not much larger than the cost of the fractional solution. This will ensure that the cost of the integer solution is not much larger than the cost of the optimal integer solution.</p>
<p>The main technique used to do the third step (rounding) is to use randomization, and then to use probabilistic arguments to bound the increase in cost due to the rounding (following the probabilistic method from combinatorics). There, probabilistic arguments are used to show the existence of discrete structures with desired properties. In this context, one uses such arguments to show the following:</p>
<p>Finally, to make the third step computationally efficient, one either shows that <img class="mwe-math-fallback-image-inline tex" alt="x'" src="//upload.wikimedia.org/math/3/0/b/30b94bbbad526eeb6dd345afdaeaccf8.png"> approximates <img class="mwe-math-fallback-image-inline tex" alt="x" src="//upload.wikimedia.org/math/9/d/d/9dd4e461268c8034f5c8564e155c67a6.png"> with high probability (so that the step can remain randomized) or one derandomizes the rounding step, typically using the method of conditional probabilities. The latter method converts the randomized rounding process into an efficient deterministic process that is guaranteed to reach a good outcome.</p>
<h2>Comparison to other applications of the probabilistic method</h2>
<p>The randomized rounding step differs from most applications of the probabilistic method in two respects:</p>
<ol>
<li>The computational complexity of the rounding step is important. It should be implementable by a fast (e.g. polynomial time) algorithm.</li>
<li>The probability distribution underlying the random experiment is a function of the solution <img class="mwe-math-fallback-image-inline tex" alt="x" src="//upload.wikimedia.org/math/9/d/d/9dd4e461268c8034f5c8564e155c67a6.png"> of a relaxation of the problem instance. This fact is crucial to proving the performance guarantee of the approximation algorithm --- that is, that for any problem instance, the algorithm returns a solution that approximates the <i>optimal solution for that specific instance</i>. In comparison, applications of the probabilistic method in combinatorics typically show the existence of structures whose features depend on other parameters of the input. For example, consider Turán's theorem, which can be stated as "any graph with <img class="mwe-math-fallback-image-inline tex" alt="n" src="//upload.wikimedia.org/math/7/b/8/7b8b965ad4bca0e41ab51de7b31363a1.png"> vertices of average degree <img class="mwe-math-fallback-image-inline tex" alt="d" src="//upload.wikimedia.org/math/8/2/7/8277e0910d750195b448797616e091ad.png"> must have an independent set of size at least <img class="mwe-math-fallback-image-inline tex" alt="n/(d+1)" src="//upload.wikimedia.org/math/4/c/2/4c2a88158d7231f7a1bf13d24bd20b6d.png">. (See this for a probabilistic proof of Turán's theorem.) While there are graphs for which this bound is tight, there are also graphs which have independent sets much larger than <img class="mwe-math-fallback-image-inline tex" alt="n/(d+1)" src="//upload.wikimedia.org/math/4/c/2/4c2a88158d7231f7a1bf13d24bd20b6d.png">. Thus, the size of the independent set shown to exist by Turán's theorem in a graph may, in general, be much smaller than the maximum independent set for that graph.</li>
</ol>
<h2>Set Cover example</h2>
<p>The method is best illustrated by example. The following example illustrates how randomized rounding can be used to design an approximation algorithm for the Set Cover problem.</p>
<p>Fix any instance <img class="mwe-math-fallback-image-inline tex" alt="\langle c, \mathcal S\rangle" src="//upload.wikimedia.org/math/6/c/5/6c56f44dde0def44c4b1ae423df4c76b.png"> of the Set Cover problem over a universe <img class="mwe-math-fallback-image-inline tex" alt="\mathcal U" src="//upload.wikimedia.org/math/9/4/b/94b427c31b2bc1dd340d462506b4f2ad.png">.</p>
<p>For step 1, let IP be the standard integer linear program for set cover for this instance.</p>
<p>For step 2, let LP be the linear programming relaxation of IP, and compute an optimal solution <img class="mwe-math-fallback-image-inline tex" alt="x^*" src="//upload.wikimedia.org/math/d/2/8/d282fd3350bb3ec2d1e940574e8fd42d.png"> to LP using any standard linear programming algorithm. (This takes time polynomial in the input size.)</p>
<p>(The feasible solutions to LP are the vectors <img class="mwe-math-fallback-image-inline tex" alt="x" src="//upload.wikimedia.org/math/9/d/d/9dd4e461268c8034f5c8564e155c67a6.png"> that assign each set <img class="mwe-math-fallback-image-inline tex" alt="s \in\mathcal S" src="//upload.wikimedia.org/math/b/b/1/bb178f4a1dc574d798bb77cec02399e6.png"> a non-negative weight <img class="mwe-math-fallback-image-inline tex" alt="x_s" src="//upload.wikimedia.org/math/a/7/2/a727b3abb09c0ecf8898343a5bbeffb1.png">, such that, for each element <img class="mwe-math-fallback-image-inline tex" alt="e\in\mathcal U" src="//upload.wikimedia.org/math/f/1/5/f1539bef3859e4763142e88a9a7596c7.png">, <img class="mwe-math-fallback-image-inline tex" alt="x'" src="//upload.wikimedia.org/math/3/0/b/30b94bbbad526eeb6dd345afdaeaccf8.png"> <i>covers</i> <img class="mwe-math-fallback-image-inline tex" alt="e" src="//upload.wikimedia.org/math/e/1/6/e1671797c52e15f763380b45e841ec32.png"> -- the total weight assigned to the sets containing <img class="mwe-math-fallback-image-inline tex" alt="e" src="//upload.wikimedia.org/math/e/1/6/e1671797c52e15f763380b45e841ec32.png"> is at least 1, that is,</p>
<p>The optimal solution <img class="mwe-math-fallback-image-inline tex" alt="x^*" src="//upload.wikimedia.org/math/d/2/8/d282fd3350bb3ec2d1e940574e8fd42d.png"> is a feasible solution whose cost</p>
<p>is as small as possible.)</p>
<p>Note that any set cover <img class="mwe-math-fallback-image-inline tex" alt="\mathcal C" src="//upload.wikimedia.org/math/8/c/3/8c32def588a95101eae4857f4db831e2.png"> for <img class="mwe-math-fallback-image-inline tex" alt="\mathcal S" src="//upload.wikimedia.org/math/2/8/8/2887e2ec013807aaa21b231028bfc50a.png"> gives a feasible solution <img class="mwe-math-fallback-image-inline tex" alt="x" src="//upload.wikimedia.org/math/9/d/d/9dd4e461268c8034f5c8564e155c67a6.png"> (where <img class="mwe-math-fallback-image-inline tex" alt="x_s=1" src="//upload.wikimedia.org/math/7/7/b/77be86b6fe2392e3c06f1acb0a6738ba.png"> for <img class="mwe-math-fallback-image-inline tex" alt="s\in\mathcal C" src="//upload.wikimedia.org/math/c/9/1/c919b6cfce8d2e02acc84547ec7b9dd5.png">, <img class="mwe-math-fallback-image-inline tex" alt="x_s=0" src="//upload.wikimedia.org/math/3/3/e/33e56c65fd3a82547dd1afc4b56962a3.png"> otherwise). The cost of this <img class="mwe-math-fallback-image-inline tex" alt="\mathcal C" src="//upload.wikimedia.org/math/8/c/3/8c32def588a95101eae4857f4db831e2.png"> equals the cost of <img class="mwe-math-fallback-image-inline tex" alt="x" src="//upload.wikimedia.org/math/9/d/d/9dd4e461268c8034f5c8564e155c67a6.png">, that is,</p>
<p>In other words, the linear program LP is a relaxation of the given set-cover problem.</p>
<p>Since <img class="mwe-math-fallback-image-inline tex" alt="x^*" src="//upload.wikimedia.org/math/d/2/8/d282fd3350bb3ec2d1e940574e8fd42d.png"> has minimum cost among feasible solutions to the LP, <i>the cost of <img class="mwe-math-fallback-image-inline tex" alt="x^*" src="//upload.wikimedia.org/math/d/2/8/d282fd3350bb3ec2d1e940574e8fd42d.png"> is a lower bound on the cost of the optimal set cover</i>.</p>
<h3>Step 3: The randomized rounding step</h3>
<p>Here is a description of the third step—the rounding step, which must convert the minimum-cost fractional set cover <img class="mwe-math-fallback-image-inline tex" alt="x^*" src="//upload.wikimedia.org/math/d/2/8/d282fd3350bb3ec2d1e940574e8fd42d.png"> into a feasible integer solution <img class="mwe-math-fallback-image-inline tex" alt="x'" src="//upload.wikimedia.org/math/3/0/b/30b94bbbad526eeb6dd345afdaeaccf8.png"> (corresponding to a true set cover).</p>
<p>The rounding step should produce an <img class="mwe-math-fallback-image-inline tex" alt="x'" src="//upload.wikimedia.org/math/3/0/b/30b94bbbad526eeb6dd345afdaeaccf8.png"> that, with positive probability, has cost within a small factor of the cost of <img class="mwe-math-fallback-image-inline tex" alt="x^*" src="//upload.wikimedia.org/math/d/2/8/d282fd3350bb3ec2d1e940574e8fd42d.png">. Then (since the cost of <img class="mwe-math-fallback-image-inline tex" alt="x^*" src="//upload.wikimedia.org/math/d/2/8/d282fd3350bb3ec2d1e940574e8fd42d.png"> is a lower bound on the cost of the optimal set cover), the cost of <img class="mwe-math-fallback-image-inline tex" alt="x'" src="//upload.wikimedia.org/math/3/0/b/30b94bbbad526eeb6dd345afdaeaccf8.png"> will be within a small factor of the optimal cost.</p>
<p>As a starting point, consider the most natural rounding scheme:</p>
<p>With this rounding scheme, the expected cost of the chosen sets is at most <img class="mwe-math-fallback-image-inline tex" alt="\sum_s c(s) x^*_s" src="//upload.wikimedia.org/math/6/2/0/6203454f8e589a6d0b52a5be0a21ee2f.png">, the cost of the fractional cover. This is good. Unfortunately the coverage is not good. When the variables <img class="mwe-math-fallback-image-inline tex" alt="x^*_s" src="//upload.wikimedia.org/math/1/6/0/16013173a9b1cad7a657e46108653ea5.png"> are small, the probability that an element <img class="mwe-math-fallback-image-inline tex" alt="e" src="//upload.wikimedia.org/math/e/1/6/e1671797c52e15f763380b45e841ec32.png"> is not covered is about</p>
<p>So only a constant fraction of the elements will be covered in expectation.</p>
<p>To make <img class="mwe-math-fallback-image-inline tex" alt="x'" src="//upload.wikimedia.org/math/3/0/b/30b94bbbad526eeb6dd345afdaeaccf8.png"> cover every element with high probability, the standard rounding scheme first <i>scales up</i> the rounding probabilities by an appropriate factor <img class="mwe-math-fallback-image-inline tex" alt="\lambda &gt; 1 " src="//upload.wikimedia.org/math/f/e/4/fe4adaeaba7bf4e28226671f2061435f.png">. Here is the standard rounding scheme:</p>
<p>Scaling the probabilities up by <img class="mwe-math-fallback-image-inline tex" alt="\lambda" src="//upload.wikimedia.org/math/e/0/5/e05a30d96800384dd38b22851322a6b5.png"> increases the expected cost by <img class="mwe-math-fallback-image-inline tex" alt="\lambda" src="//upload.wikimedia.org/math/e/0/5/e05a30d96800384dd38b22851322a6b5.png">, but makes coverage of all elements likely. The idea is to choose <img class="mwe-math-fallback-image-inline tex" alt="\lambda" src="//upload.wikimedia.org/math/e/0/5/e05a30d96800384dd38b22851322a6b5.png"> as small as possible so that all elements are provably covered with non-zero probability. Here is a detailed analysis.</p>
<h4>lemma (approximation guarantee for rounding scheme)</h4>
<p>(Note: with care the <img class="mwe-math-fallback-image-inline tex" alt="O(\log |\mathcal U|)" src="//upload.wikimedia.org/math/b/2/6/b26f03347e3a1e6ccea4c7cb99a97bf2.png"> can be reduced to <img class="mwe-math-fallback-image-inline tex" alt="\ln(|\mathcal U|)+O(\log\log|\mathcal U|)" src="//upload.wikimedia.org/math/c/7/f/c7f8a5f33664d3444d088b1c642d4f95.png">.)</p>
<h4>proof</h4>
<p>The output <img class="mwe-math-fallback-image-inline tex" alt="x'" src="//upload.wikimedia.org/math/3/0/b/30b94bbbad526eeb6dd345afdaeaccf8.png"> of the random rounding scheme has the desired properties as long as none of the following "bad" events occur:</p>
<ol>
<li>the cost <img class="mwe-math-fallback-image-inline tex" alt="c\cdot x'" src="//upload.wikimedia.org/math/8/1/f/81ff1818adebd840326d15877ed08223.png"> of <img class="mwe-math-fallback-image-inline tex" alt="x'" src="//upload.wikimedia.org/math/3/0/b/30b94bbbad526eeb6dd345afdaeaccf8.png"> exceeds <img class="mwe-math-fallback-image-inline tex" alt="2\lambda c\cdot x^*" src="//upload.wikimedia.org/math/4/0/4/4041b7547ac6c622973658372f0874b9.png">, or</li>
<li>for some element <img class="mwe-math-fallback-image-inline tex" alt="e" src="//upload.wikimedia.org/math/e/1/6/e1671797c52e15f763380b45e841ec32.png">, <img class="mwe-math-fallback-image-inline tex" alt="x'" src="//upload.wikimedia.org/math/3/0/b/30b94bbbad526eeb6dd345afdaeaccf8.png"> fails to cover <img class="mwe-math-fallback-image-inline tex" alt="e" src="//upload.wikimedia.org/math/e/1/6/e1671797c52e15f763380b45e841ec32.png">.</li>
</ol>
<p>The expectation of each <img class="mwe-math-fallback-image-inline tex" alt="x'_s" src="//upload.wikimedia.org/math/e/0/0/e00bd2783b4a2a5c07cdd1c3f5ef57ff.png"> is at most <img class="mwe-math-fallback-image-inline tex" alt="\lambda x_s^*" src="//upload.wikimedia.org/math/3/e/a/3ea5e2bf4f0f56e3bf082fa38865d6ab.png">. By linearity of expectation, the expectation of <img class="mwe-math-fallback-image-inline tex" alt="c\cdot x'" src="//upload.wikimedia.org/math/8/1/f/81ff1818adebd840326d15877ed08223.png"> is at most <img class="mwe-math-fallback-image-inline tex" alt="\sum_s c(s)\lambda x_s^*=\lambda c\cdot x^*" src="//upload.wikimedia.org/math/8/3/5/83589640b2b1325d8c6c7a68a16b97cd.png">. Thus, by Markov's inequality, the probability of the first bad event above is at most <img class="mwe-math-fallback-image-inline tex" alt="1/2" src="//upload.wikimedia.org/math/9/7/5/975ca8804565c1a569450d61090b2743.png">.</p>
<p>For the remaining bad events (one for each element <img class="mwe-math-fallback-image-inline tex" alt="e" src="//upload.wikimedia.org/math/e/1/6/e1671797c52e15f763380b45e841ec32.png">), note that, since <img class="mwe-math-fallback-image-inline tex" alt="\sum_{s\ni e} x^*_s \ge 1" src="//upload.wikimedia.org/math/d/1/b/d1bb1b2a38334eaa6262fca4f7a338ab.png"> for any given element <img class="mwe-math-fallback-image-inline tex" alt="e" src="//upload.wikimedia.org/math/e/1/6/e1671797c52e15f763380b45e841ec32.png">, the probability that <img class="mwe-math-fallback-image-inline tex" alt="e" src="//upload.wikimedia.org/math/e/1/6/e1671797c52e15f763380b45e841ec32.png"> is not covered is</p>
<p>(This uses the inequality <img class="mwe-math-fallback-image-inline tex" alt="1+z\le e^z" src="//upload.wikimedia.org/math/4/7/d/47d45ec3d282cd851038be6fe0da8b3a.png">, which is strict for <img class="mwe-math-fallback-image-inline tex" alt="z \ne 0" src="//upload.wikimedia.org/math/d/3/1/d31ead18171e7708fe647bc27bc3ce77.png">.)</p>
<p>Thus, for each of the <img class="mwe-math-fallback-image-inline tex" alt="|\mathcal U|" src="//upload.wikimedia.org/math/7/f/5/7f5eb89320f143777294731a764034de.png"> elements, the probability that the element is not covered is less than <img class="mwe-math-fallback-image-inline tex" alt="1/(2\mathcal U)" src="//upload.wikimedia.org/math/8/d/4/8d43114ccd88620d65d9f4c40669b67a.png">.</p>
<p>By the naive union bound, the probability that one of the <img class="mwe-math-fallback-image-inline tex" alt="1+|\mathcal U|" src="//upload.wikimedia.org/math/2/b/d/2bd5d4aac939ca08d76e80b080673cf5.png"> bad events happens is less than <img class="mwe-math-fallback-image-inline tex" alt="1/2 + |\mathcal U|/(2\mathcal U)=1" src="//upload.wikimedia.org/math/c/e/9/ce9cbd6d52b3002dcf137f0b0b16bda6.png">. Thus, with positive probability there are no bad events and <img class="mwe-math-fallback-image-inline tex" alt="x'" src="//upload.wikimedia.org/math/3/0/b/30b94bbbad526eeb6dd345afdaeaccf8.png"> is a set cover of cost at most <img class="mwe-math-fallback-image-inline tex" alt="2\lambda c\cdot x^*" src="//upload.wikimedia.org/math/4/0/4/4041b7547ac6c622973658372f0874b9.png">. QED</p>
<h3>Derandomization using the method of conditional probabilities</h3>
<p>The lemma above shows the <i>existence</i> of a set cover of cost <img class="mwe-math-fallback-image-inline tex" alt="O(\log(|\mathcal U|)c\cdot x^*" src="//upload.wikimedia.org/math/9/4/5/945d4419c2848b61b2597ccfc935c754.png">). In this context our goal is an efficient approximation algorithm, not just an existence proof, so we are not done.</p>
<p>One approach would be to increase <img class="mwe-math-fallback-image-inline tex" alt="\lambda" src="//upload.wikimedia.org/math/e/0/5/e05a30d96800384dd38b22851322a6b5.png"> a little bit, then show that the probability of success is at least, say, 1/4. With this modification, repeating the random rounding step a few times is enough to ensure a successful outcome with high probability.</p>
<p>That approach weakens the approximation ratio. We next describe a different approach that yields a deterministic algorithm that is guaranteed to match the approximation ratio of the existence proof above. The approach is called the method of conditional probabilities.</p>
<p>The deterministic algorithm emulates the randomized rounding scheme: it considers each set <img class="mwe-math-fallback-image-inline tex" alt="s\in\mathcal S" src="//upload.wikimedia.org/math/b/b/1/bb178f4a1dc574d798bb77cec02399e6.png"> in turn, and chooses <img class="mwe-math-fallback-image-inline tex" alt="x'_s \in\{0,1\}" src="//upload.wikimedia.org/math/b/7/9/b792859f7f4f8da8167947553ab89992.png">. But instead of making each choice <i>randomly</i> based on <img class="mwe-math-fallback-image-inline tex" alt="x^*" src="//upload.wikimedia.org/math/d/2/8/d282fd3350bb3ec2d1e940574e8fd42d.png">, it makes the choice <i>deterministically</i>, so as to <i>keep the conditional probability of failure, given the choices so far, below 1</i>.</p>
<h4>Bounding the conditional probability of failure</h4>
<p>We want to be able to set each variable <img class="mwe-math-fallback-image-inline tex" alt="x'_s" src="//upload.wikimedia.org/math/e/0/0/e00bd2783b4a2a5c07cdd1c3f5ef57ff.png"> in turn so as to keep the conditional probability of failure below 1. To do this, we need a good bound on the conditional probability of failure. The bound will come by refining the original existence proof. That proof implicitly bounds the probability of failure by the expectation of the random variable</p>
<p>where</p>
<p>is the set of elements left uncovered at the end.</p>
<p>The random variable <img class="mwe-math-fallback-image-inline tex" alt="F" src="//upload.wikimedia.org/math/8/0/0/800618943025315f869e4e1f09471012.png"> may appear a bit mysterious, but it mirrors the probabilistic proof in a systematic way. The first term in <img class="mwe-math-fallback-image-inline tex" alt="F" src="//upload.wikimedia.org/math/8/0/0/800618943025315f869e4e1f09471012.png"> comes from applying Markov's inequality to bound the probability of the first bad event (the cost is too high). It contributes at least 1 to <img class="mwe-math-fallback-image-inline tex" alt="F" src="//upload.wikimedia.org/math/8/0/0/800618943025315f869e4e1f09471012.png"> if the cost of <img class="mwe-math-fallback-image-inline tex" alt="x'" src="//upload.wikimedia.org/math/3/0/b/30b94bbbad526eeb6dd345afdaeaccf8.png"> is too high. The second term counts the number of bad events of the second kind (uncovered elements). It contributes at least 1 to <img class="mwe-math-fallback-image-inline tex" alt="F" src="//upload.wikimedia.org/math/8/0/0/800618943025315f869e4e1f09471012.png"> if <img class="mwe-math-fallback-image-inline tex" alt="x'" src="//upload.wikimedia.org/math/3/0/b/30b94bbbad526eeb6dd345afdaeaccf8.png"> leaves any element uncovered. Thus, in any outcome where <img class="mwe-math-fallback-image-inline tex" alt="F" src="//upload.wikimedia.org/math/8/0/0/800618943025315f869e4e1f09471012.png"> is less than 1, <img class="mwe-math-fallback-image-inline tex" alt="x'" src="//upload.wikimedia.org/math/3/0/b/30b94bbbad526eeb6dd345afdaeaccf8.png"> must cover all the elements and have cost meeting the desired bound from the lemma. In short, if the rounding step fails, then <img class="mwe-math-fallback-image-inline tex" alt="F \ge 1" src="//upload.wikimedia.org/math/9/3/b/93b2ddd94e09e64f39072841704aeca2.png">. This implies (by Markov's inequality) that <i><img class="mwe-math-fallback-image-inline tex" alt="E[F]" src="//upload.wikimedia.org/math/5/b/d/5bdb1345299e3589b3a6eaed01266816.png"> is an upper bound on the probability of failure.</i> Note that the argument above is implicit already in the proof of the lemma, which also shows by calculation that <img class="mwe-math-fallback-image-inline tex" alt="E[F] &lt; 1" src="//upload.wikimedia.org/math/d/e/8/de8a5ed5391ca399c141b8ad2e7104eb.png">.</p>
<p>To apply the method of conditional probabilities, we need to extend the argument to bound the <i>conditional</i> probability of failure as the rounding step proceeds. Usually, this can be done in a systematic way, although it can be technically tedious.</p>
<p>So, what about the <i>conditional</i> probability of failure as the rounding step iterates through the sets? Since <img class="mwe-math-fallback-image-inline tex" alt="F \ge 1" src="//upload.wikimedia.org/math/9/3/b/93b2ddd94e09e64f39072841704aeca2.png"> in any outcome where the rounding step fails, by Markov's inequality, the <i>conditional</i> probability of failure is at most the <i>conditional</i> expectation of <img class="mwe-math-fallback-image-inline tex" alt="F" src="//upload.wikimedia.org/math/8/0/0/800618943025315f869e4e1f09471012.png">.</p>
<p>Next we calculate the conditional expectation of <img class="mwe-math-fallback-image-inline tex" alt="F" src="//upload.wikimedia.org/math/8/0/0/800618943025315f869e4e1f09471012.png">, much as we calculated the unconditioned expectation of <img class="mwe-math-fallback-image-inline tex" alt="F" src="//upload.wikimedia.org/math/8/0/0/800618943025315f869e4e1f09471012.png"> in the original proof. Consider the state of the rounding process at the end of some iteration <img class="mwe-math-fallback-image-inline tex" alt="t" src="//upload.wikimedia.org/math/e/3/5/e358efa489f58062f10dd7316b65649e.png">. Let <img class="mwe-math-fallback-image-inline tex" alt="S^{(t)}" src="//upload.wikimedia.org/math/d/5/f/d5ffabd208377bbfaa4e27bc5edb39eb.png"> denote the sets considered so far (the first <img class="mwe-math-fallback-image-inline tex" alt="t" src="//upload.wikimedia.org/math/e/3/5/e358efa489f58062f10dd7316b65649e.png"> sets in <img class="mwe-math-fallback-image-inline tex" alt="\mathcal S" src="//upload.wikimedia.org/math/2/8/8/2887e2ec013807aaa21b231028bfc50a.png">). Let <img class="mwe-math-fallback-image-inline tex" alt="x^{(t)}" src="//upload.wikimedia.org/math/d/a/0/da027683ca9ee0163078b547758ad812.png"> denote the (partially assigned) vector <img class="mwe-math-fallback-image-inline tex" alt="x'" src="//upload.wikimedia.org/math/3/0/b/30b94bbbad526eeb6dd345afdaeaccf8.png"> (so <img class="mwe-math-fallback-image-inline tex" alt="x^{(t)}_s" src="//upload.wikimedia.org/math/f/4/6/f460745a385ecba244f409177441d829.png"> is determined only if <img class="mwe-math-fallback-image-inline tex" alt="s\in S^{(t)}" src="//upload.wikimedia.org/math/8/2/9/8299b997c4ccbdcbd4d183cd212a9e21.png">). For each set <img class="mwe-math-fallback-image-inline tex" alt="s\not\in S^{(t)}" src="//upload.wikimedia.org/math/2/6/9/2694fce4020c820e445ca50227b22352.png">, let <img class="mwe-math-fallback-image-inline tex" alt="p_s = \min(\lambda x^*_s, 1)" src="//upload.wikimedia.org/math/6/b/a/6ba4635ed7b4ab27c73e41d555acc9cf.png"> denote the probability with which <img class="mwe-math-fallback-image-inline tex" alt="x'_s" src="//upload.wikimedia.org/math/e/0/0/e00bd2783b4a2a5c07cdd1c3f5ef57ff.png"> will be set to 1. Let <img class="mwe-math-fallback-image-inline tex" alt="\mathcal U^{(t)}" src="//upload.wikimedia.org/math/8/7/a/87aa7a2fbb2e7bfae6b865bbc3bcca73.png"> contain the not-yet-covered elements. Then the conditional expectation of <img class="mwe-math-fallback-image-inline tex" alt="F" src="//upload.wikimedia.org/math/8/0/0/800618943025315f869e4e1f09471012.png">, given the choices made so far, that is, given <img class="mwe-math-fallback-image-inline tex" alt="x^{(t)}" src="//upload.wikimedia.org/math/d/a/0/da027683ca9ee0163078b547758ad812.png">, is</p>
<p>Note that <img class="mwe-math-fallback-image-inline tex" alt="E[F | x^{(t)}]" src="//upload.wikimedia.org/math/c/e/9/ce96b87bda5c4a134f957d3258d57df1.png"> is determined only after iteration <img class="mwe-math-fallback-image-inline tex" alt="t" src="//upload.wikimedia.org/math/e/3/5/e358efa489f58062f10dd7316b65649e.png">.</p>
<h4>Keeping the conditional probability of failure below 1</h4>
<p>To keep the conditional probability of failure below 1, it suffices to keep the conditional expectation of <img class="mwe-math-fallback-image-inline tex" alt="F" src="//upload.wikimedia.org/math/8/0/0/800618943025315f869e4e1f09471012.png"> below 1. To do this, it suffices to keep the conditional expectation of <img class="mwe-math-fallback-image-inline tex" alt="F" src="//upload.wikimedia.org/math/8/0/0/800618943025315f869e4e1f09471012.png"> from increasing. This is what the algorithm will do. It will set <img class="mwe-math-fallback-image-inline tex" alt="x'_s" src="//upload.wikimedia.org/math/e/0/0/e00bd2783b4a2a5c07cdd1c3f5ef57ff.png"> in each iteration to ensure that</p>
<p>(where <img class="mwe-math-fallback-image-inline tex" alt="m=|\mathcal S|" src="//upload.wikimedia.org/math/e/4/f/e4f2756515a4bddff2ed9619204854d1.png">).</p>
<p>In the <img class="mwe-math-fallback-image-inline tex" alt="t" src="//upload.wikimedia.org/math/e/3/5/e358efa489f58062f10dd7316b65649e.png">th iteration, how can the algorithm set <img class="mwe-math-fallback-image-inline tex" alt="x'_{s'}" src="//upload.wikimedia.org/math/0/8/9/089eedf6b6c1af01948ff8e5d438887e.png"> to ensure that <img class="mwe-math-fallback-image-inline tex" alt="E[F|x^{(t)}] \le E[F|S^{(t-1)}]" src="//upload.wikimedia.org/math/8/d/e/8de870f24563bbc1984a4e343db54deb.png">? It turns out that it can simply set <img class="mwe-math-fallback-image-inline tex" alt="x'_{s'}" src="//upload.wikimedia.org/math/0/8/9/089eedf6b6c1af01948ff8e5d438887e.png"> so as to <i>minimize</i> the resulting value of <img class="mwe-math-fallback-image-inline tex" alt="E[F|x^{(t)}]" src="//upload.wikimedia.org/math/c/e/9/ce96b87bda5c4a134f957d3258d57df1.png">.</p>
<p>To see why, focus on the point in time when iteration <img class="mwe-math-fallback-image-inline tex" alt="t" src="//upload.wikimedia.org/math/e/3/5/e358efa489f58062f10dd7316b65649e.png"> starts. At that time, <img class="mwe-math-fallback-image-inline tex" alt="E[F|x^{(t-1)}]" src="//upload.wikimedia.org/math/5/d/d/5dd07f0080ec4b52eb3c66ae5b97674b.png"> is determined, but <img class="mwe-math-fallback-image-inline tex" alt="E[F|x^{(t)}]" src="//upload.wikimedia.org/math/c/e/9/ce96b87bda5c4a134f957d3258d57df1.png"> is not yet determined --- it can take two possible values depending on how <img class="mwe-math-fallback-image-inline tex" alt="x'_{s'}" src="//upload.wikimedia.org/math/0/8/9/089eedf6b6c1af01948ff8e5d438887e.png"> is set in iteration <img class="mwe-math-fallback-image-inline tex" alt="t" src="//upload.wikimedia.org/math/e/3/5/e358efa489f58062f10dd7316b65649e.png">. Let <img class="mwe-math-fallback-image-inline tex" alt="E^{(t-1)}" src="//upload.wikimedia.org/math/7/3/f/73f891524d3b4fc87ea4a6489e7942b9.png"> denote the value of <img class="mwe-math-fallback-image-inline tex" alt="E[F|x'^{(t-1)}]" src="//upload.wikimedia.org/math/2/c/9/2c97980cfd8198b82cc27ab2f293c2b4.png">. Let <img class="mwe-math-fallback-image-inline tex" alt="E^{(t)}_0" src="//upload.wikimedia.org/math/b/5/b/b5b220987b4cdab3eba67fc957915978.png"> and <img class="mwe-math-fallback-image-inline tex" alt="E^{(t)}_1" src="//upload.wikimedia.org/math/a/a/a/aaad4cf174624c36422e5e1957bd921f.png">, denote the two possible values of <img class="mwe-math-fallback-image-inline tex" alt="E[F|x^{(t)}]" src="//upload.wikimedia.org/math/c/e/9/ce96b87bda5c4a134f957d3258d57df1.png">, depending on whether <img class="mwe-math-fallback-image-inline tex" alt="x'_{s'}" src="//upload.wikimedia.org/math/0/8/9/089eedf6b6c1af01948ff8e5d438887e.png"> is set to 0, or 1, respectively. By the definition of conditional expectation,</p>
<p>Since a weighted average of two quantities is always at least the minimum of those two quantities, it follows that</p>
<p>Thus, setting <img class="mwe-math-fallback-image-inline tex" alt="x'_{s'}" src="//upload.wikimedia.org/math/0/8/9/089eedf6b6c1af01948ff8e5d438887e.png"> so as to minimize the resulting value of <img class="mwe-math-fallback-image-inline tex" alt="E[F | x^{(t)}]" src="//upload.wikimedia.org/math/c/e/9/ce96b87bda5c4a134f957d3258d57df1.png"> will guarantee that <img class="mwe-math-fallback-image-inline tex" alt="E[F | x^{(t)}] \le E[F | x^{(t-1)}]" src="//upload.wikimedia.org/math/7/3/b/73b55f7189b53cd0a2a050a20bb526ea.png">. This is what the algorithm will do.</p>
<p>In detail, what does this mean? Considered as a function of <img class="mwe-math-fallback-image-inline tex" alt="x'_{s'}" src="//upload.wikimedia.org/math/0/8/9/089eedf6b6c1af01948ff8e5d438887e.png"> (with all other quantities fixed) <img class="mwe-math-fallback-image-inline tex" alt="E[F | x^{(t)}]" src="//upload.wikimedia.org/math/c/e/9/ce96b87bda5c4a134f957d3258d57df1.png"> is a linear function of <img class="mwe-math-fallback-image-inline tex" alt="x'_{s'}" src="//upload.wikimedia.org/math/0/8/9/089eedf6b6c1af01948ff8e5d438887e.png">, and the coefficient of <img class="mwe-math-fallback-image-inline tex" alt="x'_{s'}" src="//upload.wikimedia.org/math/0/8/9/089eedf6b6c1af01948ff8e5d438887e.png"> in that function is</p>
<p>Thus, the algorithm should set <img class="mwe-math-fallback-image-inline tex" alt="x'_{s'}" src="//upload.wikimedia.org/math/0/8/9/089eedf6b6c1af01948ff8e5d438887e.png"> to 0 if this expression is positive, and 1 otherwise. This gives the following algorithm.</p>
<h3>Randomized-rounding algorithm for Set Cover</h3>
<p><b>input:</b> set system <img class="mwe-math-fallback-image-inline tex" alt="\mathcal S" src="//upload.wikimedia.org/math/2/8/8/2887e2ec013807aaa21b231028bfc50a.png">, universe <img class="mwe-math-fallback-image-inline tex" alt="\mathcal U" src="//upload.wikimedia.org/math/9/4/b/94b427c31b2bc1dd340d462506b4f2ad.png">, cost vector <img class="mwe-math-fallback-image-inline tex" alt="c" src="//upload.wikimedia.org/math/4/a/8/4a8a08f09d37b73795649038408b5f33.png"></p>
<p><b>output:</b> set cover <img class="mwe-math-fallback-image-inline tex" alt="x'" src="//upload.wikimedia.org/math/3/0/b/30b94bbbad526eeb6dd345afdaeaccf8.png"> (a solution to the standard integer linear program for set cover)</p>
<ol>
<li>Compute a min-cost fractional set cover <img class="mwe-math-fallback-image-inline tex" alt="x^*" src="//upload.wikimedia.org/math/d/2/8/d282fd3350bb3ec2d1e940574e8fd42d.png"> (an optimal solution to the LP relaxation).</li>
<li>Let <img class="mwe-math-fallback-image-inline tex" alt="\lambda \leftarrow \ln(2|\mathcal U|)" src="//upload.wikimedia.org/math/f/8/a/f8a3f1c7ee37987497720f1be5d42402.png">. Let <img class="mwe-math-fallback-image-inline tex" alt="p_s \leftarrow \min(\lambda x^*_{s},1)" src="//upload.wikimedia.org/math/2/b/a/2ba4bd927c5d3427cba87ffb5a3eab3d.png"> for each <img class="mwe-math-fallback-image-inline tex" alt="s\in\mathcal S" src="//upload.wikimedia.org/math/b/b/1/bb178f4a1dc574d798bb77cec02399e6.png">.</li>
<li>For each <img class="mwe-math-fallback-image-inline tex" alt="s'\in\mathcal S" src="//upload.wikimedia.org/math/d/6/e/d6e2967ca55ee7063796160a70bf853d.png"> do:
<ol>
<li>Let <img class="mwe-math-fallback-image-inline tex" alt="\mathcal S \leftarrow \mathcal S - \{s'\}" src="//upload.wikimedia.org/math/5/0/1/501806a8260e5fbee060b29de80abc89.png">.   (<img class="mwe-math-fallback-image-inline tex" alt="\mathcal S" src="//upload.wikimedia.org/math/2/8/8/2887e2ec013807aaa21b231028bfc50a.png"> contains the not-yet-decided sets.)</li>
<li>If    <img class="mwe-math-fallback-image-inline tex" alt="
\frac{c_{s'}}{2\lambda c\cdot x^*}
&gt;
\sum_{e\in s'\cap\mathcal U} \prod_{s\in \mathcal S, s\ni e}(1-p_s)
" src="//upload.wikimedia.org/math/5/2/3/523895c7a31c882e64263d5a7669d12a.png">
<dl>
<dd>then set <img class="mwe-math-fallback-image-inline tex" alt="x'_s\leftarrow 0" src="//upload.wikimedia.org/math/6/6/9/669d75fbffc3edf4c7ba3225871e51eb.png">,</dd>
<dd>else set <img class="mwe-math-fallback-image-inline tex" alt="x'_s\leftarrow 1" src="//upload.wikimedia.org/math/9/5/b/95bde48083ec9ccd77293f4f4bb45029.png"> and <img class="mwe-math-fallback-image-inline tex" alt="\mathcal U\leftarrow\mathcal U - s'" src="//upload.wikimedia.org/math/7/f/c/7fcb2efef9437e8535b78019a970e29b.png">.</dd>
<dd>  (<img class="mwe-math-fallback-image-inline tex" alt="\mathcal U" src="//upload.wikimedia.org/math/9/4/b/94b427c31b2bc1dd340d462506b4f2ad.png"> contains the not-yet-covered elements.)</dd>
</dl>
</li>
</ol>
</li>
<li>Return <img class="mwe-math-fallback-image-inline tex" alt="x'" src="//upload.wikimedia.org/math/3/0/b/30b94bbbad526eeb6dd345afdaeaccf8.png">.</li>
</ol>
<ol>
<li>Let <img class="mwe-math-fallback-image-inline tex" alt="\mathcal S \leftarrow \mathcal S - \{s'\}" src="//upload.wikimedia.org/math/5/0/1/501806a8260e5fbee060b29de80abc89.png">.   (<img class="mwe-math-fallback-image-inline tex" alt="\mathcal S" src="//upload.wikimedia.org/math/2/8/8/2887e2ec013807aaa21b231028bfc50a.png"> contains the not-yet-decided sets.)</li>
<li>If    <img class="mwe-math-fallback-image-inline tex" alt="
\frac{c_{s'}}{2\lambda c\cdot x^*}
&gt;
\sum_{e\in s'\cap\mathcal U} \prod_{s\in \mathcal S, s\ni e}(1-p_s)
" src="//upload.wikimedia.org/math/5/2/3/523895c7a31c882e64263d5a7669d12a.png">
<dl>
<dd>then set <img class="mwe-math-fallback-image-inline tex" alt="x'_s\leftarrow 0" src="//upload.wikimedia.org/math/6/6/9/669d75fbffc3edf4c7ba3225871e51eb.png">,</dd>
<dd>else set <img class="mwe-math-fallback-image-inline tex" alt="x'_s\leftarrow 1" src="//upload.wikimedia.org/math/9/5/b/95bde48083ec9ccd77293f4f4bb45029.png"> and <img class="mwe-math-fallback-image-inline tex" alt="\mathcal U\leftarrow\mathcal U - s'" src="//upload.wikimedia.org/math/7/f/c/7fcb2efef9437e8535b78019a970e29b.png">.</dd>
<dd>  (<img class="mwe-math-fallback-image-inline tex" alt="\mathcal U" src="//upload.wikimedia.org/math/9/4/b/94b427c31b2bc1dd340d462506b4f2ad.png"> contains the not-yet-covered elements.)</dd>
</dl>
</li>
</ol>
<h4>lemma (approximation guarantee for algorithm)</h4>
<h4>proof</h4>
<p>The algorithm ensures that the conditional expectation of <img class="mwe-math-fallback-image-inline tex" alt="F" src="//upload.wikimedia.org/math/8/0/0/800618943025315f869e4e1f09471012.png">, <img class="mwe-math-fallback-image-inline tex" alt="E[F \,|\, x^{(t)}]" src="//upload.wikimedia.org/math/3/a/a/3aa209f4edc6940e5ef6e1c241c5363a.png">, does not increase at each iteration. Since this conditional expectation is initially less than 1 (as shown previously), the algorithm ensures that the conditional expectation stays below 1. Since the conditional probability of failure is at most the conditional expectation of <img class="mwe-math-fallback-image-inline tex" alt="F" src="//upload.wikimedia.org/math/8/0/0/800618943025315f869e4e1f09471012.png">, in this way the algorithm ensures that the conditional probability of failure stays below 1. Thus, at the end, when all choices are determined, the algorithm reaches a successful outcome. That is, the algorithm above returns a set cover <img class="mwe-math-fallback-image-inline tex" alt="x'" src="//upload.wikimedia.org/math/3/0/b/30b94bbbad526eeb6dd345afdaeaccf8.png"> of cost at most <img class="mwe-math-fallback-image-inline tex" alt="2\ln(2|\mathcal U|)" src="//upload.wikimedia.org/math/0/4/4/044f8d52b840e94b398d271abf47be18.png"> times the minimum cost of any (fractional) set cover.</p>
<h3>Remarks</h3>
<p>In the example above, the algorithm was guided by the conditional expectation of a random variable <img class="mwe-math-fallback-image-inline tex" alt="F" src="//upload.wikimedia.org/math/8/0/0/800618943025315f869e4e1f09471012.png">. In some cases, instead of an exact conditional expectation, an <i>upper bound</i> (or sometimes a lower bound) on some conditional expectation is used instead. This is called a pessimistic estimator.</p>
<h2>See also</h2>
<ul>
<li>Method of conditional probabilities</li>
</ul>
</body>
</html>