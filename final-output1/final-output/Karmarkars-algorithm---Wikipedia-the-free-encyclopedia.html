<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Karmarkars-algorithm---Wikipedia-the-free-encyclopedia.html</title></head>
<body>
<h1>Karmarkar's algorithm</h1>
<p><b>Karmarkar's algorithm</b> is an algorithm introduced by Narendra Karmarkar in 1984 for solving linear programming problems. It was the first reasonably efficient algorithm that solves these problems in polynomial time. The ellipsoid method is also polynomial time but proved to be inefficient in practice.</p>
<p>Where <img class="mwe-math-fallback-image-inline tex" alt="n" src="//upload.wikimedia.org/math/7/b/8/7b8b965ad4bca0e41ab51de7b31363a1.png"> is the number of variables and <img class="mwe-math-fallback-image-inline tex" alt="L" src="//upload.wikimedia.org/math/d/2/0/d20caec3b48a1eef164cb4ca81ba2587.png"> is the number of bits of input to the algorithm, Karmarkar's algorithm requires <img class="mwe-math-fallback-image-inline tex" alt="O(n^{3.5} L)" src="//upload.wikimedia.org/math/1/2/2/122caa21d417ef138e44432ddb60eaa5.png"> operations on <img class="mwe-math-fallback-image-inline tex" alt="O(L)" src="//upload.wikimedia.org/math/9/b/9/9b97a29b8f65340215df8549fa0249fd.png"> digit numbers, as compared to <img class="mwe-math-fallback-image-inline tex" alt="O(n^6 L)" src="//upload.wikimedia.org/math/a/7/9/a79c6a3aee80d9f3681a2c384d5db44c.png"> such operations for the ellipsoid algorithm. The runtime of Karmarkar's algorithm is thus</p>
<p>using FFT-based multiplication (see Big O notation).</p>
<p>Karmarkar's algorithm falls within the class of interior point methods: the current guess for the solution does not follow the boundary of the feasible set as in the simplex method, but it moves through the interior of the feasible region, improving the approximation of the optimal solution by a definite fraction with every iteration, and converging to an optimal solution with rational data.</p>
<p></p>
<h2>Contents</h2>
<ul>
<li>1 The Algorithm</li>
<li>2 Example</li>
<li>3 Patent controversy --- "Can Mathematics be patented ?"</li>
<li>4 References</li>
</ul>
<p></p>
<h2>The Algorithm</h2>
<p>Consider a Linear Programming problem in matrix form:</p>
<p>The algorithm determines the next feasible direction toward optimality and scales back by a factor 0 &lt; γ ≤ 1.</p>
<p>Karmarkar's algorithm is rather complicated. Interested readers can refer.     A simplified version, called the affine-scaling method, analyzed by others, can be described succinctly as follows. Note that the affine-scaling algorithm, while applicable to small scale problems, is not a polynomial time algorithm. For large scale and complex problems the original approach needs to be followed. Karmarkar also has extended the methodology  to solve problems with integer constraints and non-convex problems.</p>
<p>WHATSON? 357575e0-cb02-474c-b76d-2d61f32742a4</p>
<pre>
<b>Algorithm</b> Affine-Scaling
  Input:  A, b, c, <img class="mwe-math-fallback-image-inline tex" alt="x^0" src="//upload.wikimedia.org/math/5/9/b/59b95a7f867ce9d4e0f0b5f86f1260ff.png">, <i>stopping criterion</i>, <img class="mwe-math-fallback-image-inline tex" alt="\gamma" src="//upload.wikimedia.org/math/3/3/4/334de1ea38b615839e4ee6b65ee1b103.png">.
</pre>
<p>WHATSON? a19e0744-1906-4233-bd09-6ef93917d263</p>
<pre>
  <img class="mwe-math-fallback-image-inline tex" alt=" k \leftarrow 0 " src="//upload.wikimedia.org/math/a/5/7/a57316c75c7b57609c650c2a02e9c001.png">
  <b>do while</b> <i>stopping criterion</i> <b>not satisfied</b>
     <img class="mwe-math-fallback-image-inline tex" alt="v^k \leftarrow b-Ax^k" src="//upload.wikimedia.org/math/8/a/f/8af07bf9f1dd7685abc2af1bb40a0715.png">
     <img class="mwe-math-fallback-image-inline tex" alt="D_v \leftarrow \operatorname{diag}(v_1^k,\ldots,v_m^k)" src="//upload.wikimedia.org/math/9/6/c/96c154ae8f4ee45ed3e7739a71ad4523.png">
     <img class="mwe-math-fallback-image-inline tex" alt="h_x\leftarrow (A^TD_v^{-2}A)^{-1}c" src="//upload.wikimedia.org/math/7/9/d/79df6e1c558aef5c6437daa60904a14d.png">
     <img class="mwe-math-fallback-image-inline tex" alt="h_v\leftarrow -Ah_x" src="//upload.wikimedia.org/math/5/c/f/5cfe603319ee80076b44d4cf71ef211e.png">
     <b>if</b> <img class="mwe-math-fallback-image-inline tex" alt="h_v \ge 0" src="//upload.wikimedia.org/math/d/a/b/dab0878f34babca263c703f26cc4d371.png"> <b>then</b>
        <b>return</b> unbounded
     <b>end if</b>
     <img class="mwe-math-fallback-image-inline tex" alt="\alpha \leftarrow \gamma\cdot \min\{-v_i^k/(h_v)_i \,\,|\,\, (h_v)_i &lt; 0,\, i=1,\ldots,m\}" src="//upload.wikimedia.org/math/1/4/1/1411f917110eaf9b596d6025d3fa1da9.png">
     <img class="mwe-math-fallback-image-inline tex" alt="x^{k+1}\leftarrow x^k + \alpha h_x" src="//upload.wikimedia.org/math/0/f/d/0fd17d70159a3ca13e21ddbe0edd9ea4.png">
     <img class="mwe-math-fallback-image-inline tex" alt="k\leftarrow k+1" src="//upload.wikimedia.org/math/f/2/0/f2044ab5352c4639c0adc356c2f07d54.png">
  <b>end do</b>
</pre>
<ul>
<li><small>"←" is a shorthand for "changes to". For instance, "<i>largest</i> ← <i>item</i>" means that the value of <i>largest</i> changes to the value of <i>item</i>.</small></li>
<li><small>"<b>return</b>" terminates the algorithm and outputs the value that follows.</small></li>
</ul>
<h2>Example</h2>
<p>Consider the linear program</p>
<p>That is, there are 2 variables <img class="mwe-math-fallback-image-inline tex" alt="x_1, x_2" src="//upload.wikimedia.org/math/9/8/6/9865b118af4cfc107929ec116ab9eb80.png"> and 11 constraints associated with varying values of <img class="mwe-math-fallback-image-inline tex" alt="p" src="//upload.wikimedia.org/math/8/3/8/83878c91171338902e0fe0fb97a8c47a.png">. This figure shows each iteration of the algorithm as red circle points. The constraints are shown as blue lines.</p>
<h2>Patent controversy --- "Can Mathematics be patented ?"</h2>
<p>At the time he invented the algorithm, Narendra Karmarkar was employed by AT&amp;T. After applying the algorithm to optimizing AT&amp;T 's telephone network, they realized that his invention could be of practical importance. In April 1985, AT&amp;T promptly applied for a patent on Karmarkar's algorithm and that became more fuel for the ongoing controversy over the issue of software patents. This left many mathematicians uneasy, such as Ronald Rivest (himself one of the holders of the patent on the RSA algorithm), who expressed the opinion that research proceeded on the basis that algorithms should be free. Even before the patent was actually granted, it seemed that there was prior art that might have been applicable. Mathematicians who specialize in numerical analysis such as Philip Gill and others claimed that Karmarkar's algorithm is equivalent to a projected Newton barrier method with a logarithmic barrier function, if the parameters are chosen suitably. However, some say Gill's argument is flawed, insofar as the method they describe does not even qualify as an "algorithm", since it requires choices of parameters that don't follow from the internal logic of the method, but rely on external guidance, essentially from Karmarkar's algorithm. Furthermore, Karmarkar's contributions are considered far from obvious in light of all prior work, including Fiacco-McCormick, Gill and others cited by Saltzman. The patent was debated in the U.S. Senate and granted in recognition of the essential originality of Karmarkar's work, as U.S. Patent 4,744,026: "Methods and apparatus for efficient resource allocation" in May 1988. AT&amp;T supplied the KORBX system  based on this patent to the Pentagon, which enabled them to solve mathematical programming problems which were previously considered unsolvable. Opponents of software patents have further alleged that the patents ruined the positive interaction cycles that previously characterized the relationship between researchers in linear programming and industry, and specifically it isolated Karmarkar himself from the network of mathematical researchers in his field. </p>
<p>The patent itself expired in April 2006, and the algorithm is presently in the public domain.</p>
</body>
</html>