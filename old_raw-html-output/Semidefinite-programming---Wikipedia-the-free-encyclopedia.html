<h1 id="firstHeading" class="firstHeading" lang="en"><span dir="auto">Semidefinite programming</span></h1>
<p><b>Semidefinite programming</b> (<b>SDP</b>) is a subfield of <a href="/wiki/Convex_optimization" title="Convex optimization">convex optimization</a> concerned with the optimization of a linear <a href="/wiki/Objective_function" title="Objective function" class="mw-redirect">objective function</a> (that is, a function to be maximized or minimized) over the intersection of the <a href="/wiki/Cone_(linear_algebra)" title="Cone (linear algebra)">cone</a> of <a href="/wiki/Positive-definite_matrix#Negative-definite.2C_semidefinite_and_indefinite_matrices" title="Positive-definite matrix">positive semidefinite</a> <a href="/wiki/Matrix_(mathematics)" title="Matrix (mathematics)">matrices</a> with an <a href="/wiki/Affine_space" title="Affine space">affine space</a>, i.e., a <a href="/wiki/Spectrahedron" title="Spectrahedron">spectrahedron</a>.</p>
<p>Semidefinite programming is a relatively new field of optimization which is of growing interest for several reasons. Many practical problems in <a href="/wiki/Operations_research" title="Operations research">operations research</a> and <a href="/wiki/Combinatorial_optimization" title="Combinatorial optimization">combinatorial optimization</a> can be modeled or approximated as semidefinite programming problems. In automatic control theory, SDP's are used in the context of <a href="/wiki/Linear_matrix_inequality" title="Linear matrix inequality">linear matrix inequalities</a>. SDPs are in fact a special case of <a href="/wiki/Conic_optimization" title="Conic optimization">cone programming</a> and can be efficiently solved by <a href="/wiki/Interior_point_methods" title="Interior point methods" class="mw-redirect">interior point methods</a>. All <a href="/wiki/Linear_programming" title="Linear programming">linear programs</a> can be expressed as SDPs, and via hierarchies of SDPs the solutions of polynomial optimization problems can be approximated. Semidefinite programming has been used in the <a href="/wiki/Optimization" title="Optimization" class="mw-redirect">optimization of complex systems</a>. In recent years, some quantum query complexity problems have been formulated in term of semidefinite programs.</p>
<p></p>
<h2>Contents</h2>
<ul>
<li class="toclevel-1 tocsection-1"><a href="#Motivation_and_definition"><span class="tocnumber">1</span> <span class="toctext">Motivation and definition</span></a>
<ul>
<li class="toclevel-2 tocsection-2"><a href="#Initial_motivation"><span class="tocnumber">1.1</span> <span class="toctext">Initial motivation</span></a></li>
<li class="toclevel-2 tocsection-3"><a href="#Equivalent_formulations"><span class="tocnumber">1.2</span> <span class="toctext">Equivalent formulations</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-4"><a href="#Duality_theory"><span class="tocnumber">2</span> <span class="toctext">Duality theory</span></a>
<ul>
<li class="toclevel-2 tocsection-5"><a href="#Definitions"><span class="tocnumber">2.1</span> <span class="toctext">Definitions</span></a></li>
<li class="toclevel-2 tocsection-6"><a href="#Weak_duality"><span class="tocnumber">2.2</span> <span class="toctext">Weak duality</span></a></li>
<li class="toclevel-2 tocsection-7"><a href="#Strong_duality"><span class="tocnumber">2.3</span> <span class="toctext">Strong duality</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-8"><a href="#Examples"><span class="tocnumber">3</span> <span class="toctext">Examples</span></a>
<ul>
<li class="toclevel-2 tocsection-9"><a href="#Example_1"><span class="tocnumber">3.1</span> <span class="toctext">Example 1</span></a></li>
<li class="toclevel-2 tocsection-10"><a href="#Example_2"><span class="tocnumber">3.2</span> <span class="toctext">Example 2</span></a></li>
<li class="toclevel-2 tocsection-11"><a href="#Example_3_.28Goemans-Williamson_MAX_CUT_approximation_algorithm.29"><span class="tocnumber">3.3</span> <span class="toctext">Example 3 (Goemans-Williamson MAX CUT approximation algorithm)</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-12"><a href="#Algorithms"><span class="tocnumber">4</span> <span class="toctext">Algorithms</span></a>
<ul>
<li class="toclevel-2 tocsection-13"><a href="#Interior_point_methods"><span class="tocnumber">4.1</span> <span class="toctext">Interior point methods</span></a></li>
<li class="toclevel-2 tocsection-14"><a href="#Bundle_method"><span class="tocnumber">4.2</span> <span class="toctext">Bundle method</span></a></li>
<li class="toclevel-2 tocsection-15"><a href="#Other"><span class="tocnumber">4.3</span> <span class="toctext">Other</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-16"><a href="#Software"><span class="tocnumber">5</span> <span class="toctext">Software</span></a></li>
<li class="toclevel-1 tocsection-17"><a href="#Applications"><span class="tocnumber">6</span> <span class="toctext">Applications</span></a></li>
<li class="toclevel-1 tocsection-18"><a href="#References"><span class="tocnumber">7</span> <span class="toctext">References</span></a></li>
<li class="toclevel-1 tocsection-19"><a href="#External_links"><span class="tocnumber">8</span> <span class="toctext">External links</span></a></li>
</ul>
<ul>
<li class="toclevel-2 tocsection-2"><a href="#Initial_motivation"><span class="tocnumber">1.1</span> <span class="toctext">Initial motivation</span></a></li>
<li class="toclevel-2 tocsection-3"><a href="#Equivalent_formulations"><span class="tocnumber">1.2</span> <span class="toctext">Equivalent formulations</span></a></li>
</ul>
<ul>
<li class="toclevel-2 tocsection-5"><a href="#Definitions"><span class="tocnumber">2.1</span> <span class="toctext">Definitions</span></a></li>
<li class="toclevel-2 tocsection-6"><a href="#Weak_duality"><span class="tocnumber">2.2</span> <span class="toctext">Weak duality</span></a></li>
<li class="toclevel-2 tocsection-7"><a href="#Strong_duality"><span class="tocnumber">2.3</span> <span class="toctext">Strong duality</span></a></li>
</ul>
<ul>
<li class="toclevel-2 tocsection-9"><a href="#Example_1"><span class="tocnumber">3.1</span> <span class="toctext">Example 1</span></a></li>
<li class="toclevel-2 tocsection-10"><a href="#Example_2"><span class="tocnumber">3.2</span> <span class="toctext">Example 2</span></a></li>
<li class="toclevel-2 tocsection-11"><a href="#Example_3_.28Goemans-Williamson_MAX_CUT_approximation_algorithm.29"><span class="tocnumber">3.3</span> <span class="toctext">Example 3 (Goemans-Williamson MAX CUT approximation algorithm)</span></a></li>
</ul>
<ul>
<li class="toclevel-2 tocsection-13"><a href="#Interior_point_methods"><span class="tocnumber">4.1</span> <span class="toctext">Interior point methods</span></a></li>
<li class="toclevel-2 tocsection-14"><a href="#Bundle_method"><span class="tocnumber">4.2</span> <span class="toctext">Bundle method</span></a></li>
<li class="toclevel-2 tocsection-15"><a href="#Other"><span class="tocnumber">4.3</span> <span class="toctext">Other</span></a></li>
</ul>
<p></p>
<h2><span class="mw-headline" id="Motivation_and_definition">Motivation and definition</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semidefinite_programming&amp;action=edit&amp;section=1" title="Edit section: Motivation and definition">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<h3><span class="mw-headline" id="Initial_motivation">Initial motivation</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semidefinite_programming&amp;action=edit&amp;section=2" title="Edit section: Initial motivation">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>A <a href="/wiki/Linear_programming" title="Linear programming">linear programming</a> problem is one in which we wish to maximize or minimize a linear objective function of real variables over a <a href="/wiki/Polytope" title="Polytope">polytope</a>. In semidefinite programming, we instead use real-valued vectors and are allowed to take the dot product of vectors; nonnegativity constraints on real variables in LP are replaced by semidefiniteness constraints on matrix variables in SDP. Specifically, a general semidefinite programming problem can be defined as any mathematical programming problem of the form</p>
<h3><span class="mw-headline" id="Equivalent_formulations">Equivalent formulations</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semidefinite_programming&amp;action=edit&amp;section=3" title="Edit section: Equivalent formulations">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>An <img class="mwe-math-fallback-image-inline tex" alt="n \times n" src="//upload.wikimedia.org/math/6/0/7/607acaa73c762411b20745149a11e90b.png"> matrix <img class="mwe-math-fallback-image-inline tex" alt="M" src="//upload.wikimedia.org/math/6/9/6/69691c7bdcc3ce6d5d8a1361f22d04ac.png"> is said to be <a href="/wiki/Positive-definite_matrix#Positive-semidefinite" title="Positive-definite matrix">positive semidefinite</a> if it is the <a href="/wiki/Gramian_matrix" title="Gramian matrix">gramian matrix</a> of some vectors (i.e. if there exist vectors <img class="mwe-math-fallback-image-inline tex" alt="x^1, \ldots, x^n" src="//upload.wikimedia.org/math/4/0/f/40f5724a8aea802b64d9ababa61fbec1.png"> such that <img class="mwe-math-fallback-image-inline tex" alt="m_{i,j}=x^i \cdot x^j" src="//upload.wikimedia.org/math/d/4/9/d49bdc7cc5aee6049e326ee409b6a600.png"> for all <img class="mwe-math-fallback-image-inline tex" alt="i,j" src="//upload.wikimedia.org/math/e/e/8/ee813f0ede8664a8049b1b6720f03b60.png">). If this is the case, we denote this as <img class="mwe-math-fallback-image-inline tex" alt="M \succeq 0" src="//upload.wikimedia.org/math/4/6/9/4699fd6ecbf65db5a6ec0ab77959c82a.png">. Note that there are several other equivalent definitions of being positive semidefinite, for example, positive semidefinite matrices have only non-negative eigenvalues and have a positive definite square root.</p>
<p>Denote by <img class="mwe-math-fallback-image-inline tex" alt="\mathbb{S}^n" src="//upload.wikimedia.org/math/6/a/f/6af6cea7f3e0e5b952eb7db71fda65a8.png"> the space of all <img class="mwe-math-fallback-image-inline tex" alt="n \times n" src="//upload.wikimedia.org/math/6/0/7/607acaa73c762411b20745149a11e90b.png"> real symmetric matrices. The space is equipped with the <a href="/wiki/Inner_product_space" title="Inner product space">inner product</a> (where <img class="mwe-math-fallback-image-inline tex" alt="{\rm tr}" src="//upload.wikimedia.org/math/2/a/a/2aaacd3b83e40ccfcbcdfb4982026598.png"> denotes the <a href="/wiki/Trace_(linear_algebra)" title="Trace (linear algebra)">trace</a>) <img class="mwe-math-fallback-image-inline tex" alt="
  \langle A,B\rangle_{\mathbb{S}^n} = {\rm tr}(A^T B) = \sum_{i=1,j=1}^n
  A_{ij}B_{ij}.
" src="//upload.wikimedia.org/math/3/6/5/36502f8844159cb36dc832ae72173eaa.png"></p>
<p>We can rewrite the mathematical program given in the previous section equivalently as</p>
<p>where entry <img class="mwe-math-fallback-image-inline tex" alt="i,j" src="//upload.wikimedia.org/math/e/e/8/ee813f0ede8664a8049b1b6720f03b60.png"> in <img class="mwe-math-fallback-image-inline tex" alt="C" src="//upload.wikimedia.org/math/0/d/6/0d61f8370cad1d412f80b84d143e1257.png"> is given by <img class="mwe-math-fallback-image-inline tex" alt="c_{i,j}" src="//upload.wikimedia.org/math/9/2/e/92e822addd4c1d7ce4e6ca59c1504af4.png"> from the previous section and <img class="mwe-math-fallback-image-inline tex" alt="A_k" src="//upload.wikimedia.org/math/d/9/3/d93f57d24bbe3378bf1116d752877d4f.png"> is an <img class="mwe-math-fallback-image-inline tex" alt="n \times n" src="//upload.wikimedia.org/math/6/0/7/607acaa73c762411b20745149a11e90b.png"> matrix having <img class="mwe-math-fallback-image-inline tex" alt="i,j" src="//upload.wikimedia.org/math/e/e/8/ee813f0ede8664a8049b1b6720f03b60.png">th entry <img class="mwe-math-fallback-image-inline tex" alt="a_{i,j,k}" src="//upload.wikimedia.org/math/c/d/f/cdf7fc3eb2fe92d657a6e5873e4b3fe0.png"> from the previous section.</p>
<p>Note that if we add <a href="/wiki/Slack_variable" title="Slack variable">slack variables</a> appropriately, this SDP can be converted to one of the form</p>
<p>For convenience, an SDP may be specified in a slightly different, but equivalent form. For example, linear expressions involving nonnegative <a href="/wiki/Scalar_(mathematics)" title="Scalar (mathematics)">scalar</a> variables may be added to the program specification. This remains an SDP because each variable can be incorporated into the matrix <img class="mwe-math-fallback-image-inline tex" alt="X" src="//upload.wikimedia.org/math/0/2/1/02129bb861061d1a052c592e2dc6b383.png"> as a diagonal entry (<img class="mwe-math-fallback-image-inline tex" alt="X_{ii}" src="//upload.wikimedia.org/math/2/7/0/27062a1a56818ac8fb0141f4e1bc3292.png"> for some <img class="mwe-math-fallback-image-inline tex" alt="i" src="//upload.wikimedia.org/math/8/6/5/865c0c0b4ab0e063e5caa3387c1a8741.png">). To ensure that <img class="mwe-math-fallback-image-inline tex" alt="X_{ii} \geq 0" src="//upload.wikimedia.org/math/3/5/2/352e325ac2e1e3571943f314b56cfa2f.png">, constraints <img class="mwe-math-fallback-image-inline tex" alt="X_{ij} = 0" src="//upload.wikimedia.org/math/b/3/9/b3911a388d24085c221f7fd9af9739a3.png"> can be added for all <img class="mwe-math-fallback-image-inline tex" alt="j \neq i" src="//upload.wikimedia.org/math/c/c/f/ccf5f455f5de788b5d5eeaf339059de1.png">. As another example, note that for any positive semidefinite matrix <img class="mwe-math-fallback-image-inline tex" alt="X" src="//upload.wikimedia.org/math/0/2/1/02129bb861061d1a052c592e2dc6b383.png">, there exists a set of vectors <img class="mwe-math-fallback-image-inline tex" alt="\{ v_i \}" src="//upload.wikimedia.org/math/0/3/e/03e8c609dbb101a8d92839b7f35e122c.png"> such that the <img class="mwe-math-fallback-image-inline tex" alt="i" src="//upload.wikimedia.org/math/8/6/5/865c0c0b4ab0e063e5caa3387c1a8741.png">, <img class="mwe-math-fallback-image-inline tex" alt="j" src="//upload.wikimedia.org/math/3/6/3/363b122c528f54df4a0446b6bab05515.png"> entry of <img class="mwe-math-fallback-image-inline tex" alt="X" src="//upload.wikimedia.org/math/0/2/1/02129bb861061d1a052c592e2dc6b383.png"> is <img class="mwe-math-fallback-image-inline tex" alt="X_{ij} = (v_i, v_j)" src="//upload.wikimedia.org/math/e/c/2/ec25ce17c06970008e2d731a928d033e.png"> the <a href="/wiki/Dot_product" title="Dot product">scalar product</a> of <img class="mwe-math-fallback-image-inline tex" alt="v_i" src="//upload.wikimedia.org/math/f/0/e/f0e66f55342ef85ba8be3415dd92d8e2.png"> and <img class="mwe-math-fallback-image-inline tex" alt="v_j" src="//upload.wikimedia.org/math/2/7/5/275dc431f9270317c68595220d6b8730.png">. Therefore, SDPs are often formulated in terms of linear expressions on scalar products of vectors. Given the solution to the SDP in the standard form, the vectors <img class="mwe-math-fallback-image-inline tex" alt="\{ v_i \}" src="//upload.wikimedia.org/math/0/3/e/03e8c609dbb101a8d92839b7f35e122c.png"> can be recovered in <img class="mwe-math-fallback-image-inline tex" alt="O(n^3)" src="//upload.wikimedia.org/math/6/8/0/6809c59370e21b3e6e8fd117442fd377.png"> time (e.g., by using an incomplete <a href="/wiki/Cholesky_decomposition" title="Cholesky decomposition">Cholesky decomposition</a> of X).</p>
<h2><span class="mw-headline" id="Duality_theory">Duality theory</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semidefinite_programming&amp;action=edit&amp;section=4" title="Edit section: Duality theory">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<h3><span class="mw-headline" id="Definitions">Definitions</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semidefinite_programming&amp;action=edit&amp;section=5" title="Edit section: Definitions">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Analogously to linear programming, given a general SDP of the form</p>
<p>(the primal problem or P-SDP), we define the <i><a href="/wiki/Dual_problem" title="Dual problem" class="mw-redirect">dual</a></i> semidefinite program (D-SDP) as</p>
<p>where for any two matrices <img class="mwe-math-fallback-image-inline tex" alt="P" src="//upload.wikimedia.org/math/4/4/c/44c29edb103a2872f519ad0c9a0fdaaa.png"> and <img class="mwe-math-fallback-image-inline tex" alt="Q" src="//upload.wikimedia.org/math/f/0/9/f09564c9ca56850d4cd6b3319e541aee.png">, <img class="mwe-math-fallback-image-inline tex" alt="P \succeq Q" src="//upload.wikimedia.org/math/3/3/b/33bbee7dea13ee0d4a311a3ee2c7d4eb.png"> means <img class="mwe-math-fallback-image-inline tex" alt="P-Q \succeq 0" src="//upload.wikimedia.org/math/9/c/e/9ce23d30aa47d387ebb335c488b3d368.png">.</p>
<h3><span class="mw-headline" id="Weak_duality">Weak duality</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semidefinite_programming&amp;action=edit&amp;section=6" title="Edit section: Weak duality">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>The <a href="/wiki/Weak_duality" title="Weak duality">weak duality</a> theorem states that the value of the primal SDP is at least the value of the dual SDP. Therefore, any feasible solution to the dual SDP lower-bounds the primal SDP value, and conversely, any feasible solution to the primal SDP upper-bounds the dual SDP value. This is because</p>
<p>where the last inequality is because both matrices are positive semidefinite, and the result of this function is sometimes referred to as duality gap.</p>
<h3><span class="mw-headline" id="Strong_duality">Strong duality</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semidefinite_programming&amp;action=edit&amp;section=7" title="Edit section: Strong duality">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Under a condition known as Slater's condition, the value of the primal and dual SDPs are equal. This is known as <a href="/wiki/Strong_duality" title="Strong duality">strong duality</a>. Unlike for <a href="/wiki/Linear_programming" title="Linear programming">linear programs</a>, however, not every SDP satisfies strong duality; in general, the value of the dual SDP may lie strictly below the value of the primal.</p>
<p>(i) Suppose the primal problem (P-SDP) is bounded below and strictly feasible (i.e., there exists <img class="mwe-math-fallback-image-inline tex" alt="X_0\in\mathbb{S}^n, X_0\succ 0" src="//upload.wikimedia.org/math/d/a/7/da7289749ddef76fe96004c07c14e3d9.png"> such that <img class="mwe-math-fallback-image-inline tex" alt="\langle
A_i,X_0\rangle_{\mathbb{S}^n} = b_i" src="//upload.wikimedia.org/math/a/b/9/ab943489cb9b3ca72270800575b52d2e.png">, <img class="mwe-math-fallback-image-inline tex" alt="i=1,\ldots,m" src="//upload.wikimedia.org/math/e/9/f/e9fc2bada9d8a674f790a0c58e5312b7.png">). Then there is an optimal solution <img class="mwe-math-fallback-image-inline tex" alt="y^*" src="//upload.wikimedia.org/math/8/9/b/89b3a69e7c4dd4ee4e7aaf09191ac8e1.png"> to (D-SDP) and</p>
<p>(ii) Suppose the dual problem (D-SDP) is bounded above and strictly feasible (i.e., <img class="mwe-math-fallback-image-inline tex" alt="\sum_{i=1}^m (y_0)_i A_i
\prec C" src="//upload.wikimedia.org/math/5/7/8/578486f24b6366edcfcc854573887c8a.png"> for some <img class="mwe-math-fallback-image-inline tex" alt="y_0\in\R^m" src="//upload.wikimedia.org/math/f/a/0/fa0ce99d887c915be2090f917e9016bb.png">). Then there is an optimal solution <img class="mwe-math-fallback-image-inline tex" alt="X^*" src="//upload.wikimedia.org/math/f/2/d/f2d6c5f9b59bae5bc8a1ff91f8ae7ded.png"> to (P-SDP) and the equality from (i) holds.</p>
<h2><span class="mw-headline" id="Examples">Examples</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semidefinite_programming&amp;action=edit&amp;section=8" title="Edit section: Examples">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<h3><span class="mw-headline" id="Example_1">Example 1</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semidefinite_programming&amp;action=edit&amp;section=9" title="Edit section: Example 1">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Consider three random variables <img class="mwe-math-fallback-image-inline tex" alt="A" src="//upload.wikimedia.org/math/7/f/c/7fc56270e7a70fa81a5935b72eacbe29.png">, <img class="mwe-math-fallback-image-inline tex" alt="B" src="//upload.wikimedia.org/math/9/d/5/9d5ed678fe57bcca610140957afab571.png">, and <img class="mwe-math-fallback-image-inline tex" alt="C" src="//upload.wikimedia.org/math/0/d/6/0d61f8370cad1d412f80b84d143e1257.png">. By definition, their <a href="/wiki/Correlation" title="Correlation" class="mw-redirect">correlation coefficients</a> <img class="mwe-math-fallback-image-inline tex" alt="\rho_{AB}, \ \rho_{AC}, \rho_{BC} " src="//upload.wikimedia.org/math/d/e/f/def6df310c1afd3d9915f400e8ed7c83.png"> are valid if and only if</p>
<p>Suppose that we know from some prior knowledge (empirical results of an experiment, for example) that <img class="mwe-math-fallback-image-inline tex" alt="-0.2 \leq \rho_{AB} \leq -0.1" src="//upload.wikimedia.org/math/7/d/9/7d998af280a3e97c9343dba52e52cc93.png"> and <img class="mwe-math-fallback-image-inline tex" alt="0.4 \leq \rho_{BC} \leq 0.5" src="//upload.wikimedia.org/math/1/e/0/1e04db601379e2d5b3a026dd587587e4.png">. The problem of determining the smallest and largest values that <img class="mwe-math-fallback-image-inline tex" alt="\rho_{AC} \ " src="//upload.wikimedia.org/math/a/a/b/aaba1aef36163cf425751afc5cd04aaf.png"> can take is given by:</p>
<p>we set <img class="mwe-math-fallback-image-inline tex" alt="\rho_{AB} = x_{12}, \ \rho_{AC} = x_{13}, \ \rho_{BC} = x_{23} " src="//upload.wikimedia.org/math/1/1/9/1191b244ef613ec7d85f8fcc7b6c3d37.png"> to obtain the answer. This can be formulated by an SDP. We handle the inequality constraints by augmenting the variable matrix and introducing <a href="/wiki/Slack_variable" title="Slack variable">slack variables</a>, for example</p>
<p><img class="mwe-math-fallback-image-inline tex" alt="\mathrm{tr}\left(\left(\begin{array}{cccccc}
0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\end{array}\right)\cdot\left(\begin{array}{cccccc}
1 &amp; x_{12} &amp; x_{13} &amp; 0 &amp; 0 &amp; 0\\
x_{12} &amp; 1 &amp; x_{23} &amp; 0 &amp; 0 &amp; 0\\
x_{13} &amp; x_{23} &amp; 1 &amp; 0 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 0 &amp; s_{1} &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 0 &amp; 0 &amp; s_{2} &amp; 0\\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; s_{3}\end{array}\right)\right)=x_{12} + s_{1}=-0.1" src="//upload.wikimedia.org/math/2/4/d/24d1326cfd0440119334e712dc3e8f89.png"></p>
<p>Solving this SDP gives the minimum and maximum values of <img class="mwe-math-fallback-image-inline tex" alt="\rho_{AC} = x_{13} \ " src="//upload.wikimedia.org/math/c/8/0/c80bdb0f4479ca99a97b1e2bca106799.png"> as <img class="mwe-math-fallback-image-inline tex" alt="-0.978" src="//upload.wikimedia.org/math/a/6/7/a6770d397eeb8ea8b95ddd8c8d1052dc.png"> and <img class="mwe-math-fallback-image-inline tex" alt=" 0.872 " src="//upload.wikimedia.org/math/e/6/b/e6beb5d7465a1f43e959e0731e865cfd.png"> respectively.</p>
<h3><span class="mw-headline" id="Example_2">Example 2</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semidefinite_programming&amp;action=edit&amp;section=10" title="Edit section: Example 2">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Consider the problem</p>
<p>where we assume that <img class="mwe-math-fallback-image-inline tex" alt="d^Tx&gt;0" src="//upload.wikimedia.org/math/a/3/4/a3497df2adb01d8db618032d44c81800.png"> whenever <img class="mwe-math-fallback-image-inline tex" alt="Ax+b\geq 0" src="//upload.wikimedia.org/math/6/2/4/624041fa0c0db52ea379c4ee713a89f8.png">.</p>
<p>Introducing an auxiliary variable <img class="mwe-math-fallback-image-inline tex" alt="t" src="//upload.wikimedia.org/math/e/3/5/e358efa489f58062f10dd7316b65649e.png"> the problem can be reformulated:</p>
<p>In this formulation, the objective is a linear function of the variables <img class="mwe-math-fallback-image-inline tex" alt="x,t" src="//upload.wikimedia.org/math/2/6/d/26d5cf1de3b457150077701d163bcaca.png">.</p>
<p>The first restriction can be written as</p>
<p>where the matrix <img class="mwe-math-fallback-image-inline tex" alt="\textbf{diag}(Ax+b)" src="//upload.wikimedia.org/math/1/f/4/1f470b7f2d765e018b4bd83a55a9c5da.png"> is the square matrix with values in the diagonal equal to the elements of the vector <img class="mwe-math-fallback-image-inline tex" alt="Ax+b" src="//upload.wikimedia.org/math/7/c/8/7c8a2320ba08ff74e783b46a8513dfa1.png">.</p>
<p>The second restriction can be written as</p>
<p>Defining <img class="mwe-math-fallback-image-inline tex" alt="D" src="//upload.wikimedia.org/math/f/6/2/f623e75af30e62bbd73d6df5b50bb7b5.png"> as follows</p>
<p>We can use the theory of Schur Complements to see that</p>
<p>(Boyd and Vandenberghe, 1996)</p>
<p>The semidefinite program associated with this problem is</p>
<h3><span class="mw-headline" id="Example_3_.28Goemans-Williamson_MAX_CUT_approximation_algorithm.29">Example 3 (Goemans-Williamson MAX CUT approximation algorithm)</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semidefinite_programming&amp;action=edit&amp;section=11" title="Edit section: Example 3 (Goemans-Williamson MAX CUT approximation algorithm)">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Semidefinite programs are important tools for developing approximation algorithms for NP-hard maximization problems. The first approximation algorithm based on an SDP is due to Goemans and Williamson (JACM, 1995). They studied the MAX CUT problem: Given a <a href="/wiki/Graph_(mathematics)" title="Graph (mathematics)">graph</a> <i>G</i> = (<i>V</i>, <i>E</i>), output a <a href="/wiki/Partition_of_a_set" title="Partition of a set">partition</a> of the vertices <i>V</i> so as to maximize the number of edges crossing from one side to the other. This problem can be expressed as an <a href="/wiki/Quadratic_programming" title="Quadratic programming">integer quadratic program</a>:</p>
<p>Unless <a href="/wiki/P_%3D_NP" title="P = NP" class="mw-redirect">P = NP</a>, we cannot solve this maximization problem efficiently. However, Goemans and Williamson observed a general three-step procedure for attacking this sort of problem:</p>
<ol>
<li><i>Relax</i> the integer quadratic program into an SDP.</li>
<li>Solve the SDP (to within an arbitrarily small additive error <img class="mwe-math-fallback-image-inline tex" alt="\epsilon" src="//upload.wikimedia.org/math/c/5/0/c50b9e82e318d4c163e4b1b060f7daf5.png">).</li>
<li><i>Round</i> the SDP solution to obtain an approximate solution to the original integer quadratic program.</li>
</ol>
<p>For MAX CUT, the most natural relaxation is</p>
<p>This is an SDP because the objective function and constraints are all linear functions of vector inner products. Solving the SDP gives a set of unit vectors in <img class="mwe-math-fallback-image-inline tex" alt="\mathbf{R^n}" src="//upload.wikimedia.org/math/5/0/b/50b644a47d4cb9eecb09cf589f3044e8.png">; since the vectors are not required to be collinear, the value of this relaxed program can only be higher than the value of the original quadratic integer program. Finally, a rounding procedure is needed to obtain a partition. Goemans and Williamson simply choose a uniformly random hyperplane through the origin and divide the vertices according to which side of the hyperplane the corresponding vectors lie. Straightforward analysis shows that this procedure achieves an expected <i>approximation ratio</i> (performance guarantee) of 0.87856 - ε. (The expected value of the cut is the sum over edges of the probability that the edge is cut, which is proportional to the angle <img class="mwe-math-fallback-image-inline tex" alt="\cos^{-1}\langle v_{i}, v_{j}\rangle" src="//upload.wikimedia.org/math/1/7/0/170ffad77d715fab45c1cd3f8f57c84b.png"> between the vectors at the endpoints of the edge over <img class="mwe-math-fallback-image-inline tex" alt="\pi" src="//upload.wikimedia.org/math/5/2/2/522359592d78569a9eac16498aa7a087.png">. Comparing this probability to <img class="mwe-math-fallback-image-inline tex" alt="(1-\langle v_{i}, v_{j}\rangle)/{2}" src="//upload.wikimedia.org/math/6/7/a/67a181e397632a962fe0e288bff02cc4.png">, in expectation the ratio is always at least 0.87856.) Assuming the <a href="/wiki/Unique_games_conjecture" title="Unique games conjecture">Unique Games Conjecture</a>, it can be shown that this approximation ratio is essentially optimal.</p>
<p>Since the original paper of Goemans and Williamson, SDPs have been applied to develop numerous approximation algorithms. Recently, Prasad Raghavendra has developed a general framework for constraint satisfaction problems based on the <a href="/wiki/Unique_games_conjecture" title="Unique games conjecture">Unique Games Conjecture</a>.<sup id="cite_ref-1" class="reference"><a href="#cite_note-1"><span>[</span>1<span>]</span></a></sup></p>
<h2><span class="mw-headline" id="Algorithms">Algorithms</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semidefinite_programming&amp;action=edit&amp;section=12" title="Edit section: Algorithms">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>There are several types of algorithms for solving SDPs. These algorithms output the value of the SDP up to an additive error <img class="mwe-math-fallback-image-inline tex" alt="\epsilon" src="//upload.wikimedia.org/math/c/5/0/c50b9e82e318d4c163e4b1b060f7daf5.png"> in time that is polynomial in the program description size and <img class="mwe-math-fallback-image-inline tex" alt="\log (1/\epsilon)" src="//upload.wikimedia.org/math/4/a/c/4acbab6a3981a472d2f6f3e914966354.png">.</p>
<h3><span class="mw-headline" id="Interior_point_methods">Interior point methods</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semidefinite_programming&amp;action=edit&amp;section=13" title="Edit section: Interior point methods">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Most codes are based on <a href="/wiki/Interior_point_methods" title="Interior point methods" class="mw-redirect">interior point methods</a> (CSDP, SeDuMi, SDPT3, DSDP, SDPA). Robust and efficient for general linear SDP problems. Restricted by the fact that the algorithms are second-order methods and need to store and factorize a large (and often dense) matrix.</p>
<h3><span class="mw-headline" id="Bundle_method">Bundle method</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semidefinite_programming&amp;action=edit&amp;section=14" title="Edit section: Bundle method">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>The code ConicBundle formulates the SDP problem as a <a href="/w/index.php?title=Nonsmooth_optimization&amp;action=edit&amp;redlink=1" class="new" title="Nonsmooth optimization (page does not exist)">nonsmooth optimization</a> problem and solves it by the Spectral Bundle method of nonsmooth optimization. This approach is very efficient for a special class of linear SDP problems.</p>
<h3><span class="mw-headline" id="Other">Other</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semidefinite_programming&amp;action=edit&amp;section=15" title="Edit section: Other">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Algorithms based on <a href="/w/index.php?title=Augmented_Lagrangian&amp;action=edit&amp;redlink=1" class="new" title="Augmented Lagrangian (page does not exist)">augmented Lagrangian</a> method (PENSDP) are similar in behavior to the interior point methods and can be specialized to some very large scale problems. Other algorithms use low-rank information and reformulation of the SDP as a <a href="/wiki/Nonlinear_programming" title="Nonlinear programming">nonlinear programming</a> problem (SPDLR).</p>
<h2><span class="mw-headline" id="Software">Software</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semidefinite_programming&amp;action=edit&amp;section=16" title="Edit section: Software">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>The following codes are available for SDP:</p>
<ul>
<li><a rel="nofollow" class="external text" href="http://sdpa.sourceforge.net/index.html">SDPA</a>, C++</li>
<li><a rel="nofollow" class="external text" href="https://projects.coin-or.org/Csdp/">CSDP</a>, C</li>
<li><a rel="nofollow" class="external text" href="http://www.math.nus.edu.sg/~mattohkc/sdpt3.html">SDPT3</a>, Matlab. Free.</li>
<li><a rel="nofollow" class="external text" href="http://sedumi.ie.lehigh.edu/">SeDuMi</a>, Matlab. Free.</li>
<li>DSDP</li>
<li><a rel="nofollow" class="external text" href="http://www.penopt.com/pensdp.html">PENSDP</a>, C, Fortran, Matlab. Commercial.</li>
<li><a rel="nofollow" class="external text" href="http://dollar.biz.uiowa.edu/~sburer/pmwiki/pmwiki.php%3Fn=Main.SDPLR%3Faction=logout.html">SDPLR</a>, C, Matlab</li>
<li><a rel="nofollow" class="external text" href="http://www-user.tu-chemnitz.de/~helmberg/ConicBundle/">ConicBundle</a>, C/C++</li>
<li><a rel="nofollow" class="external text" href="http://cvxopt.org/">CVXOPT</a>, python. Free.</li>
</ul>
<p>SeDuMi runs on MATLAB and uses the Self-Dual method for solving general convex optimization problems.</p>
<h2><span class="mw-headline" id="Applications">Applications</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semidefinite_programming&amp;action=edit&amp;section=17" title="Edit section: Applications">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Semidefinite programming has been applied to find approximate solutions to combinatorial optimization problems, such as the solution of the <a href="/wiki/Max_cut" title="Max cut" class="mw-redirect">max cut</a> problem with an <a href="/wiki/Approximation_ratio" title="Approximation ratio" class="mw-redirect">approximation ratio</a> of 0.87856. SDPs are also used in geometry to determine tensegrity graphs, and arise in control theory as <a href="/wiki/Linear_matrix_inequality" title="Linear matrix inequality">LMIs</a>.</p>
<h2><span class="mw-headline" id="References">References</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semidefinite_programming&amp;action=edit&amp;section=18" title="Edit section: References">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ol class="references">
<li id="cite_note-1"><span class="mw-cite-backlink"><b><a href="#cite_ref-1">^</a></b></span> <span class="reference-text">Raghavendra, P. 2008. <a rel="nofollow" class="external text" href="http://doi.acm.org/10.1145/1374376.1374414">Optimal algorithms and inapproximability results for every CSP?</a>. In Proceedings of the 40th Annual ACM Symposium on theory of Computing (Victoria, British Columbia, Canada, May 17–20, 2008). STOC '08. ACM, New York, NY, 245-254.</span></li>
</ol>
<ul>
<li>Lieven Vandenberghe, Stephen Boyd, "Semidefinite Programming", SIAM Review 38, March 1996, pp. 49–95. <a rel="nofollow" class="external text" href="http://stanford.edu/~boyd/papers/pdf/semidef_prog.pdf">pdf</a></li>
</ul>
<ul>
<li>Monique Laurent, Franz Rendl, "Semidefinite Programming and Integer Programming", Report PNA-R0210, CWI, Amsterdam, April 2002. <a rel="nofollow" class="external text" href="http://www.optimization-online.org/DB_HTML/2002/12/585.html">optimization-online</a></li>
</ul>
<ul>
<li>E. de Klerk, "Aspects of Semidefinite Programming: Interior Point Algorithms and Selected Applications", Kluwer Academic Publishers, March 2002, <a href="/wiki/Special:BookSources/1402005474" class="internal mw-magiclink-isbn">ISBN 1-4020-0547-4</a>.</li>
</ul>
<ul>
<li>Robert M. Freund, "Introduction to Semidefinite Programming (SDP), <a rel="nofollow" class="external text" href="http://ocw.mit.edu/courses/sloan-school-of-management/15-094j-systems-optimization-models-and-computation-sma-5223-spring-2004/lecture-notes/sdp094_digest.pdf">SDP-Introduction</a></li>
</ul>
<h2><span class="mw-headline" id="External_links">External links</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semidefinite_programming&amp;action=edit&amp;section=19" title="Edit section: External links">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul>
<li><a rel="nofollow" class="external text" href="http://www-user.tu-chemnitz.de/~helmberg/semidef.html">Links to introductions and events in the field</a></li>
<li><a rel="nofollow" class="external text" href="http://www.cs.elte.hu/~lovasz/semidef.ps">Lecture notes from László Lovász</a> on Semidefinite Programming</li>
</ul>
<p><br></p>
<ul>
<li class="nv-view"><a href="/wiki/Template:Optimization_algorithms" title="Template:Optimization algorithms"><span title="View this template" style=";;background:none transparent;border:none;;">v</span></a></li>
<li class="nv-talk"><a href="/wiki/Template_talk:Optimization_algorithms" title="Template talk:Optimization algorithms"><span title="Discuss this template" style=";;background:none transparent;border:none;;">t</span></a></li>
<li class="nv-edit"><a class="external text" href="//en.wikipedia.org/w/index.php?title=Template:Optimization_algorithms&amp;action=edit"><span title="Edit this template" style=";;background:none transparent;border:none;;">e</span></a></li>
</ul>
<ul>
<li><a href="/wiki/Golden_section_search" title="Golden section search">Golden section search</a></li>
<li><a href="/wiki/Powell%27s_method" title="Powell's method">Interpolation methods</a></li>
<li><a href="/wiki/Line_search" title="Line search">Line search</a></li>
<li><a href="/wiki/Nelder%E2%80%93Mead_method" title="Nelder–Mead method">Nelder–Mead method</a></li>
<li><a href="/wiki/Successive_parabolic_interpolation" title="Successive parabolic interpolation">Successive parabolic interpolation</a></li>
</ul>
<ul>
<li><a href="/wiki/Trust_region" title="Trust region">Trust region</a></li>
<li><a href="/wiki/Wolfe_conditions" title="Wolfe conditions">Wolfe conditions</a></li>
</ul>
<ul>
<li><a href="/wiki/Broyden%E2%80%93Fletcher%E2%80%93Goldfarb%E2%80%93Shanno_algorithm" title="Broyden–Fletcher–Goldfarb–Shanno algorithm">BFGS</a> and <a href="/wiki/Limited-memory_BFGS" title="Limited-memory BFGS">L-BFGS</a></li>
<li><a href="/wiki/Davidon%E2%80%93Fletcher%E2%80%93Powell_formula" title="Davidon–Fletcher–Powell formula">DFP</a></li>
<li><a href="/wiki/SR1_formula" title="SR1 formula" class="mw-redirect">Symmetric rank-one (SR1)</a></li>
</ul>
<ul>
<li><a href="/wiki/Gauss%E2%80%93Newton_algorithm" title="Gauss–Newton algorithm">Gauss–Newton</a></li>
<li><a href="/wiki/Gradient_descent" title="Gradient descent">Gradient</a></li>
<li><a href="/wiki/Levenberg%E2%80%93Marquardt_algorithm" title="Levenberg–Marquardt algorithm">Levenberg–Marquardt</a></li>
<li><a href="/wiki/Nonlinear_conjugate_gradient_method" title="Nonlinear conjugate gradient method">Conjugate gradient</a></li>
</ul>
<ul>
<li><a href="/wiki/Newton%27s_method_in_optimization" title="Newton's method in optimization">Newton's method</a></li>
</ul>
<ul>
<li><a href="/wiki/Barrier_function" title="Barrier function">Barrier methods</a></li>
<li><a href="/wiki/Penalty_method" title="Penalty method">Penalty methods</a></li>
</ul>
<ul>
<li><a href="/wiki/Augmented_Lagrangian_method" title="Augmented Lagrangian method">Augmented Lagrangian methods</a></li>
<li><a href="/wiki/Sequential_quadratic_programming" title="Sequential quadratic programming">Sequential quadratic programming</a></li>
<li><a href="/wiki/Successive_linear_programming" title="Successive linear programming">Successive linear programming</a></li>
</ul>
<ul>
<li><a href="/wiki/Cutting-plane_method" title="Cutting-plane method">Cutting-plane method</a></li>
<li><a href="/wiki/Frank%E2%80%93Wolfe_algorithm" title="Frank–Wolfe algorithm">Reduced gradient (Frank–Wolfe)</a></li>
<li><a href="/wiki/Subgradient_method" title="Subgradient method">Subgradient method</a></li>
</ul>
<ul>
<li><a href="/wiki/Ellipsoid_method" title="Ellipsoid method">Ellipsoid algorithm of Khachiyan</a></li>
<li><a href="/wiki/Karmarkar%27s_algorithm" title="Karmarkar's algorithm">Projective algorithm of Karmarkar</a></li>
</ul>
<ul>
<li><a href="/wiki/Simplex_algorithm" title="Simplex algorithm">Simplex algorithm of Dantzig</a></li>
<li><a href="/wiki/Revised_simplex_algorithm" title="Revised simplex algorithm" class="mw-redirect">Revised simplex algorithm</a></li>
<li><a href="/wiki/Criss-cross_algorithm" title="Criss-cross algorithm">Criss-cross algorithm</a></li>
<li><a href="/wiki/Lemke%27s_algorithm" title="Lemke's algorithm">Principal pivoting algorithm of Lemke</a></li>
</ul>
<ul>
<li><a href="/wiki/Approximation_algorithm" title="Approximation algorithm">Approximation algorithm</a></li>
<li><a href="/wiki/Dynamic_programming" title="Dynamic programming">Dynamic programming</a></li>
<li><a href="/wiki/Greedy_algorithm" title="Greedy algorithm">Greedy algorithm</a></li>
<li><a href="/wiki/Integer_programming" title="Integer programming">Integer programming</a>
<ul>
<li><a href="/wiki/Branch_and_bound" title="Branch and bound">Branch &amp; bound</a> or <a href="/wiki/Branch_and_cut" title="Branch and cut">cut</a></li>
</ul>
</li>
</ul>
<ul>
<li><a href="/wiki/Branch_and_bound" title="Branch and bound">Branch &amp; bound</a> or <a href="/wiki/Branch_and_cut" title="Branch and cut">cut</a></li>
</ul>
<ul>
<li><a href="/wiki/Bellman%E2%80%93Ford_algorithm" title="Bellman–Ford algorithm">Bellman–Ford</a></li>
<li><a href="/wiki/Bor%C5%AFvka%27s_algorithm" title="Borůvka's algorithm">Borůvka</a></li>
<li><a href="/wiki/Dijkstra%27s_algorithm" title="Dijkstra's algorithm">Dijkstra</a></li>
<li><a href="/wiki/Floyd%E2%80%93Warshall_algorithm" title="Floyd–Warshall algorithm">Floyd–Warshall</a></li>
<li><a href="/wiki/Johnson%27s_algorithm" title="Johnson's algorithm">Johnson</a></li>
<li><a href="/wiki/Kruskal%27s_algorithm" title="Kruskal's algorithm">Kruskal</a></li>
</ul>
<ul>
<li><a href="/wiki/Dinic%27s_algorithm" title="Dinic's algorithm">Dinic</a></li>
<li><a href="/wiki/Edmonds%E2%80%93Karp_algorithm" title="Edmonds–Karp algorithm">Edmonds–Karp</a></li>
<li><a href="/wiki/Ford%E2%80%93Fulkerson_algorithm" title="Ford–Fulkerson algorithm">Ford–Fulkerson</a></li>
<li><a href="/wiki/Push-relabel_maximum_flow_algorithm" title="Push-relabel maximum flow algorithm" class="mw-redirect">Push-relabel maximum flow</a></li>
</ul>
<ul>
<li><a href="/wiki/Evolutionary_algorithm" title="Evolutionary algorithm">Evolutionary algorithm</a></li>
<li><a href="/wiki/Hill_climbing" title="Hill climbing">Hill climbing</a></li>
<li><a href="/wiki/Local_search_(optimization)" title="Local search (optimization)">Local search</a></li>
<li><a href="/wiki/Simulated_annealing" title="Simulated annealing">Simulated annealing</a></li>
<li><a href="/wiki/Tabu_search" title="Tabu search">Tabu search</a></li>
</ul>
<ul>
<li><b>Categories</b>
<ul>
<li><a href="/wiki/Category:Optimization_algorithms_and_methods" title="Category:Optimization algorithms and methods">Algorithms and methods</a></li>
<li><a href="/wiki/Category:Heuristic_algorithms" title="Category:Heuristic algorithms">Heuristics</a></li>
</ul>
</li>
<li><b><a href="/wiki/Comparison_of_optimization_software" title="Comparison of optimization software">Software</a></b></li>
</ul>
<ul>
<li><a href="/wiki/Category:Optimization_algorithms_and_methods" title="Category:Optimization algorithms and methods">Algorithms and methods</a></li>
<li><a href="/wiki/Category:Heuristic_algorithms" title="Category:Heuristic algorithms">Heuristics</a></li>
</ul>
