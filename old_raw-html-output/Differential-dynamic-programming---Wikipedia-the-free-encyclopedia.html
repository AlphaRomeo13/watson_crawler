<h1 id="firstHeading" class="firstHeading" lang="en"><span dir="auto">Differential dynamic programming</span></h1>
<p><b>Differential dynamic programming (DDP)</b> is an <a href="/wiki/Optimal_control" title="Optimal control">optimal control</a> algorithm of the <a href="/wiki/Trajectory_optimization" title="Trajectory optimization">trajectory optimization</a> class. The algorithm was introduced in 1966 by <a href="/wiki/David_Mayne" title="David Mayne">Mayne</a><sup id="cite_ref-1" class="reference"><a href="#cite_note-1"><span>[</span>1<span>]</span></a></sup> and subsequently analysed in Jacobson and Mayne's eponymous book.<sup id="cite_ref-2" class="reference"><a href="#cite_note-2"><span>[</span>2<span>]</span></a></sup> The algorithm uses locally-quadratic models of the dynamics and cost functions, and displays <a href="/wiki/Rate_of_convergence" title="Rate of convergence">quadratic convergence</a>. It is closely related to Pantoja's step-wise Newton's method.<sup id="cite_ref-3" class="reference"><a href="#cite_note-3"><span>[</span>3<span>]</span></a></sup><sup id="cite_ref-4" class="reference"><a href="#cite_note-4"><span>[</span>4<span>]</span></a></sup></p>
<p></p>
<h2>Contents</h2>
<ul>
<li class="toclevel-1 tocsection-1"><a href="#Finite-horizon_discrete-time_problems"><span class="tocnumber">1</span> <span class="toctext">Finite-horizon discrete-time problems</span></a></li>
<li class="toclevel-1 tocsection-2"><a href="#Dynamic_programming"><span class="tocnumber">2</span> <span class="toctext">Dynamic programming</span></a></li>
<li class="toclevel-1 tocsection-3"><a href="#Differential_dynamic_programming"><span class="tocnumber">3</span> <span class="toctext">Differential dynamic programming</span></a></li>
<li class="toclevel-1 tocsection-4"><a href="#Regularization_and_line-search"><span class="tocnumber">4</span> <span class="toctext">Regularization and line-search</span></a></li>
<li class="toclevel-1 tocsection-5"><a href="#See_also"><span class="tocnumber">5</span> <span class="toctext">See also</span></a></li>
<li class="toclevel-1 tocsection-6"><a href="#References"><span class="tocnumber">6</span> <span class="toctext">References</span></a></li>
<li class="toclevel-1 tocsection-7"><a href="#External_links"><span class="tocnumber">7</span> <span class="toctext">External links</span></a></li>
</ul>
<p></p>
<h2><span class="mw-headline" id="Finite-horizon_discrete-time_problems">Finite-horizon discrete-time problems</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Differential_dynamic_programming&amp;action=edit&amp;section=1" title="Edit section: Finite-horizon discrete-time problems">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>The dynamics</p>
<p style="margin:0;"><img class="mwe-math-fallback-image-inline tex" alt="\mathbf{x}_{i+1} = \mathbf{f}(\mathbf{x}_i,\mathbf{u}_i)" src="//upload.wikimedia.org/math/0/d/f/0dfdf56c5aca61d4e33af2e826f4989d.png"></p>
<p style="margin:0;"></p>
<p style="margin:0; font-size:4pt;"> </p>
<p style="margin:0; font-size:1pt;"> </p>
<p style="margin:0; font-size:4pt;"> </p>
<p style="margin:0; font-size:1pt;"> </p>
<p style="margin:0pt;"><b>(<span id="math_1" class="reference nourlexpansion" style="font-weight:bold; font-style:italic;">1</span>)</b></p>
<p>describe the evolution of the state <img class="mwe-math-fallback-image-inline tex" alt="\textstyle\mathbf{x}" src="//upload.wikimedia.org/math/8/3/0/830ee4a4699ebdc550271ba96f0fc1c5.png"> given the control <img class="mwe-math-fallback-image-inline tex" alt="\mathbf{u}" src="//upload.wikimedia.org/math/2/5/c/25cdaba0e466192c4086c413c442def1.png"> from time <img class="mwe-math-fallback-image-inline tex" alt="i" src="//upload.wikimedia.org/math/8/6/5/865c0c0b4ab0e063e5caa3387c1a8741.png"> to time <img class="mwe-math-fallback-image-inline tex" alt="i+1" src="//upload.wikimedia.org/math/1/5/a/15ab2d2b0b92c13f328635e5c4bdbe64.png">. The <i>total cost</i> <img class="mwe-math-fallback-image-inline tex" alt="J_0" src="//upload.wikimedia.org/math/a/f/1/af105717ba6f73bec8076e6e3709b015.png"> is the sum of running costs <img class="mwe-math-fallback-image-inline tex" alt="\textstyle\ell" src="//upload.wikimedia.org/math/d/8/e/d8efaeeb2e82f710dd2a541dd20771a5.png"> and final cost <img class="mwe-math-fallback-image-inline tex" alt="\ell_f" src="//upload.wikimedia.org/math/e/0/8/e081200eaa4f1def5a35826e4f63eb8e.png">, incurred when starting from state <img class="mwe-math-fallback-image-inline tex" alt="\mathbf{x}" src="//upload.wikimedia.org/math/3/c/6/3c66d9170d4c3fb75456e1a9fc6ead37.png"> and applying the control sequence <img class="mwe-math-fallback-image-inline tex" alt="\mathbf{U} \equiv \{\mathbf{u}_0,\mathbf{u}_1\dots,\mathbf{u}_{N-1}\}" src="//upload.wikimedia.org/math/3/b/7/3b70d9bc7bc7306ab265065deca3062d.png"> until the horizon is reached:</p>
<p>where <img class="mwe-math-fallback-image-inline tex" alt="\mathbf{x}_0\equiv\mathbf{x}" src="//upload.wikimedia.org/math/5/8/a/58ae621506236af7903d912b0bb487df.png">, and the <img class="mwe-math-fallback-image-inline tex" alt="\mathbf{x}_i" src="//upload.wikimedia.org/math/3/f/0/3f052ba8a0742f689f895fd252fa157f.png"> for <img class="mwe-math-fallback-image-inline tex" alt="i&gt;0" src="//upload.wikimedia.org/math/5/6/3/563d880e1c878d80bb57b029b4c56166.png"> are given by <b><a href="#math_1">Eq. 1</a></b>. The solution of the optimal control problem is the minimizing control sequence <img class="mwe-math-fallback-image-inline tex" alt="\mathbf{U}^*(\mathbf{x})\equiv \operatorname{argmin}_{\mathbf{U}} J_0(\mathbf{x},\mathbf{U})." src="//upload.wikimedia.org/math/0/f/1/0f167de903abe70488e49955603db50b.png"> <i>Trajectory optimization</i> means finding <img class="mwe-math-fallback-image-inline tex" alt="\mathbf{U}^*(\mathbf{x})" src="//upload.wikimedia.org/math/3/9/e/39e4aee763de4afc86f0f9cd75ba9fac.png"> for a particular <img class="mwe-math-fallback-image-inline tex" alt="\mathbf{x}" src="//upload.wikimedia.org/math/3/c/6/3c66d9170d4c3fb75456e1a9fc6ead37.png">, rather than for all possible initial states.</p>
<h2><span class="mw-headline" id="Dynamic_programming">Dynamic programming</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Differential_dynamic_programming&amp;action=edit&amp;section=2" title="Edit section: Dynamic programming">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Let <img class="mwe-math-fallback-image-inline tex" alt="\mathbf{U}_i" src="//upload.wikimedia.org/math/f/3/e/f3e77bce15cb92bbb875c734183d7a25.png"> be the partial control sequence <img class="mwe-math-fallback-image-inline tex" alt="\mathbf{U}_i \equiv \{\mathbf{u}_i,\mathbf{u}_{i+1}\dots,\mathbf{u}_{N-1}\}" src="//upload.wikimedia.org/math/a/2/c/a2c2dbf609540769f056505cc6785d31.png"> and define the <i>cost-to-go</i> <img class="mwe-math-fallback-image-inline tex" alt="J_i" src="//upload.wikimedia.org/math/6/5/7/657e4adad7075ebe664309beeef1bf79.png"> as the partial sum of costs from <img class="mwe-math-fallback-image-inline tex" alt="i" src="//upload.wikimedia.org/math/8/6/5/865c0c0b4ab0e063e5caa3387c1a8741.png"> to <img class="mwe-math-fallback-image-inline tex" alt="N" src="//upload.wikimedia.org/math/8/d/9/8d9c307cb7f3c4a32822a51922d1ceaa.png">:</p>
<p>The optimal cost-to-go or <i>value function</i> at time <img class="mwe-math-fallback-image-inline tex" alt="i" src="//upload.wikimedia.org/math/8/6/5/865c0c0b4ab0e063e5caa3387c1a8741.png"> is the cost-to-go given the minimizing control sequence:</p>
<p>Setting <img class="mwe-math-fallback-image-inline tex" alt="V(\mathbf{x},N)\equiv \ell_f(\mathbf{x}_N)" src="//upload.wikimedia.org/math/2/c/d/2cd7eab1000da6135affde0725e43e14.png">, the <a href="/wiki/Dynamic_programming" title="Dynamic programming">dynamic programming principle</a> reduces the minimization over an entire sequence of controls to a sequence of minimizations over a single control, proceeding backwards in time:</p>
<p style="margin:0;"><img class="mwe-math-fallback-image-inline tex" alt="V(\mathbf{x},i)= \min_{\mathbf{u}}[\ell(\mathbf{x},\mathbf{u}) + V(\mathbf{f}(\mathbf{x},\mathbf{u}),i+1)]." src="//upload.wikimedia.org/math/8/f/9/8f90eb41b0109b4606c541dfcb9cf3ce.png"></p>
<p style="margin:0;"></p>
<p style="margin:0; font-size:4pt;"> </p>
<p style="margin:0; font-size:1pt;"> </p>
<p style="margin:0; font-size:4pt;"> </p>
<p style="margin:0; font-size:1pt;"> </p>
<p style="margin:0pt;"><b>(<span id="math_2" class="reference nourlexpansion" style="font-weight:bold; font-style:italic;">2</span>)</b></p>
<p>This is the <a href="/wiki/Bellman_equation" title="Bellman equation">Bellman equation</a>.</p>
<h2><span class="mw-headline" id="Differential_dynamic_programming">Differential dynamic programming</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Differential_dynamic_programming&amp;action=edit&amp;section=3" title="Edit section: Differential dynamic programming">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>DDP proceeds by iteratively performing a backward pass on the nominal trajectory to generate a new control sequence, and then a forward-pass to compute and evaluate a new nominal trajectory. We begin with the backward pass. If</p>
<p>is the argument of the <img class="mwe-math-fallback-image-inline tex" alt="\min[]" src="//upload.wikimedia.org/math/e/0/6/e0607703814149a49215b2b4d6b4a263.png"> operator in <b><a href="#math_2">Eq. 2</a></b>, let <img class="mwe-math-fallback-image-inline tex" alt="Q" src="//upload.wikimedia.org/math/f/0/9/f09564c9ca56850d4cd6b3319e541aee.png"> be the variation of this quantity around the <img class="mwe-math-fallback-image-inline tex" alt="i" src="//upload.wikimedia.org/math/8/6/5/865c0c0b4ab0e063e5caa3387c1a8741.png">-th <img class="mwe-math-fallback-image-inline tex" alt="(\mathbf{x},\mathbf{u})" src="//upload.wikimedia.org/math/1/9/a/19a0255135319d10b759922a7292b6f5.png"> pair:</p>
<p>and expand to second order</p>
<p style="margin:0;"><img class="mwe-math-fallback-image-inline tex" alt="
\approx\frac{1}{2}
\begin{bmatrix}
1\\
\delta\mathbf{x}\\
\delta\mathbf{u}
\end{bmatrix}^\mathsf{T}
\begin{bmatrix}
0 &amp; Q_\mathbf{x}^\mathsf{T} &amp; Q_\mathbf{u}^\mathsf{T}\\
Q_\mathbf{x} &amp; Q_{\mathbf{x}\mathbf{x}} &amp; Q_{\mathbf{x}\mathbf{u}}\\
Q_\mathbf{u} &amp; Q_{\mathbf{u}\mathbf{x}} &amp; Q_{\mathbf{u}\mathbf{u}}
\end{bmatrix}
\begin{bmatrix}
1\\
\delta\mathbf{x}\\
\delta\mathbf{u}
\end{bmatrix}
" src="//upload.wikimedia.org/math/7/a/e/7ae0f3b568cde096c745f687e1e13afa.png"></p>
<p style="margin:0;"></p>
<p style="margin:0; font-size:4pt;"> </p>
<p style="margin:0; font-size:1pt;"> </p>
<p style="margin:0; font-size:4pt;"> </p>
<p style="margin:0; font-size:1pt;"> </p>
<p style="margin:0pt;"><b>(<span id="math_3" class="reference nourlexpansion" style="font-weight:bold; font-style:italic;">3</span>)</b></p>
<p>The <img class="mwe-math-fallback-image-inline tex" alt="Q" src="//upload.wikimedia.org/math/f/0/9/f09564c9ca56850d4cd6b3319e541aee.png"> notation used here is a variant of the notation of Morimoto where subscripts denote differentiation in denominator layout.<sup id="cite_ref-5" class="reference"><a href="#cite_note-5"><span>[</span>5<span>]</span></a></sup> Dropping the index <img class="mwe-math-fallback-image-inline tex" alt="i" src="//upload.wikimedia.org/math/8/6/5/865c0c0b4ab0e063e5caa3387c1a8741.png"> for readability, primes denoting the next time-step <img class="mwe-math-fallback-image-inline tex" alt="V'\equiv V(i+1)" src="//upload.wikimedia.org/math/c/1/3/c1368e8de8b12fa1f72874b2b2574d95.png">, the expansion coefficients are</p>
<p>The last terms in the last three equations denote contraction of a vector with a tensor. Minimizing the quadratic approximation <b><a href="#math_3">(3)</a></b> with respect to <img class="mwe-math-fallback-image-inline tex" alt="\delta\mathbf{u}" src="//upload.wikimedia.org/math/5/5/1/551eda5bb57bdd1db8aa5f8d1023348b.png"> we have</p>
<p style="margin:0;"><img class="mwe-math-fallback-image-inline tex" alt="
{\delta \mathbf{u}}^* = \operatorname{argmin}\limits_{\delta \mathbf{u}}Q(\delta \mathbf{x},\delta
\mathbf{u})=-Q_{\mathbf{u}\mathbf{u}}^{-1}(Q_\mathbf{u}+Q_{\mathbf{u}\mathbf{x}}\delta \mathbf{x}),
" src="//upload.wikimedia.org/math/5/0/0/500a67bd74f263c3923a5869f98e36bd.png"></p>
<p style="margin:0;"></p>
<p style="margin:0; font-size:4pt;"> </p>
<p style="margin:0; font-size:1pt;"> </p>
<p style="margin:0; font-size:4pt;"> </p>
<p style="margin:0; font-size:1pt;"> </p>
<p style="margin:0pt;"><b>(<span id="math_4" class="reference nourlexpansion" style="font-weight:bold; font-style:italic;">4</span>)</b></p>
<p>giving an open-loop term <img class="mwe-math-fallback-image-inline tex" alt="\mathbf{k}=-Q_{\mathbf{u}\mathbf{u}}^{-1}Q_\mathbf{u}" src="//upload.wikimedia.org/math/e/4/a/e4a94d5a6b38a58d32677023e46c243d.png"> and a feedback gain term <img class="mwe-math-fallback-image-inline tex" alt="\mathbf{K}=-Q_{\mathbf{u}\mathbf{u}}^{-1}Q_{\mathbf{u}\mathbf{x}}" src="//upload.wikimedia.org/math/d/2/e/d2e2fe0978bddc9d765cc288ac7f3a78.png">. Plugging the result back into <b><a href="#math_3">(3)</a></b>, we now have a quadratic model of the value at time <img class="mwe-math-fallback-image-inline tex" alt="i" src="//upload.wikimedia.org/math/8/6/5/865c0c0b4ab0e063e5caa3387c1a8741.png">:</p>
<p>Recursively computing the local quadratic models of <img class="mwe-math-fallback-image-inline tex" alt="V(i)" src="//upload.wikimedia.org/math/4/7/a/47aca2228d16b9374000bf2ad5046e04.png"> and the control modifications <img class="mwe-math-fallback-image-inline tex" alt="\{\mathbf{k}(i),\mathbf{K}(i)\}" src="//upload.wikimedia.org/math/d/b/e/dbe8a758732e5b019a81c9fabec25851.png">, from <img class="mwe-math-fallback-image-inline tex" alt="i=N-1" src="//upload.wikimedia.org/math/d/0/0/d005e3ea3731ab3a8480f8229b3d02ce.png"> down to <img class="mwe-math-fallback-image-inline tex" alt="i=1" src="//upload.wikimedia.org/math/9/a/0/9a041ce63f6c28100344427c6d71837b.png">, constitutes the backward pass. As above, the Value is initialized with <img class="mwe-math-fallback-image-inline tex" alt="V(\mathbf{x},N)\equiv \ell_f(\mathbf{x}_N)" src="//upload.wikimedia.org/math/2/c/d/2cd7eab1000da6135affde0725e43e14.png">. Once the backward pass is completed, a forward pass computes a new trajectory:</p>
<p>The backward passes and forward passes are iterated until convergence.</p>
<h2><span class="mw-headline" id="Regularization_and_line-search">Regularization and line-search</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Differential_dynamic_programming&amp;action=edit&amp;section=4" title="Edit section: Regularization and line-search">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Differential dynamic programming is a second-order algorithm like <a href="/wiki/Newton%27s_method" title="Newton's method">Newton's method</a>. It therefore takes large steps toward the minimum and often requires <a href="/wiki/Regularization_(mathematics)" title="Regularization (mathematics)">regularization</a> and/or <a href="/wiki/Line-search" title="Line-search" class="mw-redirect">line-search</a> to achieve convergence <sup id="cite_ref-6" class="reference"><a href="#cite_note-6"><span>[</span>6<span>]</span></a></sup> .<sup id="cite_ref-7" class="reference"><a href="#cite_note-7"><span>[</span>7<span>]</span></a></sup> Regularization in the DDP context means ensuring that the <img class="mwe-math-fallback-image-inline tex" alt="Q_{\mathbf{u}\mathbf{u}}" src="//upload.wikimedia.org/math/f/3/4/f343c730922545175aa9516a7d04fa59.png"> matrix in <b><a href="#math_4">Eq. 4</a></b> is <a href="/wiki/Positive_definite_matrix" title="Positive definite matrix" class="mw-redirect">positive definite</a>. Line-search in DDP amounts to scaling the open-loop control modification <img class="mwe-math-fallback-image-inline tex" alt="\mathbf{k}" src="//upload.wikimedia.org/math/4/9/b/49b252932f19c605cfbb78689e9365ed.png"> by some <img class="mwe-math-fallback-image-inline tex" alt="0&lt;\alpha&lt;1" src="//upload.wikimedia.org/math/b/7/5/b759578cec5b9449a9eea6d4ec1d2e2c.png">.</p>
<h2><span class="mw-headline" id="See_also">See also</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Differential_dynamic_programming&amp;action=edit&amp;section=5" title="Edit section: See also">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul>
<li><a href="/wiki/Optimal_control" title="Optimal control">optimal control</a></li>
</ul>
<h2><span class="mw-headline" id="References">References</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Differential_dynamic_programming&amp;action=edit&amp;section=6" title="Edit section: References">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ol class="references">
<li id="cite_note-1"><span class="mw-cite-backlink"><b><a href="#cite_ref-1">^</a></b></span> <span class="reference-text"><span class="citation journal">Mayne, D. Q. (1966). "A second-order gradient method of optimizing non-linear discrete time systems". <i>Int J Control</i> <b>3</b>: 85–95. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="http://dx.doi.org/10.1080%2F00207176608921369">10.1080/00207176608921369</a>.</span><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ADifferential+dynamic+programming&amp;rft.atitle=A+second-order+gradient+method+of+optimizing+non-linear+discrete+time+systems&amp;rft.aufirst=D.+Q.&amp;rft.aulast=Mayne&amp;rft.au=Mayne%2C+D.+Q.&amp;rft.date=1966&amp;rft.genre=article&amp;rft_id=info%3Adoi%2F10.1080%2F00207176608921369&amp;rft.jtitle=Int+J+Control&amp;rft.pages=85-95&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.volume=3" class="Z3988"><span style="display:none;"> </span></span></span></li>
<li id="cite_note-2"><span class="mw-cite-backlink"><b><a href="#cite_ref-2">^</a></b></span> <span class="reference-text"><span class="citation book">Mayne, David H. and Jacobson, David Q. (1970). <a rel="nofollow" class="external text" href="http://books.google.com/books/about/Differential_dynamic_programming.html?id=tA-oAAAAIAAJ"><i>Differential dynamic programming</i></a>. New York: American Elsevier Pub. Co. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a> <a href="/wiki/Special:BookSources/0-444-00070-4" title="Special:BookSources/0-444-00070-4">0-444-00070-4</a>.</span><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ADifferential+dynamic+programming&amp;rft.aufirst=David+H.+and+Jacobson%2C+David+Q.&amp;rft.aulast=Mayne&amp;rft.au=Mayne%2C+David+H.+and+Jacobson%2C+David+Q.&amp;rft.btitle=Differential+dynamic+programming&amp;rft.date=1970&amp;rft.genre=book&amp;rft_id=http%3A%2F%2Fbooks.google.com%2Fbooks%2Fabout%2FDifferential_dynamic_programming.html%3Fid%3DtA-oAAAAIAAJ&amp;rft.isbn=0-444-00070-4&amp;rft.place=New+York&amp;rft.pub=American+Elsevier+Pub.+Co.&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook" class="Z3988"><span style="display:none;"> </span></span></span></li>
<li id="cite_note-3"><span class="mw-cite-backlink"><b><a href="#cite_ref-3">^</a></b></span> <span class="reference-text"><span class="citation journal">de O. Pantoja, J. F. A. (1988). "Differential dynamic programming and Newton's method". <i>International Journal of Control</i> <b>47</b> (5): 1539–1553. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="http://dx.doi.org/10.1080%2F00207178808906114">10.1080/00207178808906114</a>. <a href="/wiki/International_Standard_Serial_Number" title="International Standard Serial Number">ISSN</a> <a rel="nofollow" class="external text" href="//www.worldcat.org/issn/0020-7179">0020-7179</a>.</span><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ADifferential+dynamic+programming&amp;rft.atitle=Differential+dynamic+programming+and+Newton%27s+method&amp;rft.au=de+O.+Pantoja%2C+J.+F.+A.&amp;rft.aufirst=J.+F.+A.&amp;rft.aulast=de+O.+Pantoja&amp;rft.date=1988&amp;rft.genre=article&amp;rft_id=info%3Adoi%2F10.1080%2F00207178808906114&amp;rft.issn=0020-7179&amp;rft.issue=5&amp;rft.jtitle=International+Journal+of+Control&amp;rft.pages=1539-1553&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.volume=47" class="Z3988"><span style="display:none;"> </span></span></span></li>
<li id="cite_note-4"><span class="mw-cite-backlink"><b><a href="#cite_ref-4">^</a></b></span> <span class="reference-text"><span class="citation web">Liao, L. Z.; C. A Shoemaker (1992). <a rel="nofollow" class="external text" href="http://hdl.handle.net/1813/5474">"Advantages of differential dynamic programming over Newton's method for discrete-time optimal control problems"</a>. Cornell University, Ithaca, NY.</span><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ADifferential+dynamic+programming&amp;rft.au=C.+A+Shoemaker&amp;rft.aufirst=L.+Z.&amp;rft.aulast=Liao&amp;rft.au=Liao%2C+L.+Z.&amp;rft.btitle=Advantages+of+differential+dynamic+programming+over+Newton%27s+method+for+discrete-time+optimal+control+problems&amp;rft.date=1992&amp;rft.genre=book&amp;rft_id=http%3A%2F%2Fhdl.handle.net%2F1813%2F5474&amp;rft.pub=Cornell+University%2C+Ithaca%2C+NY&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook" class="Z3988"><span style="display:none;"> </span></span></span></li>
<li id="cite_note-5"><span class="mw-cite-backlink"><b><a href="#cite_ref-5">^</a></b></span> <span class="reference-text"><span class="citation conference">Morimoto, J.; G. Zeglin, C.G. Atkeson (2003). "Minimax differential dynamic programming: Application to a biped walking robot". "Intelligent Robots and Systems, 2003.(IROS 2003). Proceedings. 2003 IEEE/RSJ International Conference on" <b>2</b>. pp. 1927–1932.</span><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ADifferential+dynamic+programming&amp;rft.atitle=Intelligent+Robots+and+Systems%2C+2003.%28IROS+2003%29.+Proceedings.+2003+IEEE%2FRSJ+International+Conference+on&amp;rft.aufirst=J.&amp;rft.aulast=Morimoto&amp;rft.au=Morimoto%2C+J.&amp;rft.btitle=Minimax+differential+dynamic+programming%3A+Application+to+a+biped+walking+robot&amp;rft.date=2003&amp;rft.genre=bookitem&amp;rft.pages=1927-1932&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.volume=2" class="Z3988"><span style="display:none;"> </span></span> <span style="display:none;font-size:100%" class="error citation-comment">Cite uses deprecated parameters (<a href="/wiki/Help:CS1_errors#deprecated_params" title="Help:CS1 errors">help</a>)</span></span></li>
<li id="cite_note-6"><span class="mw-cite-backlink"><b><a href="#cite_ref-6">^</a></b></span> <span class="reference-text"><span class="citation journal">Liao, L. Z; C. A Shoemaker (1991). "Convergence in unconstrained discrete-time differential dynamic programming". <i>IEEE Transactions on Automatic Control</i> <b>36</b> (6): 692. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="http://dx.doi.org/10.1109%2F9.86943">10.1109/9.86943</a>.</span><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ADifferential+dynamic+programming&amp;rft.atitle=Convergence+in+unconstrained+discrete-time+differential+dynamic+programming&amp;rft.au=C.+A+Shoemaker&amp;rft.aufirst=L.+Z&amp;rft.aulast=Liao&amp;rft.au=Liao%2C+L.+Z&amp;rft.date=1991&amp;rft.genre=article&amp;rft_id=info%3Adoi%2F10.1109%2F9.86943&amp;rft.issue=6&amp;rft.jtitle=IEEE+Transactions+on+Automatic+Control&amp;rft.pages=692&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.volume=36" class="Z3988"><span style="display:none;"> </span></span></span></li>
<li id="cite_note-7"><span class="mw-cite-backlink"><b><a href="#cite_ref-7">^</a></b></span> <span class="reference-text"><span class="citation thesis">Tassa, Y. (2011). <a rel="nofollow" class="external text" href="http://icnc.huji.ac.il/phd/theses/files/YuvalTassa.pdf"><i>Theory and implementation of bio-mimetic motor controllers</i></a> (Thesis). Hebrew University.</span><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ADifferential+dynamic+programming&amp;rft.aufirst=Y.&amp;rft.aulast=Tassa&amp;rft.au=Tassa%2C+Y.&amp;rft.btitle=Theory+and+implementation+of+bio-mimetic+motor+controllers&amp;rft.date=2011&amp;rft.genre=book&amp;rft_id=http%3A%2F%2Ficnc.huji.ac.il%2Fphd%2Ftheses%2Ffiles%2FYuvalTassa.pdf&amp;rft.pub=Hebrew+University&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook" class="Z3988"><span style="display:none;"> </span></span></span></li>
</ol>
<h2><span class="mw-headline" id="External_links">External links</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Differential_dynamic_programming&amp;action=edit&amp;section=7" title="Edit section: External links">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul>
<li><a rel="nofollow" class="external text" href="http://www.ros.org/wiki/color_DDP">A Python implementation of DDP</a></li>
<li><a rel="nofollow" class="external text" href="http://www.cs.washington.edu/people/postdocs/tassa/code/">A MATLAB implementation of DDP</a></li>
</ul>
